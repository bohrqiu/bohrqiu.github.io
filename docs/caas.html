<hr>
<p>title: 基于docker的云解决方案<br>date: 2015-12-16 21:52:17</p>
<h2 id="show-hide"><a href="#show-hide" class="headerlink" title="show: hide"></a>show: hide</h2><h1 id="基于docker的云解决方案"><a href="#基于docker的云解决方案" class="headerlink" title="基于docker的云解决方案"></a>基于docker的云解决方案</h1><blockquote>
<table>
<thead>
<tr>
<th>版本</th>
<th>时间</th>
<th>作者</th>
<th>修订章节</th>
<th>修订内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.0</td>
<td>2015-12-16</td>
<td>秋波</td>
<td>全部</td>
<td>init</td>
</tr>
<tr>
<td>1.1</td>
<td>2016-01-28</td>
<td>秋波</td>
<td>5.8</td>
<td>增加网络部分</td>
</tr>
</tbody>
</table>
</blockquote>
<h2 id="1-应用"><a href="#1-应用" class="headerlink" title="1. 应用"></a>1. 应用</h2><h3 id="1-1-yiji-boot应用"><a href="#1-1-yiji-boot应用" class="headerlink" title="1.1 yiji-boot应用"></a>1.1 <code>yiji-boot</code>应用</h3><p>应用切换到<code>yiji-boot</code>后，会提供如下能力：</p>
<ul>
<li><p>healthcheck</p>
<p>  对于应用来说，如果它所有依赖的资源(db、mq、cache、内存，cpu、磁盘io等)都健康，我们可以认为应用是健康的。</p>
<p>  对于所有的外部资源，我们都会提供组件，组件中包含<code>healthcheck</code>的能力。对于系统资源，<code>watcher</code>和<code>yiji-boot</code>提供了内存、磁盘、负载、文件描述符、线程死锁等健康检查。</p>
</li>
<li><p>metric</p>
<p>  我们需要知道某些组件(比如线程池，连接池)运行时实时状态，根据这些状态，我们可以实现监控、动态扩容的能力。</p>
</li>
<li><p><code>dtrace</code></p>
<p>  在分布式系统中，我们需要了解一个请求处理的整个链路，对于我们分析问题，优化请求路径，关键链路监控都很有帮助。我们在所有的组件上加入<code>dtrace</code>埋点。</p>
</li>
<li><p><code>hera</code></p>
<p>  <code>hera</code>提供配置管理和动态修改配置的能力。我们所有的组件开发时，把组件的动态修改能力交给<code>hera</code>，我们可以在不停机的状态下对线程池、连接池等限制资源调整。</p>
</li>
</ul>
<p>以上能力还不够，我们后面会结合业界的最佳实践(比如spring cloud)，完善<code>yiji-boot</code>。对于基于<code>yiji-boot</code>开发的应用来说，这些非功能性需求能力会随着<code>yiji-boot</code>的升级，能力一步一步增强。</p>
<h3 id="1-2-非yiji-boot应用"><a href="#1-2-非yiji-boot应用" class="headerlink" title="1.2 非yiji-boot应用"></a>1.2 非<code>yiji-boot</code>应用</h3><p>很不幸，这个世界总有不完美的地方。某些应用可能因为一些限制，很难切换到<code>yiji-boot</code>上,这些应用没有上面谈到的<code>yiji-boot</code>的能力，但是我们要求应用必须遵循各种规范，规范也是契约，通过契约，我们来实现统一的监控、健康检查、日志收集。</p>
<h2 id="2-轻量级虚拟化-docker"><a href="#2-轻量级虚拟化-docker" class="headerlink" title="2. 轻量级虚拟化-docker"></a>2. 轻量级虚拟化-docker</h2><p><code>docker</code>提供了轻量级的、基于内核虚拟化的、高性能解决方案，运行视图称之为容器，它表现为linux上的一个进程，它通过<code>cgroups</code>、<code>namespace</code>、<code>unionfs</code>实现了资源隔离。</p>
<p><code>docker</code>镜像是容器的静态视角，镜像是程序、数据和及其所依赖的程序的集合。我们把应用<code>build</code>成一个<code>docker</code>镜像，镜像是自包含，通过一条命令把<code>docker</code>镜像run起来。</p>
<p>对于<code>yiji-boot</code>应用和非<code>yiji-boot</code>应用，构建docker镜像后，我们有了统一应用的启动、停止操作。</p>
<h2 id="3-集群-kubernetes"><a href="#3-集群-kubernetes" class="headerlink" title="3. 集群-kubernetes"></a>3. 集群-kubernetes</h2><p><code>kubernetes</code>是google开源的应用集群管理工具，我们使用它来管理docker容器。它吸收了<code>borg</code>的优秀理念.在google内部,借助于<code>borg</code>：</p>
<blockquote>
<blockquote>
<p>We launch over 2 billion containers per week.</p>
</blockquote>
</blockquote>
<p>针对集群面临的问题，我们一一列举解决方案：</p>
<h3 id="3-1-资源调度"><a href="#3-1-资源调度" class="headerlink" title="3.1 资源调度"></a>3.1 资源调度</h3><p>集群核心的问题是资源调度。我们对应用进行分类并描述应用所需要的资源(比如cpu、内存)，kubernetes会根据应用资源需求，并去对各个物理节点上的资源打分，选取合适的资源来运行应用。</p>
<p>通过<code>metrics</code>、<code>healthcheck</code>、<code>watcher</code>提供的能力，我们在资源调度策略上能做到自动化<code>水平扩展</code>。</p>
<h3 id="3-2-请求路由"><a href="#3-2-请求路由" class="headerlink" title="3.2 请求路由"></a>3.2 请求路由</h3><p>应用要对外提供服务，需要把用户的请求路由到对应的服务器。</p>
<h4 id="3-2-1-入口系统"><a href="#3-2-1-入口系统" class="headerlink" title="3.2.1 入口系统"></a>3.2.1 入口系统</h4><p>对于入口系统，我们应用前面会有<code>nginx</code>，<code>nginx</code>来实现负载均衡和请求分发。(下图省略某些中间环节)</p>
<pre><code>                    ----&gt;web
browser-&gt;dns-&gt;ngnix-|
                    ----&gt;web
</code></pre><p>通过kubernetes提供的services，我们的拓扑会调整为如下的结构：</p>
<pre><code>                                              ----&gt;web
browser-&gt;dns-&gt;ngnix(L4/L7)-&gt;dns-&gt;kub services-|
                                              ----&gt;web
</code></pre><p>kubernetes会提供服务注册、服务发现、服务路由的能力，并通过健康检查实现动态请求调度。(kubernetes services的高可用和性能需要评估，如不满足，可以用固定ip的方式玩)</p>
<h4 id="3-2-2-内部系统"><a href="#3-2-2-内部系统" class="headerlink" title="3.2.2 内部系统"></a>3.2.2 内部系统</h4><p>目前我们内部系统使用了dubbo，dubbo自带服务注册，服务发现，服务路由能力。借助kubernetes的replication controller，控制应用副本数量。</p>
<h3 id="3-3-应用优雅停机"><a href="#3-3-应用优雅停机" class="headerlink" title="3.3 应用优雅停机"></a>3.3 应用优雅停机</h3><p>当dubbo服务关闭时，会通知服务调用方，不要发送新的请求过来，服务把请求处理完毕并返回后才关闭应用。我们设置应用停机超时时长为3分钟，对于超时的应用，保留应用现场dump(系统层面和jvm层面，并持久化到物理机文件系统），杀死应用。通过应用现场dump数据，我们可以分析应用的问题。</p>
<p>对于入口系统，通过kubernetes提供的钩子，同样提供应用优雅停机的实现。</p>
<h3 id="3-4-服务平滑升级"><a href="#3-4-服务平滑升级" class="headerlink" title="3.4 服务平滑升级"></a>3.4 服务平滑升级</h3><p>通过kubernetes提供的<code>rolling update</code>能力，实现多个应用逐步发布。</p>
<h3 id="3-5-日志搜索"><a href="#3-5-日志搜索" class="headerlink" title="3.5 日志搜索"></a>3.5 日志搜索</h3><p>应用都在kubernetes集群内，看日志是个大问题。我们通过<code>elk</code>，把所有日志收集起来，为开发同学提供统一的查询视图。</p>
<h3 id="3-6-应用状态监控"><a href="#3-6-应用状态监控" class="headerlink" title="3.6 应用状态监控"></a>3.6 应用状态监控</h3><p>通过<code>metrics</code>、<code>healthcheck</code>、<code>watcher</code>，我们暴露了容器的系统运行状态、组件运行状态、健康状态，我们会把这些数据实时收集起来，为应用<strong>自动</strong>动态<code>水平扩容</code>、<code>垂直扩容</code>提供依据，为开发同学提供统一的状态视图。</p>
<h3 id="3-7-业务监控"><a href="#3-7-业务监控" class="headerlink" title="3.7 业务监控"></a>3.7 业务监控</h3><p>通过收集所有的业务日志，按照业务规则定制监控、统计指标，提供统一的查询视图。</p>
<h3 id="3-8-容器状态视图"><a href="#3-8-容器状态视图" class="headerlink" title="3.8 容器状态视图"></a>3.8 容器状态视图</h3><p>通过kubernetes容器数据收集插件，为运维提供容器状态统一视图。</p>
<h3 id="3-9-dtrace"><a href="#3-9-dtrace" class="headerlink" title="3.9 dtrace"></a>3.9 dtrace</h3><p><code>SOA</code>架构体系下，服务能力由多套系统提供，如何快速定位出问题的节点是个麻烦的事。</p>
<p>通过<code>dtrace</code>对<code>rpc</code>框架埋点，我们能获得请求链路日志，为开发同学、运营同学提供多个系统之间请求流转视图，并能根据历史访问情况提供监控、报警能力。</p>
<p>通过<code>dtrace</code>对所有<code>资源组件</code>埋点，为开发同学提供应用内部的请求流转视图，为性能优化、故障分析提供数据支持。</p>
<h2 id="4-迁移计划"><a href="#4-迁移计划" class="headerlink" title="4. 迁移计划"></a>4. 迁移计划</h2><h3 id="4-1-yiji-boot"><a href="#4-1-yiji-boot" class="headerlink" title="4.1 yiji-boot"></a>4.1 yiji-boot</h3><p>我们计划在2016年3月份完成所有应用切换成yiji-boot。</p>
<h3 id="4-2-kubernetes集群"><a href="#4-2-kubernetes集群" class="headerlink" title="4.2 kubernetes集群"></a>4.2 kubernetes集群</h3><p>我们计划在测试环境实现所有的无状态应用切换到kubernetes集群上。把测试环境所有的硬件资源充分利用起来，并验证整个体系，同时也增强各个功能组件(日志搜索、应用状态监控、dtrace)。</p>
<h2 id="5-主要任务"><a href="#5-主要任务" class="headerlink" title="5. 主要任务"></a>5. 主要任务</h2><h3 id="5-1-kubernetes"><a href="#5-1-kubernetes" class="headerlink" title="5.1 kubernetes"></a>5.1 kubernetes</h3><ul>
<li>kubernetes services 高可用评估</li>
<li>安全需求评估</li>
</ul>
<h3 id="5-2-dtrace"><a href="#5-2-dtrace" class="headerlink" title="5.2 dtrace"></a>5.2 dtrace</h3><h4 id="5-2-1-实现应用内的资源调用跟踪"><a href="#5-2-1-实现应用内的资源调用跟踪" class="headerlink" title="5.2.1 实现应用内的资源调用跟踪"></a>5.2.1 实现应用内的资源调用跟踪</h4><ul>
<li>对外部的所有调用视为对资源的调用，所有涉及到网络io的请求都是资源(磁盘io先不管，我们的发展趋势是，应用除了写日志，不会设计磁盘io)</li>
<li>尽量无侵入的实现跟踪代码插入，改写公共包+Java agent 加载时织入</li>
<li>可以动态修改每一种资源是否启用跟踪(配置数据写到配置管理系统)</li>
<li>入口请求都启用跟踪</li>
</ul>
<h4 id="5-2-2-应用内跟踪数据统计"><a href="#5-2-2-应用内跟踪数据统计" class="headerlink" title="5.2.2 应用内跟踪数据统计"></a>5.2.2 应用内跟踪数据统计</h4><ul>
<li>展示应用所有调用链路</li>
<li>展示应用调用链路统计数据，平均，最大，最小，方差</li>
</ul>
<h4 id="5-2-3-监控报警"><a href="#5-2-3-监控报警" class="headerlink" title="5.2.3 监控报警"></a>5.2.3 监控报警</h4><ul>
<li>根据接口调用历史数据报警</li>
<li>根据异常等级，频次等阈值报警</li>
</ul>
<h3 id="5-3-实时状态采集"><a href="#5-3-实时状态采集" class="headerlink" title="5.3 实时状态采集"></a>5.3 实时状态采集</h3><p>实时状态功能主要从应用中，获取应用当前信息(watcher、metric、healthcheck)，应用运行环境信息。</p>
<ul>
<li>灵活的实现服务发现(kubernetes、CMDB)+手动添加服务</li>
<li>定时主动从应用层采集数据</li>
<li>收集数据形成报表，报表可以考虑<code>Grafana</code></li>
</ul>
<h3 id="5-4-日志收集"><a href="#5-4-日志收集" class="headerlink" title="5.4 日志收集"></a>5.4 日志收集</h3><h3 id="5-5-业务监控"><a href="#5-5-业务监控" class="headerlink" title="5.5 业务监控"></a>5.5 业务监控</h3><h3 id="5-6-服务鉴权"><a href="#5-6-服务鉴权" class="headerlink" title="5.6 服务鉴权"></a>5.6 服务鉴权</h3><p>实现操作人和服务之间的认证、授权。认证授权信息从OA(OA中有人员组织关系，权限)中获取。</p>
<h3 id="5-7-跨机房"><a href="#5-7-跨机房" class="headerlink" title="5.7 跨机房"></a>5.7 跨机房</h3><p>我们的现状(金融在重庆，其他在天津)决定我们一个数据中心已经跨机房了。在多个机房中部署基础镜像(主机房推送到其他机房)。发布上线时，通过非专线网络传输应用镜像层(docker分层文件系统)。在其他机房build镜像发布上线。</p>
<p>有状态的服务不放入kubernetes集群，网络上维持原状，保证重庆集群和天津集群的互联互通。</p>
<h3 id="5-8-网络"><a href="#5-8-网络" class="headerlink" title="5.8 网络"></a>5.8 网络</h3><ol>
<li><p>网络组件选型</p>
<p> 性能、安全、高可用</p>
</li>
</ol>
<p>初步选型flunnel+ovs</p>
<h2 id="6-写在最后"><a href="#6-写在最后" class="headerlink" title="6. 写在最后"></a>6. 写在最后</h2><p>愿景很宏大，很美好，但是还有不少路要走。还需要不少组件需要开发，还有一些关键组件的评估。先感谢各位同学能在2016年3月份之前完成应用切换。感谢帮助我们完成构想的同学，希望我们能一起来完成这个大工程。</p>
