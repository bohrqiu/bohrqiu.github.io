<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>2015年03月Reading Notes</title>
      <link href="/2015-03-reading-notes/"/>
      <url>/2015-03-reading-notes/</url>
      <content type="html"><![CDATA[<hr><p>title: 2015年03月Reading Notes<br>date: 2015-03-02 21:52:17<br>categories: java<br>tags:</p><ul><li>READING NOTES</li></ul><hr><h2 id="The-Asset-Pipeline"><a href="#The-Asset-Pipeline" class="headerlink" title="The Asset Pipeline"></a>The Asset Pipeline</h2><p><a href="http://guides.rubyonrails.org/asset_pipeline.html" target="_blank" rel="noopener">http://guides.rubyonrails.org/asset_pipeline.html</a></p><p><code>Asset Pipeline</code>对网站的静态资源进行预处理(合并、简化、压缩、预处理coffeescirpt sass等)。对于静态资源的处理，这里面提到的<code>Fingerprinting</code>来优化http 缓存可以借鉴下。</p><p><code>Fingerprinting</code>技术是在文件名中加上文件内容的标识，当文件内容改变时，文件名也改变。比如文件<code>global.css</code>加入md5的指纹后，文件名为<code>global-908e25f4bf641868d8683022a5b62f54.css</code>.</p><p>以前我们经常用<code>query string</code>中来标识版本，比如<code>main.js?1.4</code>/<code>main.js?v=1.4</code>.这种方式在某些CDN中有问题(有些CDN只识别文件名，新的版本文件会替换原版本的文件，在部署这个时间窗口会导致页面混乱)。</p><p>在使用浏览器缓存时，一般涉及到http header包括下面两种方案:</p><ol><li><code>Expires</code>和<code>Cache-Control: max-age</code> (没有过期之前，完全不发送请求)</li><li><code>Last-Modifed</code>和<code>ETag</code> (内容协商，需要发一个请求，如果内容没有变化，响应304)</li></ol><p>当方案2和<code>Fingerprinting</code>结合起来时，就比较完美了。对于现在很多开放CDN来讲，基本上都会用方案1，这是开源库名字里面的版本号就起着<code>Fingerprinting</code>的作用。也有用方案2的，估计是出于统计分析的目的。</p><p>对于静态资源的缓存，理想的组合是：</p><ol><li>配置很长的本地缓存时间(善用<code>Expires</code>和<code>Cache-Control: max-age</code>)，比如1年</li><li>通过<code>Fingerprinting</code>控制缓存(静态资源文件改变，对应的html的资源引用url也改变)</li></ol>]]></content>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2015年04月Reading Notes</title>
      <link href="/2015-04-reading-notes/"/>
      <url>/2015-04-reading-notes/</url>
      <content type="html"><![CDATA[<hr><p>title: 2015年04月Reading Notes<br>date: 2015-04-01 21:52:17<br>categories: java<br>tags:</p><ul><li>READING NOTES</li><li>nashorn</li><li>java reflect</li></ul><hr><h2 id="Enterprise-Nashorn"><a href="#Enterprise-Nashorn" class="headerlink" title="Enterprise Nashorn"></a><a name="enterprise_nashorn">Enterprise Nashorn</a></h2><p><a href="https://community.oracle.com/docs/DOC-910779" target="_blank" rel="noopener">https://community.oracle.com/docs/DOC-910779</a></p><p>本文讲述了<code>Nashorn</code>的一些使用场景：</p><ol><li>由外部提供计算逻辑，服务端执行计算逻辑返回结果</li><li>用java来定义接口，js来写逻辑，方便动态更新计算逻辑。(比如短信中的路由策略，需要经常更新)</li><li>写shell脚本(访问数据库，访问网络,监控…)</li></ol><p><code>Nashorn</code>的性能比前任强多了，但是和java比较还是有差距，主要的性能开销在js-&gt;java上。在关注性能的场景，可以在业务使用时，采用方法2，并缓存proxy对象。</p><pre><code>private static String isPrime = &quot; function test(num) {\n&quot; + &quot;if (num % 2 == 0)&quot; + &quot;return false;&quot; + &quot;for (var i = 3; i * i &lt;= num; i += 2)&quot;                                    + &quot;if (num % i == 0)&quot; + &quot;return false;&quot; + &quot;return true;&quot; + &quot;}&quot;;private Supplier&lt;Predicate&lt;Long&gt;&gt; supplier = Suppliers.memoize(() -&gt; getFilter());private Predicate getFilter() {    Invocable invocable = (Invocable) this.engine;    try {        this.engine.eval(isPrime);        return invocable.getInterface(Predicate.class);    } catch (Exception ex) {        throw Throwables.propagate(ex);    }}@Testpublic void testJavaScriptWithMemoize() throws Exception {    supplier.get().test(172673l);}</code></pre><p>对比了下<code>nashorn</code>和<code>groovy</code>的性能：</p><pre><code>NashornPerfTest.testJavaScript: [measured 50000 out of 51000 rounds, threads: 4 (all cores)] round: 0.00 [+- 0.00], round.block: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 96, GC.time: 0.25, time.total: 34.20, time.warmup: 3.44, time.bench: 30.76NashornPerfTest.testJava: [measured 50000 out of 51000 rounds, threads: 4 (all cores)] round: 0.00 [+- 0.00], round.block: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 0, GC.time: 0.00, time.total: 0.28, time.warmup: 0.01, time.bench: 0.27NashornPerfTest.testJavaScriptWithMemoize: [measured 50000 out of 51000 rounds, threads: 4 (all cores)] round: 0.00 [+- 0.00], round.block: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 0, GC.time: 0.00, time.total: 0.35, time.warmup: 0.06, time.bench: 0.29GroovyTest.testGroovyWithMemoize: [measured 50000 out of 51000 rounds, threads: 4 (all cores)] round: 0.00 [+- 0.00], round.block: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 5, GC.time: 0.07, time.total: 3.86, time.warmup: 1.75, time.bench: 2.11</code></pre><h2 id="spring-多线程中两个事务执行顺序控制"><a href="#spring-多线程中两个事务执行顺序控制" class="headerlink" title="spring 多线程中两个事务执行顺序控制"></a>spring 多线程中两个事务执行顺序控制</h2><p>有些场景需要控制两个事务的执行顺序，比如事务A执行完后，需要事务B中执行费时操作。因为是费时操作，一般会把事务B放到独立的线程中执行。然而事务A和事务B在不同的线程中，事务B还会依赖事务A提交的数据。如果在事务A中新启动线程执行事务B，有可能事务A还没有提交，就开始执行事务B了。这种场景需要保证事务A提交后，才能在新线程中执行事务B。</p><p>可以使用<code>TransactionSynchronizationManager</code>来解决这个问题：</p><pre><code>TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronization(){       void afterCommit(){            //submit transaction B to threadpool       }})；</code></pre><p>在事务A中加上此钩子，在<code>afterCommit</code>方法中向线程池提交事务A任务。具体处理代码<code>AbstractPlatformTransactionManager#triggerAfterCommit</code>，<code>ThreadLocal</code>清理<code>AbstractPlatformTransactionManager#cleanupAfterCompletion</code>.</p><h2 id="Web应用的缓存设计模式"><a href="#Web应用的缓存设计模式" class="headerlink" title="Web应用的缓存设计模式"></a>Web应用的缓存设计模式</h2><p><a href="">http://robbinfan.com/blog/38/orm-cache-sumup</a></p><p>robbin大哥讲解了对<code>ORM</code>缓存的理解.我司也有不少项目用了<code>ORM</code>,大多数人没有使用缓存的意识,有这样意识的同学提到过用<code>ehcache</code>,这在单节点的情况下，工作得很好，但是到了线上多机部署，数据不一致的问题就会出现，至少也要选用分布式缓存系统来实现哈。还有一点，因为有了缓存，数据订正这种事情就要谨慎了。</p><h2 id="java反射的性能"><a href="#java反射的性能" class="headerlink" title="java反射的性能"></a><a name="java_reflect">java反射的性能</a></h2><p>先看看下面的数据：</p><pre><code>Benchmark                                  Mode  Cnt     Score    Error  Units testInvokeMethod_Direct                avgt   20     0.587 ±  0.036  ns/op testInvokeMethod_Reflectasm            avgt   20    39.940 ±  1.957  ns/op testInvokeMethod_Reflectasm_withCache  avgt   20     9.784 ±  0.745  ns/op testInvokeMethod_reflect               avgt   20  1513.409 ± 85.396  ns/op testInvokeMethod_reflect_withCache     avgt   20    29.444 ±  1.863  ns/op</code></pre><p>上面的数据测试了<code>直接调用java方法</code>、<code>通过反射调用java</code>、<code>通过ReflectASM调用java</code>，<code>withCache</code>意思是把中间对象缓存起来。<br>反射确实很慢，但是只要把反射对象缓存起来，性能提升很大，<code>Reflectasm_withCache</code>比<code>reflect_withCache</code>快了3倍多。</p><p><code>Reflectasm</code>的原理是生成java源代码来实现反射的调用，下面就是生成的源代码。</p><pre><code>package reflectasm;import java.util.Map;import com.esotericsoftware.reflectasm.MethodAccess;public class PojoMethodAccess extends MethodAccess {    public Object invoke(Object paramObject, int paramInt, Object[] paramArrayOfObject) {        Pojo localPojo = (Pojo) paramObject;        switch (paramInt) {            case 0:                return Boolean.valueOf(localPojo.equals((Object) paramArrayOfObject[0]));            case 1:                return localPojo.toString();            case 2:                return Integer.valueOf(localPojo.hashCode());            case 3:                return localPojo.getName();            case 4:                localPojo.setName((String) paramArrayOfObject[0]);                return null;        }        throw new IllegalArgumentException(&quot;Method not found: &quot; + paramInt);    }}</code></pre><p>补充:</p><p>–</p><pre><code>ROUND 1:Benchmark                           Mode  Cnt   Score   Error  Units MHOpto.mh_invoke                    avgt   15  11.332 ± 0.577  ns/op MHOpto.mh_invokeExact               avgt   15  10.605 ± 0.667  ns/op MHOpto.mh_invokeExact_static_fianl  avgt   15   3.797 ± 0.201  ns/op MHOpto.plain                        avgt   15   4.093 ± 0.156  ns/op MHOpto.reflect                      avgt   15  11.599 ± 0.646  ns/op MHOpto.unreflect_invoke             avgt   15  11.147 ± 0.743  ns/op MHOpto.unreflect_invokeExact        avgt   15  11.392 ± 0.518  ns/op ROUND 2: Benchmark                           Mode  Cnt   Score   Error  UnitsMHOpto.mh_invoke                    avgt   15  11.799 ± 0.847  ns/opMHOpto.mh_invokeExact               avgt   15  11.830 ± 0.637  ns/opMHOpto.mh_invokeExact_static_fianl  avgt   15   4.415 ± 0.191  ns/opMHOpto.plain                        avgt   15   4.084 ± 0.300  ns/opMHOpto.reflect                      avgt   15  12.191 ± 0.637  ns/opMHOpto.unreflect_invoke             avgt   15  11.535 ± 0.816  ns/opMHOpto.unreflect_invokeExact        avgt   15  11.828 ± 0.666  ns/op</code></pre><p><code>MethodHandle</code>太牛叉了。</p><h2 id="spring-mvc的异步servlet实现"><a href="#spring-mvc的异步servlet实现" class="headerlink" title="spring mvc的异步servlet实现"></a><a name="spring_async_servelt">spring mvc的异步servlet实现</a></h2><p>spring异步web处理流程，我们先以<code>Controller</code>方法返回<code>Callable</code>对象为例</p><ol><li>http线程处理请求到Controller方法，返回Callable结果</li><li>spring选用<code>CallableMethodReturnValueHandler</code>来处理Callable结果，提交Callable到线程池，当前http线程返回,参考<code>WebAsyncManager.startCallableProcessing()</code></li><li>线程池中线程执行<code>Callable</code>任务，并且<code>dispatch</code>请求到容器，参考<code>WebAsyncManager.setConcurrentResultAndDispatch()</code></li><li>容器选取http线程继续处理请求</li></ol><p>通过分析源代码，下面几点需要关注下：</p><ol><li><p><strong>dispatch请求后，又会执行filterchain</strong>，我们需要保证filter只执行一次，filter最好继承<code>OncePerRequestFilter</code>。</p></li><li><p>spring内置了几种异步结果处理器，<code>CallableMethodReturnValueHandler</code>、<code>AsyncTaskMethodReturnValueHandler</code>、<code>DeferredResultMethodReturnValueHandler</code>分别支持方法返回<code>Callable</code>,<code>WebAsyncTask</code>,<code>DeferredResult</code>。</p></li><li><p><code>org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter#taskExecutor</code>此默认线程池为<code>SimpleAsyncTaskExecutor</code>，此<code>taskExecutor</code>每次都会都会新建线程来处理任务，生产环境建议单独配置线程池。</p></li></ol>]]></content>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> nashorn </tag>
            
            <tag> java reflect </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>一次技术问答</title>
      <link href="/%E4%B8%80%E6%AC%A1%E6%8A%80%E6%9C%AF%E9%97%AE%E7%AD%94/"/>
      <url>/%E4%B8%80%E6%AC%A1%E6%8A%80%E6%9C%AF%E9%97%AE%E7%AD%94/</url>
      <content type="html"><![CDATA[<p>最近一年多都没有写博客了，技术上做了很多有意义的事情，也有一些经验上的积累，逐步沉淀到博客上。</p><p>今天回答某公司的技术上的一些疑问，把问题和回答贴上来。逐步<code>养</code>自己的技术观。</p><a id="more"></a><h3 id="1-如何做数据安全防范？还有哪些支付安全需要注意？"><a href="#1-如何做数据安全防范？还有哪些支付安全需要注意？" class="headerlink" title="1. 如何做数据安全防范？还有哪些支付安全需要注意？"></a>1. 如何做数据安全防范？还有哪些支付安全需要注意？</h3><p>数据安全防范主要分为两个方面：</p><ol><li><p>内部</p><ul><li>数据库管理员职责单一，不能既懂业务，又懂数据库</li><li>数据库合理管控</li><li>日志脱敏</li><li>线上导入到线下的测试数据需要审核</li></ul></li><li><p>外部</p><p> 防止数据被泄露出去，比如sql防注入，服务器权限合理管控，数据访问需要进行合理的授权(比如遍历id就能把数据查出来)</p></li></ol><p>技术上的安全关注下owasp top 10，业务上的安全需要属于风控了，这块我了解的比较少，比如基本的同卡进出。</p><h3 id="2-认证授权怎样拦截无效用户？"><a href="#2-认证授权怎样拦截无效用户？" class="headerlink" title="2. 认证授权怎样拦截无效用户？"></a>2. 认证授权怎样拦截无效用户？</h3><p>上下文说得不是很清楚。我理解为，认证服务的能力。除了功能性需求，可能还需要一些非功能性需求。比如认证服务需要使用缓存，认证服务需要有限流。</p><h3 id="3-分布式性能提升的方案-数据模型设计有哪些最佳实践？"><a href="#3-分布式性能提升的方案-数据模型设计有哪些最佳实践？" class="headerlink" title="3. 分布式性能提升的方案. 数据模型设计有哪些最佳实践？"></a>3. 分布式性能提升的方案. 数据模型设计有哪些最佳实践？</h3><p>这个话题太大，我只能大概说下：</p><ol><li>首先要平衡组件和服务之间的关系，毕竟分布式第一定律：不要分布式</li><li>分布式场景，应该要考虑允许数据不一致的情况，合适的引入缓存</li><li>所有的性能问题，其实是怎么把资源榨干，了解各种资源的特性，就了解了如何取舍资源利用率</li><li>性能需要考虑，在项目前期，要对性能有预期，留下足够扩展的点，不要过多投入，也不能完全不管。</li></ol><h3 id="4-交易相关分布式事务控制-log的处理方式-异常处理机制请随意分享一些实际的经验"><a href="#4-交易相关分布式事务控制-log的处理方式-异常处理机制请随意分享一些实际的经验" class="headerlink" title="4. 交易相关分布式事务控制. log的处理方式. 异常处理机制请随意分享一些实际的经验"></a>4. 交易相关分布式事务控制. log的处理方式. 异常处理机制请随意分享一些实际的经验</h3><ol><li>分布式事务不要碰，简单的做法：服务提供方幂等+服务使用方努力尝试。这样做开销最小，毕竟失败不是常态。</li><li>log不要阻塞业务的执行。log中应该要保留请求唯一id，便于做链路分析。open-tracing还不错。</li><li>异常的处理原则：a. 业务尽量不要处理异常，交给框架，这样代码写起来会很优雅(框架异常处理器来处理)。b. 不要吞掉底层异常 c. 业务异常要考虑下是否必须收集栈信息(不收集栈信息可以减少日志，并提高性能)</li></ol><h3 id="5-分享一下中间件使用场景"><a href="#5-分享一下中间件使用场景" class="headerlink" title="5. 分享一下中间件使用场景"></a>5. 分享一下中间件使用场景</h3><p><code>中间件</code>这个词太大了。没办法讲。</p><h3 id="6-用dubbo框架多服务之间rpc调用同步返回这种需求有什么好的方法来保证实时性返回，因为整个服务链调执行完后还需要每个链路挨个返回效率很低"><a href="#6-用dubbo框架多服务之间rpc调用同步返回这种需求有什么好的方法来保证实时性返回，因为整个服务链调执行完后还需要每个链路挨个返回效率很低" class="headerlink" title="6. 用dubbo框架多服务之间rpc调用同步返回这种需求有什么好的方法来保证实时性返回，因为整个服务链调执行完后还需要每个链路挨个返回效率很低"></a>6. 用dubbo框架多服务之间rpc调用同步返回这种需求有什么好的方法来保证实时性返回，因为整个服务链调执行完后还需要每个链路挨个返回效率很低</h3><p>这个不是dubbo的问题。该异步的异步，该并行的并行，能缓存的缓存，性能自然好了。</p><h3 id="7-封装mq做同步返回替代rpc同步返回机制是否可行"><a href="#7-封装mq做同步返回替代rpc同步返回机制是否可行" class="headerlink" title="7. 封装mq做同步返回替代rpc同步返回机制是否可行"></a>7. 封装mq做同步返回替代rpc同步返回机制是否可行</h3><p>mq做同步返回？mq本来就是异步的，同步只是在交互上的同步，由两个异步的场景+等待组合成对外部的异步，这样做意义不大把？</p><p>soa中，dubbo只是提供了一种解决rpc的手段，不要忘记，消息在很多场景下比用rpc好得多。</p><h3 id="8-定时服务只能单点部署，如何做高可用"><a href="#8-定时服务只能单点部署，如何做高可用" class="headerlink" title="8. 定时服务只能单点部署，如何做高可用"></a>8. 定时服务只能单点部署，如何做高可用</h3><p>定时任务可以做高可用，开源有解决方案，quartz也有解决方案。两种思路：</p><ol><li>基于quartz官方的数据库方案。</li><li>数据库存任务，用zookeeper之类的来做任务分配，用quartz来做节点上的定时任务。</li></ol><h3 id="9-怎样才能评估服务拆分的合理性"><a href="#9-怎样才能评估服务拆分的合理性" class="headerlink" title="9. 怎样才能评估服务拆分的合理性"></a>9. 怎样才能评估服务拆分的合理性</h3><ul><li>若非可重用，先尽量不要拆分。微服务这样的入大流的名词，做起来需要很多基础设施做支撑。单体应用能支撑得很好，组件化，模块化也很不错。</li><li>服务拆分尽量按照领域来设计，高内聚、低耦合是目标(参考面向对象设计的基本原则)。服务粒度靠业务场景养出来的，准则很多，需要根据业务场景来逐步演进。</li><li>公司的技术架构能改变公司的业务发展现状！！！技术真的能带来生产力！！！可以参考阿里巴巴<code>大中台，小前台</code>的思路。不过要看阶段，合适的阶段做合适的事情，技术能带来价值，也能带来麻烦。一切都是取舍。</li></ul><h3 id="10-web项目分布式集群时session共享有什么好的实践。"><a href="#10-web项目分布式集群时session共享有什么好的实践。" class="headerlink" title="10. web项目分布式集群时session共享有什么好的实践。"></a>10. web项目分布式集群时session共享有什么好的实践。</h3><p>spring session+redis或者spring session+内存网格(Hazelcast\ Ignite）</p><h3 id="11-Dubbo服务不停机升级，如何让正在运行的处理完毕，并且不接收新请求的"><a href="#11-Dubbo服务不停机升级，如何让正在运行的处理完毕，并且不接收新请求的" class="headerlink" title="11. Dubbo服务不停机升级，如何让正在运行的处理完毕，并且不接收新请求的"></a>11. Dubbo服务不停机升级，如何让正在运行的处理完毕，并且不接收新请求的</h3><p>我们内部的版本修复了这个问题。步骤如下：</p><ul><li>provider通知consumer,不要发新请求过来（zookeeper unregister service）</li><li>provider等待服务执行完毕 (provider计数)</li><li>consumer等待服务执行完毕 (执行完毕后provider计数)</li><li>provider关闭</li><li>cusumer关闭</li></ul><h3 id="12-易极付这边的页面自动生成技术是如何实现的？"><a href="#12-易极付这边的页面自动生成技术是如何实现的？" class="headerlink" title="12. 易极付这边的页面自动生成技术是如何实现的？"></a>12. 易极付这边的页面自动生成技术是如何实现的？</h3><p>通过自动生成的业务主要用于后台管理，包括：新增，修改，删除，分页，导入，导出等功能。做起来比较简单，访问数据库获取元数据，通过freemarker生成代码。</p><h3 id="13-支付系统的异步通知的实现，如何优雅的控制通知的频率"><a href="#13-支付系统的异步通知的实现，如何优雅的控制通知的频率" class="headerlink" title="13. 支付系统的异步通知的实现，如何优雅的控制通知的频率"></a>13. 支付系统的异步通知的实现，如何优雅的控制通知的频率</h3><p>我们内部有一个通知服务，所有要对外通知的系统向通知服务发送消息。通知系统记录任务，通过异步http向外发送消息。每个任务维护通知的状态。现在通知间隔是逐步递增的。</p><h3 id="14-包的版本使用SNAPSHOT，怎样确保使用gradle下载的是最新的jar包"><a href="#14-包的版本使用SNAPSHOT，怎样确保使用gradle下载的是最新的jar包" class="headerlink" title="14. 包的版本使用SNAPSHOT，怎样确保使用gradle下载的是最新的jar包"></a>14. 包的版本使用SNAPSHOT，怎样确保使用gradle下载的是最新的jar包</h3><p>gradle有5年多没有用了，大概参考官方文档<a href="https://docs.gradle.org/current/userguide/dependency_management.html#sec:controlling_caching" target="_blank" rel="noopener">gradle:controlling_caching</a>可以做到。</p><h3 id="15-遇到回调先于同步返回的情况，该如何处理？"><a href="#15-遇到回调先于同步返回的情况，该如何处理？" class="headerlink" title="15. 遇到回调先于同步返回的情况，该如何处理？"></a>15. 遇到回调先于同步返回的情况，该如何处理？</h3><p>对于服务调用方，需要考虑幂等。谁先回来都无所谓。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> share </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2016年08月Reading Notes</title>
      <link href="/2016-08-reading-notes/"/>
      <url>/2016-08-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><p>服务发现用于动态感知服务提供方地址，并提供服务路由分发策略能力。</p><h3 id="1-客户端发现"><a href="#1-客户端发现" class="headerlink" title="1. 客户端发现"></a>1. 客户端发现</h3><p>客户端从注册中心获取服务列表，客户端监听服务列表的变化，客户端通过路由策略选择合适的服务端地址。</p><p>服务端在停服务时，需要先通知客户端不要发送新请求过来，等服务端把当前请求处理完后，才断开连接。</p><h3 id="2-代理端发现"><a href="#2-代理端发现" class="headerlink" title="2. 代理端发现"></a>2. 代理端发现</h3><p>代理端对外提供服务，主要用于对外请求路由。代理端(比如nginx/haproxy)转发请求到后端服务。后端服务暴露地址到注册中心，代理程序动态获取服务地址。</p><p>nginx可以试试<a href="https://github.com/weibocom/nginx-upsync-module" target="_blank" rel="noopener">nginx-upsync-module</a></p><p>在k8s内部，采用nginx+dns+k8s proxy实现。</p><h2 id="关于高可用系统"><a href="#关于高可用系统" class="headerlink" title="关于高可用系统"></a>关于高可用系统</h2><p><a href="http://coolshell.cn/articles/17459.html" target="_blank" rel="noopener">http://coolshell.cn/articles/17459.html</a></p><p>前段时间写了一段公司的公关文(CUI NIU BI)，强迫自己写了<code>5个9</code>。</p><p>作者讲了几个大实话：</p><blockquote><blockquote><p>如果你没有一套科学的牛逼的软件工程的管理，没有牛逼先进的自动化的运维工具，没有技术能力很牛逼的工程师团队，怎么可能出现高可用的系统啊。</p></blockquote></blockquote><blockquote><blockquote><p>深层次的东西则是——对工程这门科学的尊重：1.对待技术的态度 2.一个公司的工程文化 3.领导者对工程的尊重</p></blockquote></blockquote><p>佛渡有缘人，点到即止，不强求。</p><ol><li>以前对高可用的关注点主要在应用层面，现在加入运维团队后，高可用的关注点延伸到机房、硬件。</li><li>同城双活只要网络质量靠谱点，还是比较好做，主要是南北请求路由控制和东西流量故障切换。</li><li>把服务不可用的因素分成<a href="https://docs.oracle.com/cd/A91202_01/901_doc/rac.901/a89867/pshavdtl.htm" target="_blank" rel="noopener">planned、unplanned</a>，分别设计预案</li></ol><p>也许把<code>SLA</code>写到合同里，我就不敢乱吹牛逼了。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> 服务发现 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2016年06月Reading Notes</title>
      <link href="/2016-06-reading-notes/"/>
      <url>/2016-06-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Service-Wiring-with-Spring-Cloud"><a href="#Service-Wiring-with-Spring-Cloud" class="headerlink" title="Service Wiring with Spring Cloud"></a>Service Wiring with Spring Cloud</h2><p><a href="https://www.infoq.com/articles/spring-cloud-service-wiring" target="_blank" rel="noopener">https://www.infoq.com/articles/spring-cloud-service-wiring</a></p><p>这篇文章聊到了spring cloud如何提供配置管理、服务发现、服务路由能力。结合我们的现状谈谈：</p><ol><li>有些应用没有做到cloud-ready，依赖服务地址配置信息写死。。</li><li>内部请求用dubbo，实现了服务发现，服务路由，大多数问题已经hold住了</li><li>自研的配置管理系统可以做到配置动态更新，比spring cloud 下的<code>Enabling Dynamic Refresh</code>做法优雅多不少</li><li>还需要提供http服务的服务注册、发现能力。为外部http负载均衡、内部http服务依赖提供服务发现、服务路由能力</li></ol>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> nginx plus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2016年05月Reading Notes</title>
      <link href="/2016-05-reading-notes/"/>
      <url>/2016-05-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="NGINX-Plus-vs-F5-BIG-IP-A-Price-Performance-Comparison"><a href="#NGINX-Plus-vs-F5-BIG-IP-A-Price-Performance-Comparison" class="headerlink" title="NGINX Plus vs. F5 BIG-IP: A Price-Performance Comparison"></a>NGINX Plus vs. F5 BIG-IP: A Price-Performance Comparison</h2><p>当通用硬件的处理能力越来越强，专有芯片的使用场景会越来越少，硬件提供商会逐步转型为软件提供商。以前也听到不少声音，比如某硬件负载设备，通用cpu中集成了<code>LVS</code>.</p><p>未来我们可能、会、应该废弃掉大部分负载均衡设备吧。</p><h2 id="Microservices-Oracle-A-Bright-Future"><a href="#Microservices-Oracle-A-Bright-Future" class="headerlink" title="Microservices + Oracle: A Bright Future"></a>Microservices + Oracle: A Bright Future</h2><p>这篇文章对微服务的讲述很全面。部分观点不谋而合…</p><p><iframe src="//www.slideshare.net/slideshow/embed_code/key/y5r6fWXDjIHS9I" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/KellyGoetsch/microservices-oracle-a-bright-future" title="Microservices + Oracle: A Bright Future" target="_blank">Microservices + Oracle: A Bright Future</a> </strong> from <strong><a href="//www.slideshare.net/KellyGoetsch" target="_blank">Kelly Goetsch</a></strong> </div></p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> nginx plus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2016年04月Reading Notes</title>
      <link href="/2016-04-reading-notes/"/>
      <url>/2016-04-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Contended-FOR-false-sharing"><a href="#Contended-FOR-false-sharing" class="headerlink" title="@Contended FOR false sharing"></a><a name="false-sharing">@Contended FOR false sharing</a></h2><p>ABOUT False Sharing：</p><blockquote><blockquote><p>Most high performance processors, insert a cache buffer between slow memory and the high speed registers of the CPU. Accessing a memory location causes a slice of actual memory (a cache line) containing the memory location requested to be copied into the cache. Subsequent references to the same memory location or those around it can probably be satisfied out of the cache until the system determines it is necessary to maintain the coherency between cache and memory.</p></blockquote></blockquote><blockquote><blockquote><p>Each update of an individual element of a cache line marks the line as invalid. Other processors accessing a different element in the same line see the line marked as invalid. They are forced to fetch a more recent copy of the line from memory or elsewhere, even though the element accessed has not been modified. This is because cache coherency is maintained on a cache-line basis, and not for individual elements. As a result there will be an increase in interconnect traffic and overhead.</p></blockquote></blockquote><p>当下列条件满足时，False sharing极大降低了并发性能。</p><ul><li>Shared data is modified by multiple processors.</li><li>Multiple processors update data within the same cache line.</li><li>This updating occurs very frequently (for example, in a tight loop).</li></ul><p>java8 引入了<code>@Contended</code>，在对象编译时，编译器会插入<code>padding</code>,防止多个数据在一个cache line中。</p><p><code>https://github.com/m0wfo/false-sharing-demo</code>测试结果：</p><pre><code>[0] % java -XX:-RestrictContended -jar target/false-sharing-demo-1.0.0-SNAPSHOT.jar plainUpdating unpadded version 1B times Took: 55.457223514secUpdating @Contended version 1B times Took: 7.387646696sec</code></pre>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2016年02月Reading Notes</title>
      <link href="/2016-02-reading-notes/"/>
      <url>/2016-02-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="每个架构师都应该研究下康威定律"><a href="#每个架构师都应该研究下康威定律" class="headerlink" title="每个架构师都应该研究下康威定律"></a><a name="about-arch"><a href="http://mp.weixin.qq.com/s?__biz=MzA5Nzc4OTA1Mw==&amp;mid=408286995&amp;idx=1&amp;sn=1634698023c48b754d42af69cee2ab32" target="_blank" rel="noopener">每个架构师都应该研究下康威定律</a></a></h2><p>最近在做<code>DEVOPS</code>,看技术的出发点有所变化，正好看到这篇文章，总结下自己。</p><h3 id="1-系统架构的目标是解决利益相关者的关注点。"><a href="#1-系统架构的目标是解决利益相关者的关注点。" class="headerlink" title="1. 系统架构的目标是解决利益相关者的关注点。"></a>1. 系统架构的目标是解决利益相关者的关注点。</h3><blockquote><blockquote><p>架构其实是发现利益相关者（stakeholder），然后解决他们的关注点（concerns）</p><p>业务方，产品经理，客户/用户，开发经理，工程师，项目经理，测试人员，运维人员，产品运营人员等等都有可能是利益相关者，架构师要充分和利益相关者沟通，深入理解他们的关注点和痛点，并出架构解决这些关注点。</p></blockquote></blockquote><p>架构师在这里也定位为一个好的需求分析师，但是架构师往往会从自己的角度(利益相关或者立场相关)来设计。我之前一直做开发工作，在技术选型或者研究时，对于可运维性考虑得比较少，在痛过几次后，发现监控的价值，来补充相关<code>metrics</code>的能力。</p><h3 id="2-关注非功能性需求"><a href="#2-关注非功能性需求" class="headerlink" title="2. 关注非功能性需求"></a>2. 关注非功能性需求</h3><ul><li>easy to separate</li><li>easy to understand</li><li>easy to extend</li><li>easy to change</li><li>easy to replace</li><li>easy to deploy</li><li>easy to scale</li><li>easy to recover</li><li>easy to connect</li><li>easy to afford</li></ul><blockquote><blockquote><p>Architecture represents the significant design decisions that shape a system, where significant is measured by cost of change.</p><p>架构的目标是用于管理复杂性、易变性和不确定性，以确保在长期的系统演化过程中，一部分架构的变化不会对架构的其它部分产生不必要的负面影响。</p></blockquote></blockquote><p>这里补充一点，需要考虑<code>easy to find the problem</code>。除了合理的规划日志，我们要做到<code>failfast</code>。当关键资源依赖条件不满足，我们最好是把问题用最显示的方式暴露出来，而不是让它在那里一直报错。</p><h3 id="3-架构的迭代和演化性"><a href="#3-架构的迭代和演化性" class="headerlink" title="3. 架构的迭代和演化性"></a>3. 架构的迭代和演化性</h3><blockquote><blockquote><p>做技术架构的都有点完美主义倾向，一开始往往喜欢求大求全，忽视架构的演化和迭代性，这种倾向易造产品和用户之间不能形成有效快速的反馈，产品不满足最终用户需求.</p><p>在系统真正地投入生产使用之前，再好的架构都只是假设，产品越晚被使用者使用，失败的成本和风险就越高，而小步行进，通过MVP快速实验，获取客户反馈，迭代演化产品，能有效地减少失败的成本和风险。</p></blockquote></blockquote><p>好的架构是衍变出来的，而非设计出来的。</p><h3 id="4-构建闭环反馈架构"><a href="#4-构建闭环反馈架构" class="headerlink" title="4. 构建闭环反馈架构"></a>4. 构建闭环反馈架构</h3><blockquote><blockquote><p>第一条道路，系统思维，开发驱动的组织机体，其能力不是制作软件，而是持续的交付客户价值，架构师需要有全局视角和系统思维（System Thinking），深入理解整个价值交付链，从业务需求、研发、测试、集成，到部署运维，这条价值链的效率并不依赖于单个或者几个环节，局部优化的结果往往是全局受损，架构师要站在系统高度去优化整个价值交付链，让企业和客户之间形成快速和高效的价值传递。</p></blockquote></blockquote><blockquote><blockquote><p>第二条道路，强化反馈环，任何过程改进的目标都是加强和缩短反馈环。</p><p>收集-&gt;测量-&gt;调整-&gt;闭环重复，在有测量数据和反馈的基础上，系统、应用、流程和客户体验才有可能获得持续的提升和改善，否则没有数据的所谓改进只能靠拍脑袋或者说猜测。</p></blockquote></blockquote><p>这里提到监控的重要性，<strong>没有测量，就没有改进和提升</strong>，<a href="http://www.infoq.com/cn/articles/metrics-driven-development" target="_blank" rel="noopener">MDD</a>这偏文章有点意思，通过分层和可用的性能指标让开发人员了解项目业务方面的内容，反过来，业务人员也能理解项目技术方面的内容，看到开发人员所面临的问题和我们的负载局限。</p><blockquote><blockquote><p>第三条道路，鼓励勇于承担责任，冒险试错和持续提升的文化。</p></blockquote></blockquote><p>最后，贴上一张关于<code>DevOps</code>的图。</p><p><img src="/2016-02-reading-notes/devops.jpg" alt=""></p><h2 id="时间序列数据库的秘密"><a href="#时间序列数据库的秘密" class="headerlink" title="时间序列数据库的秘密"></a>时间序列数据库的秘密</h2><p><a href="http://www.infoq.com/cn/articles/database-timestamp-01" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/database-timestamp-01</a></p><p><a href="http://www.infoq.com/cn/articles/database-timestamp-01" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/database-timestamp-01</a></p><p><a href="http://www.infoq.com/cn/articles/database-timestamp-01" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/database-timestamp-01</a></p><p>此文讲明白了时序数据库，最近也在纠结这个事(原来一直看好opentsdb，但是没有深入调研opentsdb的细节，对es也不是太了解)，这里总结下全文。</p><p>时间序列数据库除了提供查询能力外，我们也希望能够提供在查询阶段做聚合能力。</p><p>聚合有有三个步骤:</p><ul><li>用索引检索出行号(搜索引擎最擅长)</li><li>从主存储按行号加载列(列式存储最合适)</li><li>计算(分布式计算列数据)</li></ul><p><code>ES</code>在这三个步骤上都做得很好。</p><ol><li><p>如何快速检索？</p><p> <img src="http://cdn3.infoqstatic.com/statics_s2_20160217-0123u3/resource/articles/database-timestamp-02/zh/resources/0820002.jpg" alt=""></p><p> lucene倒排索引由<code>Term index</code>-&gt;<code>Term Dictionary</code>-&gt;<code>Posting List</code>构成。<code>TI</code>是对<code>TD</code>做的索引，实现对Term的快速查找。Mysql使用b-tree排序存储<code>TD</code>在磁盘上;<code>Lucene</code>增加了<code>TI</code>保存在内存中，查询效率更高。</p></li><li><p>如何联合索引查询？</p><p> 对于<code>age=18 AND gender=女</code>的查询过滤。mysql的做法是(如果两个列都建立了索引，当然gender列做索引在mysql上没有什么卵用)先在索引上找<code>age=18</code>的所有id，然后遍历id匹配。</p><p> Elasticsearch支持：</p><ul><li><p>使用skip list数据结构。同时遍历gender和age的posting list，互相skip；</p><p>  利用skip list(Level0存储原始有序数据，level1存储部分数据，查找时从level1跳过部分数据)，跳过了遍历的成本,并且用<code>Frame of Reference</code>(计算差值，分块后，每个块内部选择合适的bit来存储)压缩存储。</p></li><li><p>使用bitset数据结构，对gender和age两个filter分别求出bitset，对两个bitset做AN操作。</p><p>  大多数场景下，bitset非常稀疏，bitset压缩空间很大。lucene采用<code>Roaring Bitmap</code>,算法也有点意思：<br>  计算N/65536和N%65536的值，把N/65536相同的分为一个组，分组后根据每个组的情况用short数字或者bitset。</p></li></ul></li><li><p>如何减少文档数？</p><p> 一般采用数据库会合并，把多行数据合并成一行，比如把原来精确到秒的数据合并为分。<code>ES</code>中使用内嵌文档(Nested Document)实现公共字段的去从(比如应用名、ip、环境标识、metricsname)</p></li><li><p>如何加载更快？</p><p> 如何利用索引和主存储，是一种两难的选择。</p><ul><li><p>选择不使用索引，只使用主存储：除非查询的字段就是主存储的排序字段，否则就需要顺序扫描整个主存储。</p><p>   这要求数据存储按照查询条件来选择主键(mysql中的聚簇索引)，如果查询条件很多，会扫描整个文件。</p></li><li><p>选择使用索引，然后用找到的row id去主存储加载数据：这样会导致很多碎片化的随机读操作。</p><p>  从硬盘上随机读写性能低</p></li></ul><p>Lucene底层读取文件基于mmap，充分利用操作系统的特性来映射文件到内存(列式存储的优点是每列一个文件，可以充分利用mmap，加载需要的列)，所以还是内存越大越好。</p></li><li><p>分布式聚合如何做得快？</p><p> 通过数据分片，把数据分散到多台机器。在计算时，各个节点index计算聚合结果，然后汇总后在聚合。这样也减少了网络带宽，充分利用了各个节点的计算能力。</p></li><li><p>为什么时间序列需要更复杂的聚合？</p><p> 通常会有降频(比如原来时间精确到秒，现在需要以分为单位)和降维(比如原来有地域纬度，统计时求所有地区)需求。<code>ES</code>支持Pipeline Aggregation可以实现数据在聚合之后再做聚合，能满足多次聚合的需求。</p></li></ol>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker</title>
      <link href="/docker/"/>
      <url>/docker/</url>
      <content type="html"><![CDATA[<h3 id="1-docker配置"><a href="#1-docker配置" class="headerlink" title="1. docker配置"></a>1. docker配置</h3><p>在mac osx中，docker deamon运行在virtualbox虚拟机中，docker client和虚拟机中的docker deamon交互。</p><h4 id="1-1-环境配置"><a href="#1-1-环境配置" class="headerlink" title="1.1 环境配置"></a>1.1 环境配置</h4><pre><code>#配置docker环境变量eval &quot;$(docker-machine env default)&quot;#配置docker启动alias    alias docker-start=&apos;docker-machine start default&apos;#配置docker关闭aliasalias docker-stop=&quot;docker-machine stop default&quot;</code></pre><p>启动命令如下：</p><pre><code>docker-startdocker-stop</code></pre><h4 id="1-2-配置镜像私服"><a href="#1-2-配置镜像私服" class="headerlink" title="1.2 配置镜像私服"></a>1.2 配置镜像私服</h4><p>测试环境中私服提供服务如下：</p><pre><code>#docker registry uihttp://192.168.46.21:10005/#docker registry restful apihttp://192.168.46.21:5000/v2/_catalog</code></pre><p>下面配置docker registry私服为192.168.46.21：</p><pre><code>#登陆到serverdocker-machine ssh default#修改/var/lib/boot2docker/profile--insecure-registry 192.168.46.21:5000--registry-mirror http://192.168.46.21:5000</code></pre><p>国内docker mirror：</p><pre><code>https://lug.ustc.edu.cn/wiki/mirrors/help/dockerhttp://0b929cdf.m.daocloud.io</code></pre><h3 id="2-docker-常用命令"><a href="#2-docker-常用命令" class="headerlink" title="2. docker 常用命令"></a>2. docker 常用命令</h3><p><img src="/docker/docker-command.jpg" alt=""></p><pre><code>#拉取镜像docker pull yiji/java8:1.0#查看镜像历史,能看到docker镜像层的细节docker history  yiji/java8:1.0#删除镜像docker rmi -f yiji/centos7:latest#删除容器docker rm#执行命令    docker run yiji/centos7 /bin/echo &apos;hello world&apos;#交互运行：docker run -it yiji/centos7 /bin/bash#查看容器运行状态docker ps -a#查看指定容器状态docker inspect f46935242662#查看端口隐射，通过inspect结果过滤docker inspect --format=&apos;{{.NetworkSettings.Ports}}&apos; 8f4a179a0647#查看容器资源占用docker stats 92202cc1c3f0#查看docker deamon运行ipecho $DOCKER_HOST#清理后台停止的容器docker rm $( docker ps -a -q)#查看镜像的环境变量docker run  yiji/java8:2.0  env</code></pre><h3 id="3-F-A-Q"><a href="#3-F-A-Q" class="headerlink" title="3. F.A.Q"></a>3. F.A.Q</h3><h4 id="3-1-docker文件系统"><a href="#3-1-docker文件系统" class="headerlink" title="3.1. docker文件系统"></a>3.1. docker文件系统</h4><p>docker镜像的文件系统采用多层存储，镜像中全是只读层，便于分发和共享(pull镜像时，会在本地拉已经存在的层)。运行时建立读写层，对于应用来说，需要把文件系统mount到docker中(这样性能最好)，device mapper对性能有影响。</p><blockquote><blockquote><p>Data volumes provide the best and most predictable performance. This is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy-on-write. For this reason, you may want to place heavy write workloads on data volumes.</p></blockquote></blockquote><h4 id="3-2-关于基础镜像"><a href="#3-2-关于基础镜像" class="headerlink" title="3.2. 关于基础镜像"></a>3.2. 关于基础镜像</h4><p>制作基础镜像时权衡镜像大小(虽然可以在主机上缓存基础镜像，也需要考虑首次分发的大小)。我们最开始使用centos7来制作基础镜像，发现镜像300多M，如果在加上java8，基础镜像有600多M了。</p><p>可以参考<a href="https://hub.docker.com/r/frolvlad/alpine-oraclejdk8/" target="_blank" rel="noopener">frolvlad/alpine-oraclejdk8</a>来制作基础镜像。</p><pre><code>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZEyiji/java8          2.0                 1d58b31d19a0        4 days ago          166.5 MB</code></pre><p>java8的基础镜像只有不到200m。</p><h4 id="3-3-制作docker镜像并运行"><a href="#3-3-制作docker镜像并运行" class="headerlink" title="3.3. 制作docker镜像并运行"></a>3.3. 制作docker镜像并运行</h4><ol><li><p>编写Dockerfile</p><pre><code>FROM yiji/java8:2.0COPY  yiji-boot-test-1.1-SNAPSHOT.jar /opt/yiji-boot-test-1.1-SNAPSHOT.jarWORKDIR /optENTRYPOINT java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=4004 -jar /opt/yiji-boot-test-1.1-SNAPSHOT.jar</code></pre></li><li><p>build   </p><pre><code>docker build -t  yiji-boot-test:1.0 .</code></pre></li><li><p>run</p><pre><code>docker run -p 8081:8081 -p 4004:4004  yiji-boot-test:1.0</code></pre><p> 其中8081是应用web端口，4004端口是远程调试端口</p></li><li><p>在容器内执行命令</p><p> 在容器运行起来后，我们需要去容器内check下情况。</p><pre><code>docker exec -it 92202cc1c3f0  sh</code></pre></li></ol><h4 id="3-4-docker本地存储"><a href="#3-4-docker本地存储" class="headerlink" title="3.4 docker本地存储"></a>3.4 docker本地存储</h4><p>docker 容器运行的文件存储在本地。下面来看看这些文件：</p><p>查看docker container id</p><pre><code>CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS                   PORTS                                            NAMES8f4a179a0647        yiji-boot-test:1.0   &quot;/bin/sh -c &apos;java -ag&quot;   2 hours ago         Up 2 hours               0.0.0.0:4004-&gt;4004/tcp, 0.0.0.0:8081-&gt;8081/tcp   silly_northcutt</code></pre><p>登陆到虚拟机，在mac和windows下，docker在虚拟机中运行</p><pre><code>docker-machine ssh default</code></pre><p>切换到docker运行目录</p><pre><code>sudo su -cd /var/lib/docker/aufs/mnt/</code></pre><p><code>ls |grep 8f4a179a0647</code>发现两个目录</p><pre><code>8f4a179a064737658b4055fb785c432c843f473a9d5fc40fba445017bd5b7e2e8f4a179a064737658b4055fb785c432c843f473a9d5fc40fba445017bd5b7e2e-init</code></pre><p>进入到第一个目录的opt子目录下，会找到我们打包的jar文件(chroot的魔力所在)</p><pre><code>root@default:/mnt/sda1/var/lib/docker/aufs/mnt/8f4a179a064737658b4055fb785c432c843f473a9d5fc40fba445017bd5b7e2e/opt# ls -ltotal 67168-rw-r--r--    1 root     root      68777433 Dec 28 08:26 yiji-boot-test-1.1-SNAPSHOT.jar</code></pre><h4 id="3-5-关于docker的安全"><a href="#3-5-关于docker的安全" class="headerlink" title="3.5 关于docker的安全"></a>3.5 <a name="docker-security">关于docker的安全</a></h4><p><iframe src="//www.slideshare.net/slideshow/embed_code/key/vhMhelcV6Z9rXr" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/jpetazzo/docker-linux-containers-lxc-and-security" title="Docker, Linux Containers (LXC), and security" target="_blank">Docker, Linux Containers (LXC), and security</a> </strong> from <strong><a href="//www.slideshare.net/jpetazzo" target="_blank">Jérôme Petazzoni</a></strong> </div></p><p>我们需要做两件事情，</p><ol><li><p>不要使用root in docker</p><p> 参考<a href="http://stackoverflow.com/questions/24308760/running-app-inside-docker-as-non-root-user" target="_blank" rel="noopener">Running app inside Docker as non-root user</a></p></li><li><p>经常升级内核</p></li></ol><p>做安全的同学可以看看更多关于docker 安全的文章:</p><p><a href="https://github.com/docker/docker-bench-security" target="_blank" rel="noopener">docker-bench-security</a></p><p><a href="https://github.com/konstruktoid/Docker/blob/master/Security/CheatSheet.md" target="_blank" rel="noopener">Security CheatSheet</a></p><p><a href="https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_1.6_Benchmark_v1.0.0.pdf" target="_blank" rel="noopener">CIS Docker 1.6 Benchmark</a></p><p>最后引用<a href="https://twitter.com/mortman" target="_blank" rel="noopener">David Mortman</a>在2015年<a href="https://www.defcon.org/" target="_blank" rel="noopener">Defcon</a>的一句话：</p><blockquote><blockquote><p>a year ago, [docker and security] was pretty horrible,six months ago it wasn’t so bad, and now it’s pretty usable.</p></blockquote></blockquote><h4 id="3-6-docker-run-vm"><a href="#3-6-docker-run-vm" class="headerlink" title="3.6 docker run vm?"></a>3.6 docker run vm?</h4><p>一些观点：</p><p><a href="http://dockone.io/article/935" target="_blank" rel="noopener">2016年六大OpenStack &amp; Docker发展趋势预测</a></p><blockquote><blockquote><p>由原本的虚拟机管理程序为核心转变为容器加裸机组合模式</p></blockquote></blockquote><p><a href="http://www.infoq.com/cn/news/2015/12/hypernetes-caas" target="_blank" rel="noopener">Hypernetes实现多租户CaaS，且无需客户操作系统</a></p><blockquote><blockquote><p>OpenStack是一个用于构建和管理云的IaaS框架，Hypernetes使用了它的部分组件。它使用OpenStack的身份和服务目录提供程序Keystone进行身份验证和授权。它还使用了其他的OpenStack组件，如用于存储的Cinder和Ceph，用于网络管理的Neutron。对于OpenStack而言，这是一个独特的用法，因为其组件通常都不在OpenStack部署之外使用。</p></blockquote></blockquote><h4 id="3-7-docker-api"><a href="#3-7-docker-api" class="headerlink" title="3.7 docker api"></a>3.7 docker api</h4><h5 id="3-7-1-unix-socket-api"><a href="#3-7-1-unix-socket-api" class="headerlink" title="3.7.1 unix-socket api"></a>3.7.1 unix-socket api</h5><p>查看docker信息:</p><pre><code>curl --unix-socket /var/run/docker.sock http:/info |jq</code></pre><p>api文档:</p><pre><code>https://docs.docker.com/engine/reference/api/docker_remote_api/</code></pre><h5 id="3-7-2-java-api"><a href="#3-7-2-java-api" class="headerlink" title="3.7.2 java api"></a>3.7.2 java api</h5><p>依赖：</p><pre><code>&lt;dependency&gt;        &lt;groupId&gt;com.github.docker-java&lt;/groupId&gt;        &lt;artifactId&gt;docker-java&lt;/artifactId&gt;        &lt;version&gt;3.0.1&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;groupId&gt;de.gesellix&lt;/groupId&gt;                &lt;artifactId&gt;unix-socket-factory&lt;/artifactId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.kohlschutter.junixsocket&lt;/groupId&gt;        &lt;artifactId&gt;junixsocket-common&lt;/artifactId&gt;        &lt;version&gt;2.0.4&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.kohlschutter.junixsocket&lt;/groupId&gt;        &lt;artifactId&gt;junixsocket-native-common&lt;/artifactId&gt;        &lt;version&gt;2.0.4&lt;/version&gt;    &lt;/dependency&gt;</code></pre><p> 使用：</p><pre><code> DockerClient dockerClient = DockerClientBuilder.getInstance(&quot;unix:///var/run/docker.sock&quot;).build();Info info = dockerClient.infoCmd().exec();System.out.print(info);</code></pre><p>api文档:</p><pre><code>https://github.com/docker-java/docker-java/</code></pre><h4 id="3-8-docker-on-centos7配置"><a href="#3-8-docker-on-centos7配置" class="headerlink" title="3.8 docker on centos7配置"></a>3.8 docker on centos7配置</h4><p>centos7使用systemd来管理服务，docker配置文件<code>/lib/systemd/system/docker.service</code>。比如增加tcp api端口，修改</p><pre><code>ExecStart=/usr/bin/dockerdExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --insecure-registry catalog.shurenyun.com</code></pre>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Why react?</title>
      <link href="/why-react/"/>
      <url>/why-react/</url>
      <content type="html"><![CDATA[<p>昨天给朋友推荐了<code>React</code>，但心里还真没有底，这里整理下资料，如果不考虑浏览器兼容性的问题，这东东真不错😄。</p><h4 id="1-虚拟dom是什么？"><a href="#1-虚拟dom是什么？" class="headerlink" title="1. 虚拟dom是什么？"></a>1. 虚拟dom是什么？</h4><p>虚拟DOM是HTML DOM的抽象，它和浏览器的实现分离。</p><h4 id="2-为什么虚拟dom快？"><a href="#2-为什么虚拟dom快？" class="headerlink" title="2. 为什么虚拟dom快？"></a>2. 为什么虚拟dom快？</h4><p>DOM拖慢JavaScript。所有的DOM操作都是同步的，会堵塞浏览器。JavaScript操作DOM时，必须等前一个操作结束，才能执行后一个操作。只要一个操作有卡顿，整个网页就会短暂失去响应。浏览器重绘网页的频率是60FPS（即16毫秒/帧），JavaScript做不到在16毫秒内完成DOM操作，因此产生了跳帧。虚拟dom的改变并不会引起浏览器dom的改变，而是由React在合适的时机比较差异并渲染，保证<code>FPS</code>。</p><h4 id="3-Why-is-React’s-concept-of-Virtual-DOM-said-to-be-more-performant-than-dirty-model-checking"><a href="#3-Why-is-React’s-concept-of-Virtual-DOM-said-to-be-more-performant-than-dirty-model-checking" class="headerlink" title="3. Why is React’s concept of Virtual DOM said to be more performant than dirty model checking?"></a>3. Why is React’s concept of Virtual DOM said to be more performant than dirty model checking?</h4><p>React knows when to re-render the scene because it is able to <strong>observe when this data changes</strong>. Dirty checking is slower than observables because you must poll the data at a regular interval and check all of the values in the data structure recursively. By comparison, setting a value on the state will signal to a listener that some state has changed, so React can simply listen for change events on the state and queue up re-rendering.(这点随着es6的<code>Proxy</code>到来，<code>AngularJS</code>会越来越强大😄)</p><h4 id="4-What-makes-React-fast"><a href="#4-What-makes-React-fast" class="headerlink" title="4. What makes React fast ?"></a>4. What makes React fast ?</h4><ul><li>Batched DOM read/write operations.</li><li>Efficient update of sub-tree only.</li></ul><p>Compared to dirty-check, the key differences IMO are:</p><p>Model dirty-checking: React component is explicitly set as dirty whenever setState is called, so there’s no comparison (of the data) needed here. For dirty-checking, the comparison (of the models) always happen each digest loop.</p><p>DOM updating: DOM operations are very expensive because modifying the DOM will also apply and calculate CSS styles, layouts. The saved time from unnecessary DOM modification can be longer than the time spent diffing the virtual DOM.</p><h4 id="4-What’s-the-problem-of-template-engine？"><a href="#4-What’s-the-problem-of-template-engine？" class="headerlink" title="4. What’s the problem of template engine？"></a>4. What’s the problem of template engine？</h4><p>Template languages express the initial render of your application, and you’re responsible for manually mutating the state of the UI when your backing data changes and events occur.</p><h4 id="5-how-to-run"><a href="#5-how-to-run" class="headerlink" title="5. how to run ?"></a>5. how to run ?</h4><p><img src="/why-react/reactjs.png" alt=""></p><p>上面部分是用户触发的，下面部分是定时触发的。</p><p>首先说上面部分：</p><ol><li>用户点击某dom</li><li><p><code>top-level event handler</code>分发事件到指定的<code>event handler</code></p><p> <code>top-level event handler</code>指的是<code>document</code>上的<code>event handler</code>,这种方式能够提高性能(因为在每个真实的dom上面绑定事件是非常慢的)并且跨浏览器(浏览器中的事件本身就没有统一)</p></li><li><p>用户代码调用setState()</p><p> <code>AngularJS</code>双向绑定，不需要用户调用状态变更。所以，必须要去做大量的<code>dirty check</code>。虽然是一种倒退，但是为了性能忍了，等ES6吧。</p></li></ol><p>下面部分的逻辑：<code>event loop</code>周期性的检查有状态组件是否<code>dirty</code>，然后通过<code>diff</code>算法批量更新浏览器dom树。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> react </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>don&#39;t worry, be happy!</title>
      <link href="/be-happy/"/>
      <url>/be-happy/</url>
      <content type="html"><![CDATA[<h3 id="情绪地雷区避雷方案："><a href="#情绪地雷区避雷方案：" class="headerlink" title="情绪地雷区避雷方案："></a>情绪地雷区避雷方案：</h3><ol><li>安排B计划 (比如等人吃饭，提前准备点事做，别人没到就做自己的事)</li><li>公开自己的情绪死穴 (比如提前给人说哪些是不喜欢的，如果你这样做了，我也避免不了我不发脾气)</li></ol><h3 id="情绪管理在生活与工作中的应用"><a href="#情绪管理在生活与工作中的应用" class="headerlink" title="情绪管理在生活与工作中的应用"></a>情绪管理在生活与工作中的应用</h3><ol><li><p>正向思考</p><p> 凡事往正面的角度去想，选取对自己最有利的注解</p></li><li><p>转移注意力</p><p> 去做能带来好情绪的活动或事情。比如吃自己最喜爱的食物</p></li><li><p>让开放的肢体动作带动情绪</p><p> 比如去爬山，去跑步，去旅游。</p></li><li><p>透过问句引导自己改变认知</p><pre><code>a.对方是故意的还是无心的？b.这件事还有没有其他角度与意义可以让我感觉更好？c.如果我希望自己的情绪变好，现在我应该做什么？d.这样做是真的会让情绪变好还是会有后遗症？e.我可以寻求谁的帮助来改善自己的情绪？</code></pre></li></ol><ol><li>发现自己情绪有失控的感觉或倾向，必要时离开现场</li><li>把不满、愤怒、失意等负面情绪写在纸上，然后烧掉、冲掉、寄出或者收藏</li><li>了解自身的有点，积极表现自己，但求尽心尽力</li><li>多看别人的好，适度予以宽容的对待</li><li><p>接近拥有心灵智慧的良师益友</p><p> 智慧不起烦恼，慈悲没有敌人</p></li><li><p>提醒自己：世间事都只是过程而非结果</p><p>每件事最终都会过去，包括我自己(凡人必有一死)</p></li><li><p>全力以赴后，放下得失心，因为你没有办法决定所有的事一定如你所愿</p><p>战胜对手只是人生的赢家，战胜自己才是命运的强者</p></li></ol><h3 id="哈佛大学推荐20个快乐的习惯"><a href="#哈佛大学推荐20个快乐的习惯" class="headerlink" title="哈佛大学推荐20个快乐的习惯"></a>哈佛大学推荐20个快乐的习惯</h3><ol><li><p>be grateful    (学会感恩)</p><p> 让自己变慢脚步，看看你的四周，关注生活中的细微之处：人行道上淡紫色的花，美丽的日落，洗去你一天疲惫的淋浴，伴侣眼中的笑容。当你的感恩之心能够欣赏生活的美，思考和祝福，你自然就充满了幸福感。</p></li><li><p>choose your friedns wisely</p><p> 如果你想变得开心的话，要选择和乐观的朋友在一起，他们能欣赏你真实的自己，让你的生活变得更丰富，快乐，有意义。</p></li><li><p>cultivate compassion (培养同情心)</p><p> 当我们代替别人，站在另一个角度看问题，我们更能用同情心，客观和有效的处理问题。生活中就会少一些冲突，多一点快乐。</p></li><li><p>keep leaning</p><p> 学习让我们保持年轻，梦想让我们充满活力。我们运用大脑，进行运作的时候，我们就不大会想不开心心的事情，我们会变得更开心和满足。</p></li><li><p>become a problem solver (学会解决问题)</p></li><li>do what you love</li><li><p>live in the present</p><p> 你感到沮丧，是因为你活在过去。你会感到担忧和焦虑，是因为你活在未来。但是当你感到满足，开心和平和时，你才是活在当下。</p></li><li><p>laugh often</p><p> 　笑是对抗生气或沮丧最有力的的东西。不要把生活看的太严肃。要学会在每日的奋斗中寻找幽默感和笑声。 　</p></li><li><p>practice forgiveness</p><p> 憎恨和生气是对自我的惩罚。当你释怀的时候，事实上你是在对自己施以善意。最重要的是，学会原谅自己。每个人都犯错。只有通过我们的错误，我们才慢慢学会如何成为一个更强大，更好的人。</p></li><li><p>say thanks often</p><p>对生活中的祝福要学会欣赏。向那些让你生活变好的人，无论或大或小，表达出你的欣赏之情也同样重要。</p></li><li><p>create deeper connections （学会深交）</p><p>我们的幸福感会在和另一个人的深交中不断猛增。专注聆听是加强这种关系纽带和把幸福感带给自己和别人的两个最重要的方面。</p></li><li><p>keep you agreement</p><p>我们的自尊是建立在我们对自己守承诺的情况下。高度的自尊和幸福感有直接关联。所以要对自己和别人遵守承诺。</p></li><li><p>meditate （冥想）</p></li><li><p>focus on what you’re doing</p><p>当你全身心投入一件事的时候，你就会处于一个开心的状态。当我们处于这种状态，你就不大会关心别人对你怎么看，不大会被不大重要的事情干扰。结果呢？更幸福，当然啦！</p></li><li><p>be optimistic</p><p>对于开心的人来说，玻璃都一直是半满的。每当你面对一个挑战时，如果你倾向于想象最坏的想法，那就自我转换这种情况。告诉你自己一个状况中的好处或者你从中学到的东西。乐观肯定能驱动成功和幸福感。</p></li><li><p>love unconditionally</p><p>没人是完美的,接受你自己所有的不完美,也要这样对待别人。无条件的爱一个人并不意味着你要花所有的时间和他们在一起，或者帮助他们解决问题。无条件的爱意味着接受真实的他们，以他们自己的步伐，让他们自己摸索。</p></li><li><p>don’t give up</p><p>没有完成的方案和不断的失败不可避免的会削弱你的自尊。如果你决定做某事，做完它。</p></li><li><p>do you best and then let go</p><p>每个人都有局限性。而且有时候尽管我们很努力做一件事情，但是总会事与愿违。所以做最好的自己，然后放手。当你尽了全力，你就没有遗憾了。</p></li><li><p>take care of yourself</p><p>一个健康的身体是幸福的关键。如果你身体不好，你无论如何努力，都很难快乐。确信自己吃得好，做锻炼，找点时间休息。好好照顾你的身体，大脑和精神。</p></li><li><p>give back （学会给予）</p><p>做好事是最能确保你心情好的方法之一。根据哈佛，人们做好事，他们的大脑变得活跃，就好像当你经历别的奖励时，大脑所受的刺激。所以，那些关心别人的人要比不大关心别人的人更开心。</p></li></ol>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> be happy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2015年11月Reading Notes</title>
      <link href="/2015-11-reading-notes/"/>
      <url>/2015-11-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Next-Generation-Session-Management-with-Spring-Session"><a href="#Next-Generation-Session-Management-with-Spring-Session" class="headerlink" title="Next Generation Session Management with Spring Session"></a><a name="spring-session">Next Generation Session Management with Spring Session</a></h2><p><a href="http://www.infoq.com/articles/Next-Generation-Session-Management-with-Spring-Session" target="_blank" rel="noopener">http://www.infoq.com/articles/Next-Generation-Session-Management-with-Spring-Session</a></p><p>在大规模集群的场景，无状态的应用能减少运维成本、缩短应用恢复时间。spring session主要解决了web应用session持久化的问题。把session存储在应用外部，让应用无状态。</p><p>spring session主要提供如下能力：</p><ol><li>把session的存储逻辑抽取出来，可以选择rdis，或者自己实现session存储</li><li>使用websocket也能保持会话</li><li>非web应用也能使用会话</li><li>支持多个session(可以登陆多个用户)</li><li>Restful API也能通过http header维护会话</li></ol><p>spring session 1.1版本支持<code>HttpSessionListener</code>.如果使用的redis，spring session通过key过期时的过期事件+redis消息推送来实现。可惜我们用的是<code>codis</code>，我们实现了<code>DisabledRedisMessageListenerContainer</code>把这个能力屏蔽了。</p><p>更多参考：<a href="http://docs.spring.io/spring-session/docs/current-SNAPSHOT/reference/html5/#introduction" target="_blank" rel="noopener">spring session 官方文档</a> <a href="https://github.com/spring-projects/spring-session/issues/4" target="_blank" rel="noopener">Add HttpSessionListener Support</a></p><h2 id="The-Twelve-Factor-App"><a href="#The-Twelve-Factor-App" class="headerlink" title="The Twelve-Factor App"></a><a name="the-twelve-factor-app">The Twelve-Factor App</a></h2><p><a href="http://12factor.net" target="_blank" rel="noopener">http://12factor.net</a></p><p>The twelve-factor app is a methodology for building software-as-a-service apps.</p><ol><li><p>Codebase:One codebase tracked in revision control, many deploys</p><p> one codebase per app（all tracked in revision control）, but there will be many deploys of the app(one or more staging use same code,use multi config file or configuration management system for different stage ). </p></li><li><p>Dependencies:Explicitly declare and isolate dependencies</p><p>  declares all dependencies via a dependency declaration manifest,and use dependencies check strategy to ensure that no implicit dependencies.</p></li><li><p>Config:Store config in the environment</p><p> use mutli config file （<a href="http://bohr.me/env-aware/">build env-awared app</a>）     or use configuration management system （<a href="http://cloud.spring.io/spring-cloud-config/" target="_blank" rel="noopener">spring cloud config</a>）</p></li><li><p>Backing Services:Treat backing services as attached resources</p><p> app makes no distinction between local and third party services（both are attached resources）. A deploy should be able to swap out a local MySQL database with one managed by a third party (such as Amazon RDS) without any changes to the app’s code. </p></li><li><p>Build, release, run:Strictly separate build and run stages</p><p> app uses strict separation between the build, release, and run stages. For example, it is impossible to make changes to the code at runtime, since there is no way to propagate those changes back to the build stage（we can put dynamic part code into db ）.</p></li><li><p>Processes:Execute the app as one or more stateless processes</p><p> Twelve-factor processes are stateless and share-nothing. Any data that needs to persist must be stored in a stateful backing service, typically a database.Sticky sessions should never be used or relied upon. </p></li><li><p>Port binding:Export services via port binding</p><p> The twelve-factor app is completely self-contained and does not rely on runtime injection of a webserver into the execution environment to create a web-facing service. The web app exports HTTP as a service by binding to a port, and listening to requests coming in on that port.</p></li><li><p>Concurrency:Scale out via the process model</p><p>processes are a first class citizen.Processes in the twelve-factor app take strong cues from the unix process model for running service daemons. Using this model, the developer can architect their app to handle diverse workloads by assigning each type of work to a process type.</p></li><li><p>Disposability:Maximize robustness with fast startup and graceful shutdown</p><p> Processes should strive to minimize startup time.</p><p> Processes shut down gracefully （ ceasing to listen on the service port,thereby refusing any new requests, allowing any current requests to finish, and then exiting.）when they receive a SIGTERM signal from the process manager.</p><p> For a worker process, graceful shutdown is achieved by <strong>returning the current job to the work queue</strong>.Implicit in this model is that all jobs are <strong>reentrant</strong>, which typically is achieved by wrapping the results in a transaction, or making the operation <code>idempotent</code>.</p><p> Processes should also be robust against sudden death, in the case of a failure in the underlying hardware.  A recommended approach is use of a robust queueing backend that returns jobs to the queue when clients disconnect or time out. Either way, a twelve-factor app is architected to handle unexpected, non-graceful terminations. </p></li><li><p>Dev/prod parity:Keep development, staging, and production as similar as possible</p></li></ol><pre><code>  x      | Traditional app           | Twelve-factor app     |--------------------|------------------|-----------------------|Time between deploys | Weeks   | Hours   |Code authors vs code deployers  | Different people | Same people  |Dev vs production environments  | Divergent | As similar as possible  |The twelve-factor developer resists the urge to use different backing services between development and production, even when adapters theoretically abstract away any differences in backing services.</code></pre><ol><li><p>Logs:Treat logs as event streams</p><p>A twelve-factor app never concerns itself with routing or storage of its output stream(maybe dont fit for java app).</p></li><li><p>Admin processes:Run admin/management tasks as one-off processes</p><p>One-off admin processes should be run in an identical environment as the regular long-running processes of the app. They run against a release, using the same codebase and config as any process run against that release. Admin code must ship with application code to avoid synchronization issues.</p></li></ol>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> spring-session </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2015年05月Reading Notes</title>
      <link href="/2015-05-reading-notes/"/>
      <url>/2015-05-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="使用spring-loaded提高开发效率"><a href="#使用spring-loaded提高开发效率" class="headerlink" title="使用spring loaded提高开发效率"></a><a name="springloaded">使用spring loaded提高开发效率</a></h2><p><a href="https://github.com/spring-projects/spring-loaded" target="_blank" rel="noopener">spring-loaded</a>和<a href="http://zeroturnaround.com/software/jrebel/" target="_blank" rel="noopener">jrebel</a>类似，它能发现您修改的类并重新加载。在开发测试时，您只需要使用它启动后，就可以一直写代码了。jrebel是收费的软件，spring-loaded免费，而且他很了解您代码中用到的spring特性，能很智能的帮忙重新加载类，并把bean注册到spring容器中。</p><p>使用很简单，参考下面的步骤：</p><ol><li>下载<a href="http://repo.spring.io/simple/libs-release-local/org/springframework/springloaded/1.2.3.RELEASE/springloaded-1.2.3.RELEASE.jar" target="_blank" rel="noopener">springloaded</a></li><li><p>配置IDEA</p><ul><li>打开<code>Run/Debug Configuations</code>,在<code>Defaults</code>中选择<code>Application</code></li><li><p>在右边的<code>Configuration</code> tab中配置<code>VM options</code></p><pre><code>-javaagent:/Users/bohr/software/springloaded/springloaded-1.2.3.RELEASE.jar -noverify</code></pre><p>有了此默认配置，一劳永逸。上面的路径地址修改为您保存springloaded的路径</p></li></ul></li><li>执行任何java类</li><li>修改后，编译此java类就能看到修改后的效果了。</li></ol>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> springloaded </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2015年02月Reading Notes</title>
      <link href="/2015-02-reading-notes/"/>
      <url>/2015-02-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Java-Lambdas-and-Low-Latency"><a href="#Java-Lambdas-and-Low-Latency" class="headerlink" title="Java Lambdas and Low Latency"></a>Java Lambdas and Low Latency</h2><p><a href="http://vanillajava.blogspot.hk/2015/01/java-lambdas-and-low-latency.html" target="_blank" rel="noopener">http://vanillajava.blogspot.hk/2015/01/java-lambdas-and-low-latency.html</a></p><p> <code>Lambdas</code>创建了新对象，在低延迟应用中会给<code>gc</code>带来一点点压力。<a href="http://docs.oracle.com/javase/7/docs/technotes/guides/vm/performance-enhancements-7.html" target="_blank" rel="noopener">Escape Analysis</a>(分析对象的使用范围，来做性能优化，比如锁消除，消除对象分配…)能减少这种压力。可以通过jvm参考<code>-XX:BCEATraceLevel=3</code>查看逃逸分析情况，进一步设置<code>-XX:MaxBCEAEstimateSize</code>来调整<code>Maximum bytecode size of a method to be analyzed by BC EA.</code></p><h2 id="Catch-common-Java-mistakes-as-compile-time-errors"><a href="#Catch-common-Java-mistakes-as-compile-time-errors" class="headerlink" title="Catch common Java mistakes as compile-time errors"></a>Catch common Java mistakes as compile-time errors</h2><p><a href="http://errorprone.info/" target="_blank" rel="noopener">http://errorprone.info/</a></p><p>静态代码分析工具又添一员，在编译时检查常见的java代码错误。在jdk8下貌似run不起来。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Google Java编程风格指南</title>
      <link href="/google-java-style/"/>
      <url>/google-java-style/</url>
      <content type="html"><![CDATA[<p>作者：Hawstein</p><p>出处：<a href="http://hawstein.com/posts/google-java-style.html" target="_blank" rel="noopener">http://hawstein.com/posts/google-java-style.html</a></p><p>转载说明：N个月前看到<a href="http://google-styleguide.googlecode.com/svn/trunk/javaguide.html" target="_blank" rel="noopener">Google Java Style</a>,大致扫了下，自认为命名都比较规范了。今天在整理依赖时，看到junit最新版本的release note中提到junit的代码按照<a href="http://google-styleguide.googlecode.com/svn/trunk/javaguide.html" target="_blank" rel="noopener">Google Java Style</a> fix了一遍。无意中感觉可能我也做得不够好，仔细看看文档，发现有个地方写的非常明确，值得参考。转载这篇中文翻译文章方便大家查看。</p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol><li><a href="#Intro">前言</a></li><li><a href="#SFBasic">源文件基础</a></li><li><a href="#SFStruct">源文件结构</a></li><li><a href="#Format">格式</a></li><li><a href="#Naming">命名约定</a></li><li><a href="#Practice">编程实践</a></li><li><a href="#Javadoc">Javadoc</a></li><li><a href="#End">后记</a></li></ol><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><a id="Intro">前言</a></h2><p>这份文档是Google Java编程风格规范的完整定义。当且仅当一个Java源文件符合此文档中的规则，<br>我们才认为它符合Google的Java编程风格。</p><p>与其它的编程风格指南一样，这里所讨论的不仅仅是编码格式美不美观的问题，<br>同时也讨论一些约定及编码标准。然而，这份文档主要侧重于我们所普遍遵循的规则，<br>对于那些不是明确强制要求的，我们尽量避免提供意见。</p><h3 id="1-1-术语说明"><a href="#1-1-术语说明" class="headerlink" title="1.1 术语说明"></a>1.1 术语说明</h3><p>在本文档中，除非另有说明：</p><ol><li>术语class可表示一个普通类，枚举类，接口或是annotation类型(<code>@interface</code>)</li><li>术语comment只用来指代实现的注释(implementation comments)，我们不使用“documentation comments”一词，而是用Javadoc。</li></ol><p>其他的术语说明会偶尔在后面的文档出现。</p><h3 id="1-2-指南说明"><a href="#1-2-指南说明" class="headerlink" title="1.2 指南说明"></a>1.2 指南说明</h3><p>本文档中的示例代码并不作为规范。也就是说，虽然示例代码是遵循Google编程风格，但并不意味着这是展现这些代码的唯一方式。<br>示例中的格式选择不应该被强制定为规则。</p><h2 id="源文件基础"><a href="#源文件基础" class="headerlink" title="源文件基础"></a><a id="SFBasic">源文件基础</a></h2><h3 id="2-1-文件名"><a href="#2-1-文件名" class="headerlink" title="2.1 文件名"></a>2.1 文件名</h3><p>源文件以其最顶层的类名来命名，大小写敏感，文件扩展名为<code>.java</code>。</p><h3 id="2-2-文件编码：UTF-8"><a href="#2-2-文件编码：UTF-8" class="headerlink" title="2.2 文件编码：UTF-8"></a>2.2 文件编码：UTF-8</h3><p>源文件编码格式为UTF-8。</p><h3 id="2-3-特殊字符"><a href="#2-3-特殊字符" class="headerlink" title="2.3 特殊字符"></a>2.3 特殊字符</h3><h4 id="2-3-1-空白字符"><a href="#2-3-1-空白字符" class="headerlink" title="2.3.1 空白字符"></a>2.3.1 空白字符</h4><p>除了行结束符序列，ASCII水平空格字符(0x20，即空格)是源文件中唯一允许出现的空白字符，这意味着：</p><ol><li>所有其它字符串中的空白字符都要进行转义。</li><li>制表符不用于缩进。</li></ol><h4 id="2-3-2-特殊转义序列"><a href="#2-3-2-特殊转义序列" class="headerlink" title="2.3.2 特殊转义序列"></a>2.3.2 特殊转义序列</h4><p>对于具有特殊<a href="http://zh.wikipedia.org/wiki/%E8%BD%AC%E4%B9%89%E5%BA%8F%E5%88%97" target="_blank" rel="noopener">转义序列</a>的任何字符(\b, \t, \n, \f, \r, \”, \’及\)，我们使用它的转义序列，而不是相应的八进制(比如<code>\012</code>)或Unicode(比如<code>\u000a</code>)转义。</p><h4 id="2-3-3-非ASCII字符"><a href="#2-3-3-非ASCII字符" class="headerlink" title="2.3.3 非ASCII字符"></a>2.3.3 非ASCII字符</h4><p>对于剩余的非ASCII字符，是使用实际的Unicode字符(比如∞)，还是使用等价的Unicode转义符(比如\u221e)，取决于哪个能让代码更易于阅读和理解。</p><blockquote><blockquote><p>Tip: 在使用Unicode转义符或是一些实际的Unicode字符时，建议做些注释给出解释，这有助于别人阅读和理解。</p></blockquote></blockquote><p>例如：</p><pre><code>String unitAbbrev = &quot;μs&quot;;                                 | 赞，即使没有注释也非常清晰String unitAbbrev = &quot;\u03bcs&quot;; // &quot;μs&quot;                    | 允许，但没有理由要这样做String unitAbbrev = &quot;\u03bcs&quot;; // Greek letter mu, &quot;s&quot;    | 允许，但这样做显得笨拙还容易出错String unitAbbrev = &quot;\u03bcs&quot;;                            | 很糟，读者根本看不出这是什么return &apos;\ufeff&apos; + content; // byte order mark             | Good，对于非打印字符，使用转义，并在必要时写上注释</code></pre><blockquote><blockquote><p>Tip: 永远不要由于害怕某些程序可能无法正确处理非ASCII字符而让你的代码可读性变差。当程序无法正确处理非ASCII字符时，它自然无法正确运行，<br>你就会去fix这些问题的了。(言下之意就是大胆去用非ASCII字符，如果真的有需要的话)</p></blockquote></blockquote><h2 id="源文件结构"><a href="#源文件结构" class="headerlink" title="源文件结构"></a><a id="SFStruct">源文件结构</a></h2><p>一个源文件包含(按顺序地)：</p><ol><li>许可证或版权信息(如有需要)</li><li>package语句</li><li>import语句</li><li>一个顶级类(<strong>只有一个</strong>)</li></ol><p>以上每个部分之间用一个空行隔开。</p><h3 id="3-1-许可证或版权信息"><a href="#3-1-许可证或版权信息" class="headerlink" title="3.1 许可证或版权信息"></a>3.1 许可证或版权信息</h3><p>如果一个文件包含许可证或版权信息，那么它应当被放在文件最前面。</p><h3 id="3-2-package语句"><a href="#3-2-package语句" class="headerlink" title="3.2 package语句"></a>3.2 package语句</h3><p>package语句不换行，列限制(4.4节)并不适用于package语句。(即package语句写在一行里)</p><h3 id="3-3-import语句"><a href="#3-3-import语句" class="headerlink" title="3.3 import语句"></a>3.3 import语句</h3><h4 id="3-3-1-import不要使用通配符"><a href="#3-3-1-import不要使用通配符" class="headerlink" title="3.3.1 import不要使用通配符"></a>3.3.1 import不要使用通配符</h4><p>即，不要出现类似这样的import语句：<code>import java.util.*;</code></p><h4 id="3-3-2-不要换行"><a href="#3-3-2-不要换行" class="headerlink" title="3.3.2 不要换行"></a>3.3.2 不要换行</h4><p>import语句不换行，列限制(4.4节)并不适用于import语句。(每个import语句独立成行)</p><h4 id="3-3-3-顺序和间距"><a href="#3-3-3-顺序和间距" class="headerlink" title="3.3.3 顺序和间距"></a>3.3.3 顺序和间距</h4><p>import语句可分为以下几组，按照这个顺序，每组由一个空行分隔：</p><ol><li>所有的静态导入独立成组</li><li><code>com.google</code> imports(仅当这个源文件是在<code>com.google</code>包下)</li><li>第三方的包。每个顶级包为一组，字典序。例如：android, com, junit, org, sun</li><li><code>java</code> imports</li><li><code>javax</code> imports</li></ol><p>组内不空行，按字典序排列。</p><h3 id="3-4-类声明"><a href="#3-4-类声明" class="headerlink" title="3.4 类声明"></a>3.4 类声明</h3><h4 id="3-4-1-只有一个顶级类声明"><a href="#3-4-1-只有一个顶级类声明" class="headerlink" title="3.4.1 只有一个顶级类声明"></a>3.4.1 只有一个顶级类声明</h4><p>每个顶级类都在一个与它同名的源文件中(当然，还包含<code>.java</code>后缀)。</p><p>例外：<code>package-info.java</code>，该文件中可没有<code>package-info</code>类。</p><h4 id="3-4-2-类成员顺序"><a href="#3-4-2-类成员顺序" class="headerlink" title="3.4.2 类成员顺序"></a>3.4.2 类成员顺序</h4><p>类的成员顺序对易学性有很大的影响，但这也不存在唯一的通用法则。不同的类对成员的排序可能是不同的。<br>最重要的一点，每个类应该以某种逻辑去排序它的成员，维护者应该要能解释这种排序逻辑。比如，<br>新的方法不能总是习惯性地添加到类的结尾，因为这样就是按时间顺序而非某种逻辑来排序的。</p><h5 id="3-4-2-1-重载：永不分离"><a href="#3-4-2-1-重载：永不分离" class="headerlink" title="3.4.2.1 重载：永不分离"></a>3.4.2.1 重载：永不分离</h5><p>当一个类有多个构造函数，或是多个同名方法，这些函数/方法应该按顺序出现在一起，中间不要放进其它函数/方法。</p><h2 id="格式"><a href="#格式" class="headerlink" title="格式"></a><a id="Format">格式</a></h2><p><strong>术语说明</strong>：块状结构(block-like construct)指的是一个类，方法或构造函数的主体。需要注意的是，数组初始化中的初始值可被选择性地视为块状结构(4.8.3.1节)。</p><h3 id="4-1-大括号"><a href="#4-1-大括号" class="headerlink" title="4.1 大括号"></a>4.1 大括号</h3><h4 id="4-1-1-使用大括号-即使是可选的"><a href="#4-1-1-使用大括号-即使是可选的" class="headerlink" title="4.1.1 使用大括号(即使是可选的)"></a>4.1.1 使用大括号(即使是可选的)</h4><p>大括号与<code>if, else, for, do, while</code>语句一起使用，即使只有一条语句(或是空)，也应该把大括号写上。</p><h4 id="4-1-2-非空块：K-amp-R-风格"><a href="#4-1-2-非空块：K-amp-R-风格" class="headerlink" title="4.1.2 非空块：K &amp; R 风格"></a>4.1.2 非空块：K &amp; R 风格</h4><p>对于非空块和块状结构，大括号遵循Kernighan和Ritchie风格<br>(<a href="http://www.codinghorror.com/blog/2012/07/new-programming-jargon.html" target="_blank" rel="noopener">Egyptian brackets</a>):</p><ul><li>左大括号前不换行</li><li>左大括号后换行</li><li>右大括号前换行</li><li>如果右大括号是一个语句、函数体或类的终止，则右大括号后换行; 否则不换行。例如，如果右大括号后面是else或逗号，则不换行。</li></ul><p>示例：</p><pre><code>return new MyClass() {  @Override public void method() {    if (condition()) {      try {        something();      } catch (ProblemException e) {        recover();      }    }  }};</code></pre><p>4.8.1节给出了enum类的一些例外。</p><h4 id="4-1-3-空块：可以用简洁版本"><a href="#4-1-3-空块：可以用简洁版本" class="headerlink" title="4.1.3 空块：可以用简洁版本"></a>4.1.3 空块：可以用简洁版本</h4><p>一个空的块状结构里什么也不包含，大括号可以简洁地写成<code>{}</code>，不需要换行。例外：如果它是一个多块语句的一部分(if/else 或 try/catch/finally)<br>，即使大括号内没内容，右大括号也要换行。</p><p>示例：</p><pre><code>void doNothing() {}</code></pre><h3 id="4-2-块缩进：2个空格"><a href="#4-2-块缩进：2个空格" class="headerlink" title="4.2 块缩进：2个空格"></a>4.2 块缩进：2个空格</h3><p>每当开始一个新的块，缩进增加2个空格，当块结束时，缩进返回先前的缩进级别。缩进级别适用于代码和注释。(见4.1.2节中的代码示例)</p><h3 id="4-3-一行一个语句"><a href="#4-3-一行一个语句" class="headerlink" title="4.3 一行一个语句"></a>4.3 一行一个语句</h3><p>每个语句后要换行。</p><h3 id="4-4-列限制：80或100"><a href="#4-4-列限制：80或100" class="headerlink" title="4.4 列限制：80或100"></a>4.4 列限制：80或100</h3><p>一个项目可以选择一行80个字符或100个字符的列限制，除了下述例外，任何一行如果超过这个字符数限制，必须自动换行。</p><p>例外：</p><ol><li>不可能满足列限制的行(例如，Javadoc中的一个长URL，或是一个长的JSNI方法参考)。</li><li><code>package</code>和<code>import</code>语句(见3.2节和3.3节)。</li><li>注释中那些可能被剪切并粘贴到shell中的命令行。</li></ol><h3 id="4-5-自动换行"><a href="#4-5-自动换行" class="headerlink" title="4.5 自动换行"></a>4.5 自动换行</h3><p><strong>术语说明</strong>：一般情况下，一行长代码为了避免超出列限制(80或100个字符)而被分为多行，我们称之为自动换行(line-wrapping)。</p><p>我们并没有全面，确定性的准则来决定在每一种情况下如何自动换行。很多时候，对于同一段代码会有好几种有效的自动换行方式。</p><blockquote><blockquote><p>Tip: 提取方法或局部变量可以在不换行的情况下解决代码过长的问题(是合理缩短命名长度吧)</p></blockquote></blockquote><h4 id="4-5-1-从哪里断开"><a href="#4-5-1-从哪里断开" class="headerlink" title="4.5.1 从哪里断开"></a>4.5.1 从哪里断开</h4><p>自动换行的基本准则是：更倾向于在更高的语法级别处断开。</p><ol><li>如果在<code>非赋值运算符</code>处断开，那么在该符号前断开(比如+，它将位于下一行)。注意：这一点与Google其它语言的编程风格不同(如C++和JavaScript)。<br>这条规则也适用于以下“类运算符”符号：点分隔符(.)，类型界限中的&amp;（<code>&lt;T extends Foo &amp; Bar&gt;</code>)，catch块中的管道符号(<code>catch (FooException | BarException e</code>)</li><li>如果在<code>赋值运算符</code>处断开，通常的做法是在该符号后断开(比如=，它与前面的内容留在同一行)。这条规则也适用于<code>foreach</code>语句中的分号。</li><li>方法名或构造函数名与左括号留在同一行。</li><li>逗号(,)与其前面的内容留在同一行。</li></ol><h4 id="4-5-2-自动换行时缩进至少-4个空格"><a href="#4-5-2-自动换行时缩进至少-4个空格" class="headerlink" title="4.5.2 自动换行时缩进至少+4个空格"></a>4.5.2 自动换行时缩进至少+4个空格</h4><p>自动换行时，第一行后的每一行至少比第一行多缩进4个空格(注意：制表符不用于缩进。见2.3.1节)。</p><p>当存在连续自动换行时，缩进可能会多缩进不只4个空格(语法元素存在多级时)。一般而言，两个连续行使用相同的缩进当且仅当它们开始于同级语法元素。</p><p>第4.6.3水平对齐一节中指出，不鼓励使用可变数目的空格来对齐前面行的符号。</p><h3 id="4-6-空白"><a href="#4-6-空白" class="headerlink" title="4.6 空白"></a>4.6 空白</h3><h4 id="4-6-1-垂直空白"><a href="#4-6-1-垂直空白" class="headerlink" title="4.6.1 垂直空白"></a>4.6.1 垂直空白</h4><p>以下情况需要使用一个空行：</p><ol><li>类内连续的成员之间：字段，构造函数，方法，嵌套类，静态初始化块，实例初始化块。<ul><li><strong>例外</strong>：两个连续字段之间的空行是可选的，用于字段的空行主要用来对字段进行逻辑分组。</li></ul></li><li>在函数体内，语句的逻辑分组间使用空行。</li><li>类内的第一个成员前或最后一个成员后的空行是可选的(既不鼓励也不反对这样做，视个人喜好而定)。</li><li>要满足本文档中其他节的空行要求(比如3.3节：import语句)</li></ol><p>多个连续的空行是允许的，但没有必要这样做(我们也不鼓励这样做)。</p><h4 id="4-6-2-水平空白"><a href="#4-6-2-水平空白" class="headerlink" title="4.6.2 水平空白"></a>4.6.2 水平空白</h4><p>除了语言需求和其它规则，并且除了文字，注释和Javadoc用到单个空格，单个ASCII空格也出现在以下几个地方：</p><ol><li>分隔任何保留字与紧随其后的左括号(<code>(</code>)(如<code>if, for catch</code>等)。</li><li>分隔任何保留字与其前面的右大括号(<code>}</code>)(如<code>else, catch</code>)。</li><li>在任何左大括号前(<code>{</code>)，两个例外：<ul><li><code>@SomeAnnotation({a, b})</code>(不使用空格)。</li><li><code>String[][] x = foo;</code>(大括号间没有空格，见下面的Note)。</li></ul></li><li>在任何二元或三元运算符的两侧。这也适用于以下“类运算符”符号：<ul><li>类型界限中的&amp;(<code>&lt;T extends Foo &amp; Bar&gt;</code>)。</li><li>catch块中的管道符号(<code>catch (FooException | BarException e</code>)。</li><li><code>foreach</code>语句中的分号。</li></ul></li><li>在<code>, : ;</code>及右括号(<code>)</code>)后</li><li>如果在一条语句后做注释，则双斜杠(//)两边都要空格。这里可以允许多个空格，但没有必要。</li><li>类型和变量之间：List<string> list。</string></li><li>数组初始化中，大括号内的空格是可选的，即<code>new int[] {5, 6}</code>和<code>new int[] { 5, 6 }</code>都是可以的。</li></ol><blockquote><blockquote><p>Note：这个规则并不要求或禁止一行的开关或结尾需要额外的空格，只对内部空格做要求。</p></blockquote></blockquote><h4 id="4-6-3-水平对齐：不做要求"><a href="#4-6-3-水平对齐：不做要求" class="headerlink" title="4.6.3 水平对齐：不做要求"></a>4.6.3 水平对齐：不做要求</h4><p><strong>术语说明</strong>：水平对齐指的是通过增加可变数量的空格来使某一行的字符与上一行的相应字符对齐。</p><p>这是允许的(而且在不少地方可以看到这样的代码)，但Google编程风格对此不做要求。即使对于已经使用水平对齐的代码，我们也不需要去保持这种风格。</p><p>以下示例先展示未对齐的代码，然后是对齐的代码：</p><p>private int x; // this is fine<br>private Color color; // this too</p><p>private int   x;      // permitted, but future edits<br>private Color color;  // may leave it unaligned</p><blockquote><blockquote><p>Tip：对齐可增加代码可读性，但它为日后的维护带来问题。考虑未来某个时候，我们需要修改一堆对齐的代码中的一行。<br>这可能导致原本很漂亮的对齐代码变得错位。很可能它会提示你调整周围代码的空白来使这一堆代码重新水平对齐(比如程序员想保持这种水平对齐的风格)，<br>这就会让你做许多的无用功，增加了reviewer的工作并且可能导致更多的合并冲突。</p></blockquote></blockquote><h3 id="4-7-用小括号来限定组：推荐"><a href="#4-7-用小括号来限定组：推荐" class="headerlink" title="4.7 用小括号来限定组：推荐"></a>4.7 用小括号来限定组：推荐</h3><p>除非作者和reviewer都认为去掉小括号也不会使代码被误解，或是去掉小括号能让代码更易于阅读，否则我们不应该去掉小括号。<br>我们没有理由假设读者能记住整个Java运算符优先级表。</p><h3 id="4-8-具体结构"><a href="#4-8-具体结构" class="headerlink" title="4.8 具体结构"></a>4.8 具体结构</h3><h4 id="4-8-1-枚举类"><a href="#4-8-1-枚举类" class="headerlink" title="4.8.1 枚举类"></a>4.8.1 枚举类</h4><p>枚举常量间用逗号隔开，换行可选。</p><p>没有方法和文档的枚举类可写成数组初始化的格式：</p><pre><code>private enum Suit { CLUBS, HEARTS, SPADES, DIAMONDS }</code></pre><p>由于枚举类也是一个类，因此所有适用于其它类的格式规则也适用于枚举类。</p><h4 id="4-8-2-变量声明"><a href="#4-8-2-变量声明" class="headerlink" title="4.8.2 变量声明"></a>4.8.2 变量声明</h4><h5 id="4-8-2-1-每次只声明一个变量"><a href="#4-8-2-1-每次只声明一个变量" class="headerlink" title="4.8.2.1 每次只声明一个变量"></a>4.8.2.1 每次只声明一个变量</h5><p>不要使用组合声明，比如<code>int a, b;</code>。</p><h5 id="4-8-2-2-需要时才声明，并尽快进行初始化"><a href="#4-8-2-2-需要时才声明，并尽快进行初始化" class="headerlink" title="4.8.2.2 需要时才声明，并尽快进行初始化"></a>4.8.2.2 需要时才声明，并尽快进行初始化</h5><p>不要在一个代码块的开头把局部变量一次性都声明了(这是c语言的做法)，而是在第一次需要使用它时才声明。<br>局部变量在声明时最好就进行初始化，或者声明后尽快进行初始化。</p><h4 id="4-8-3-数组"><a href="#4-8-3-数组" class="headerlink" title="4.8.3 数组"></a>4.8.3 数组</h4><h5 id="4-8-3-1-数组初始化：可写成块状结构"><a href="#4-8-3-1-数组初始化：可写成块状结构" class="headerlink" title="4.8.3.1 数组初始化：可写成块状结构"></a>4.8.3.1 数组初始化：可写成块状结构</h5><p>数组初始化可以写成块状结构，比如，下面的写法都是OK的：</p><pre><code>new int[] {  0, 1, 2, 3}new int[] {  0,  1,  2,  3}new int[] {  0, 1,  2, 3}new int[]    {0, 1, 2, 3}</code></pre><h5 id="4-8-3-2-非C风格的数组声明"><a href="#4-8-3-2-非C风格的数组声明" class="headerlink" title="4.8.3.2 非C风格的数组声明"></a>4.8.3.2 非C风格的数组声明</h5><p>中括号是类型的一部分：<code>String[] args</code>， 而非<code>String args[]</code>。</p><h4 id="4-8-4-switch语句"><a href="#4-8-4-switch语句" class="headerlink" title="4.8.4 switch语句"></a>4.8.4 switch语句</h4><p><strong>术语说明</strong>：switch块的大括号内是一个或多个语句组。每个语句组包含一个或多个switch标签(<code>case FOO:</code>或<code>default:</code>)，后面跟着一条或多条语句。</p><h5 id="4-8-4-1-缩进"><a href="#4-8-4-1-缩进" class="headerlink" title="4.8.4.1 缩进"></a>4.8.4.1 缩进</h5><p>与其它块状结构一致，switch块中的内容缩进为2个空格。</p><p>每个switch标签后新起一行，再缩进2个空格，写下一条或多条语句。</p><h5 id="4-8-4-2-Fall-through：注释"><a href="#4-8-4-2-Fall-through：注释" class="headerlink" title="4.8.4.2 Fall-through：注释"></a>4.8.4.2 Fall-through：注释</h5><p>在一个switch块内，每个语句组要么通过<code>break, continue, return</code>或抛出异常来终止，要么通过一条注释来说明程序将继续执行到下一个语句组，<br>任何能表达这个意思的注释都是OK的(典型的是用<code>// fall through</code>)。这个特殊的注释并不需要在最后一个语句组(一般是<code>default</code>)中出现。示例：</p><pre><code>switch (input) {  case 1:  case 2:    prepareOneOrTwo();    // fall through  case 3:    handleOneTwoOrThree();    break;  default:    handleLargeNumber(input);}</code></pre><h5 id="4-8-4-3-default的情况要写出来"><a href="#4-8-4-3-default的情况要写出来" class="headerlink" title="4.8.4.3 default的情况要写出来"></a>4.8.4.3 default的情况要写出来</h5><p>每个switch语句都包含一个<code>default</code>语句组，即使它什么代码也不包含。</p><h4 id="4-8-5-注解-Annotations"><a href="#4-8-5-注解-Annotations" class="headerlink" title="4.8.5 注解(Annotations)"></a>4.8.5 注解(Annotations)</h4><p>注解紧跟在文档块后面，应用于类、方法和构造函数，一个注解独占一行。这些换行不属于自动换行(第4.5节，自动换行)，因此缩进级别不变。例如：</p><pre><code>@Override@Nullablepublic String getNameIfPresent() { ... }</code></pre><p><strong>例外</strong>：单个的注解可以和签名的第一行出现在同一行。例如：</p><pre><code>@Override public int hashCode() { ... }</code></pre><p>应用于字段的注解紧随文档块出现，应用于字段的多个注解允许与字段出现在同一行。例如：</p><pre><code>@Partial @Mock DataLoader loader;</code></pre><p>参数和局部变量注解没有特定规则。</p><h4 id="4-8-6-注释"><a href="#4-8-6-注释" class="headerlink" title="4.8.6 注释"></a>4.8.6 注释</h4><h5 id="4-8-6-1-块注释风格"><a href="#4-8-6-1-块注释风格" class="headerlink" title="4.8.6.1 块注释风格"></a>4.8.6.1 块注释风格</h5><p>块注释与其周围的代码在同一缩进级别。它们可以是<code>/* ... */</code>风格，也可以是<code>// ...</code>风格。对于多行的<code>/* ... */</code>注释，后续行必须从<code>*</code>开始，<br>并且与前一行的<code>*</code>对齐。以下示例注释都是OK的。</p><pre><code>/* * This is          // And so           /* Or you can * okay.            // is this.          * even do this. */ */</code></pre><p>注释不要封闭在由星号或其它字符绘制的框架里。</p><blockquote><blockquote><p>Tip：在写多行注释时，如果你希望在必要时能重新换行(即注释像段落风格一样)，那么使用<code>/* ... */</code>。</p></blockquote></blockquote><h4 id="4-8-7-Modifiers"><a href="#4-8-7-Modifiers" class="headerlink" title="4.8.7 Modifiers"></a>4.8.7 Modifiers</h4><p>类和成员的modifiers如果存在，则按Java语言规范中推荐的顺序出现。</p><p>public protected private abstract static final transient volatile synchronized native strictfp</p><h2 id="命名约定"><a href="#命名约定" class="headerlink" title="命名约定"></a><a id="Naming">命名约定</a></h2><h3 id="5-1-对所有标识符都通用的规则"><a href="#5-1-对所有标识符都通用的规则" class="headerlink" title="5.1 对所有标识符都通用的规则"></a>5.1 对所有标识符都通用的规则</h3><p>标识符只能使用ASCII字母和数字，因此每个有效的标识符名称都能匹配正则表达式<code>\w+</code>。</p><p>在Google其它编程语言风格中使用的特殊前缀或后缀，如<code>name_</code>, <code>mName</code>, <code>s_name</code>和<code>kName</code>，在Java编程风格中都不再使用。</p><h3 id="5-2-标识符类型的规则"><a href="#5-2-标识符类型的规则" class="headerlink" title="5.2 标识符类型的规则"></a>5.2 标识符类型的规则</h3><h4 id="5-2-1-包名"><a href="#5-2-1-包名" class="headerlink" title="5.2.1 包名"></a>5.2.1 包名</h4><p>包名全部小写，连续的单词只是简单地连接起来，不使用下划线。</p><h4 id="5-2-2-类名"><a href="#5-2-2-类名" class="headerlink" title="5.2.2 类名"></a>5.2.2 类名</h4><p>类名都以<code>UpperCamelCase</code>风格编写。</p><p>类名通常是名词或名词短语，接口名称有时可能是形容词或形容词短语。现在还没有特定的规则或行之有效的约定来命名注解类型。</p><p>测试类的命名以它要测试的类的名称开始，以<code>Test</code>结束。例如，<code>HashTest</code>或<code>HashIntegrationTest</code>。</p><h4 id="5-2-3-方法名"><a href="#5-2-3-方法名" class="headerlink" title="5.2.3 方法名"></a>5.2.3 方法名</h4><p>方法名都以<code>lowerCamelCase</code>风格编写。</p><p>方法名通常是动词或动词短语。</p><p>下划线可能出现在JUnit测试方法名称中用以分隔名称的逻辑组件。一个典型的模式是：<code>test&lt;MethodUnderTest&gt;_&lt;state&gt;</code>，例如<code>testPop_emptyStack</code>。<br>并不存在唯一正确的方式来命名测试方法。</p><h4 id="5-2-4-常量名"><a href="#5-2-4-常量名" class="headerlink" title="5.2.4 常量名"></a>5.2.4 常量名</h4><p>常量名命名模式为<code>CONSTANT_CASE</code>，全部字母大写，用下划线分隔单词。那，到底什么算是一个常量？</p><p>每个常量都是一个静态final字段，但不是所有静态final字段都是常量。在决定一个字段是否是一个常量时，<br>考虑它是否真的感觉像是一个常量。例如，如果任何一个该实例的观测状态是可变的，则它几乎肯定不会是一个常量。<br>只是永远不<code>打算</code>改变对象一般是不够的，它要真的一直不变才能将它示为常量。</p><pre><code>// Constantsstatic final int NUMBER = 5;static final ImmutableList&lt;String&gt; NAMES = ImmutableList.of(&quot;Ed&quot;, &quot;Ann&quot;);static final Joiner COMMA_JOINER = Joiner.on(&apos;,&apos;);  // because Joiner is immutablestatic final SomeMutableType[] EMPTY_ARRAY = {};enum SomeEnum { ENUM_CONSTANT }// Not constantsstatic String nonFinal = &quot;non-final&quot;;final String nonStatic = &quot;non-static&quot;;static final Set&lt;String&gt; mutableCollection = new HashSet&lt;String&gt;();static final ImmutableSet&lt;SomeMutableType&gt; mutableElements = ImmutableSet.of(mutable);static final Logger logger = Logger.getLogger(MyClass.getName());static final String[] nonEmptyArray = {&quot;these&quot;, &quot;can&quot;, &quot;change&quot;};</code></pre><p>这些名字通常是名词或名词短语。</p><h4 id="5-2-5-非常量字段名"><a href="#5-2-5-非常量字段名" class="headerlink" title="5.2.5 非常量字段名"></a>5.2.5 非常量字段名</h4><p>非常量字段名以<code>lowerCamelCase</code>风格编写。</p><p>这些名字通常是名词或名词短语。</p><h4 id="5-2-6-参数名"><a href="#5-2-6-参数名" class="headerlink" title="5.2.6 参数名"></a>5.2.6 参数名</h4><p>参数名以<code>lowerCamelCase</code>风格编写。</p><p>参数应该避免用单个字符命名。</p><h4 id="5-2-7-局部变量名"><a href="#5-2-7-局部变量名" class="headerlink" title="5.2.7 局部变量名"></a>5.2.7 局部变量名</h4><p>局部变量名以<code>lowerCamelCase</code>风格编写，比起其它类型的名称，局部变量名可以有更为宽松的缩写。</p><p>虽然缩写更宽松，但还是要避免用单字符进行命名，除了临时变量和循环变量。</p><p>即使局部变量是final和不可改变的，也不应该把它示为常量，自然也不能用常量的规则去命名它。</p><h4 id="5-2-8-类型变量名"><a href="#5-2-8-类型变量名" class="headerlink" title="5.2.8 类型变量名"></a>5.2.8 类型变量名</h4><p>类型变量可用以下两种风格之一进行命名：</p><ul><li>单个的大写字母，后面可以跟一个数字(如：E, T, X, T2)。</li><li>以类命名方式(5.2.2节)，后面加个大写的T(如：RequestT, FooBarT)。</li></ul><h3 id="5-3-驼峰式命名法-CamelCase"><a href="#5-3-驼峰式命名法-CamelCase" class="headerlink" title="5.3 驼峰式命名法(CamelCase)"></a>5.3 驼峰式命名法(CamelCase)</h3><p><a href="http://zh.wikipedia.org/wiki/%E9%A7%9D%E5%B3%B0%E5%BC%8F%E5%A4%A7%E5%B0%8F%E5%AF%AB" target="_blank" rel="noopener">驼峰式命名法</a>分大驼峰式命名法(<code>UpperCamelCase</code>)和小驼峰式命名法(<code>lowerCamelCase</code>)。<br>有时，我们有不只一种合理的方式将一个英语词组转换成驼峰形式，如缩略语或不寻常的结构(例如”IPv6”或”iOS”)。Google指定了以下的转换方案。</p><p>名字从<code>散文形式</code>(prose form)开始:</p><ol><li>把短语转换为纯ASCII码，并且移除任何单引号。例如：”Müller’s algorithm”将变成”Muellers algorithm”。</li><li>把这个结果切分成单词，在空格或其它标点符号(通常是连字符)处分割开。<ul><li>推荐：如果某个单词已经有了常用的驼峰表示形式，按它的组成将它分割开(如”AdWords”将分割成”ad words”)。<br>需要注意的是”iOS”并不是一个真正的驼峰表示形式，因此该推荐对它并不适用。</li></ul></li><li>现在将所有字母都小写(包括缩写)，然后将单词的第一个字母大写：<ul><li>每个单词的第一个字母都大写，来得到大驼峰式命名。</li><li>除了第一个单词，每个单词的第一个字母都大写，来得到小驼峰式命名。</li></ul></li><li>最后将所有的单词连接起来得到一个标识符。</li></ol><p>示例：</p><pre><code>Prose form                Correct               Incorrect------------------------------------------------------------------&quot;XML HTTP request&quot;        XmlHttpRequest        XMLHTTPRequest&quot;new customer ID&quot;         newCustomerId         newCustomerID&quot;inner stopwatch&quot;         innerStopwatch        innerStopWatch&quot;supports IPv6 on iOS?&quot;   supportsIpv6OnIos     supportsIPv6OnIOS&quot;YouTube importer&quot;        YouTubeImporter                          YoutubeImporter*</code></pre><p>加星号处表示可以，但不推荐。</p><blockquote><blockquote><p>Note：在英语中，某些带有连字符的单词形式不唯一。例如：”nonempty”和”non-empty”都是正确的，因此方法名<code>checkNonempty</code>和<code>checkNonEmpty</code>也都是正确的。</p></blockquote></blockquote><h2 id="编程实践"><a href="#编程实践" class="headerlink" title="编程实践"></a><a id="Practice">编程实践</a></h2><h3 id="6-1-Override：能用则用"><a href="#6-1-Override：能用则用" class="headerlink" title="6.1 @Override：能用则用"></a>6.1 @Override：能用则用</h3><p>只要是合法的，就把<code>@Override</code>注解给用上。</p><h3 id="6-2-捕获的异常：不能忽视"><a href="#6-2-捕获的异常：不能忽视" class="headerlink" title="6.2 捕获的异常：不能忽视"></a>6.2 捕获的异常：不能忽视</h3><p>除了下面的例子，对捕获的异常不做响应是极少正确的。(典型的响应方式是打印日志，或者如果它被认为是不可能的，则把它当作一个<code>AssertionError</code>重新抛出。)</p><p>如果它确实是不需要在catch块中做任何响应，需要做注释加以说明(如下面的例子)。</p><pre><code>try {  int i = Integer.parseInt(response);  return handleNumericResponse(i);} catch (NumberFormatException ok) {  // it&apos;s not numeric; that&apos;s fine, just continue}return handleTextResponse(response);</code></pre><p><strong>例外</strong>：在测试中，如果一个捕获的异常被命名为<code>expected</code>，则它可以被不加注释地忽略。下面是一种非常常见的情形，用以确保所测试的方法会抛出一个期望中的异常，<br>因此在这里就没有必要加注释。</p><pre><code>try {  emptyStack.pop();  fail();} catch (NoSuchElementException expected) {}</code></pre><h3 id="6-3-静态成员：使用类进行调用"><a href="#6-3-静态成员：使用类进行调用" class="headerlink" title="6.3 静态成员：使用类进行调用"></a>6.3 静态成员：使用类进行调用</h3><p>使用类名调用静态的类成员，而不是具体某个对象或表达式。</p><pre><code>Foo aFoo = ...;Foo.aStaticMethod(); // goodaFoo.aStaticMethod(); // badsomethingThatYieldsAFoo().aStaticMethod(); // very bad</code></pre><h3 id="6-4-Finalizers-禁用"><a href="#6-4-Finalizers-禁用" class="headerlink" title="6.4 Finalizers: 禁用"></a>6.4 Finalizers: 禁用</h3><p>极少会去重载<code>Object.finalize</code>。</p><blockquote><blockquote><p>Tip：不要使用finalize。如果你非要使用它，请先仔细阅读和理解<a href="http://books.google.com/books?isbn=8131726592" target="_blank" rel="noopener">Effective Java</a><br>第7条款：“Avoid Finalizers”，然后不要使用它。</p></blockquote></blockquote><h2 id="Javadoc"><a href="#Javadoc" class="headerlink" title="Javadoc"></a><a id="Javadoc">Javadoc</a></h2><h3 id="7-1-格式"><a href="#7-1-格式" class="headerlink" title="7.1 格式"></a>7.1 格式</h3><h4 id="7-1-1-一般形式"><a href="#7-1-1-一般形式" class="headerlink" title="7.1.1 一般形式"></a>7.1.1 一般形式</h4><p>Javadoc块的基本格式如下所示：</p><pre><code>/** * Multiple lines of Javadoc text are written here, * wrapped normally... */public int method(String p1) { ... }</code></pre><p>或者是以下单行形式：</p><pre><code>/** An especially short bit of Javadoc. */</code></pre><p>基本格式总是OK的。当整个Javadoc块能容纳于一行时(且没有Javadoc标记@XXX)，可以使用单行形式。</p><h4 id="7-1-2-段落"><a href="#7-1-2-段落" class="headerlink" title="7.1.2 段落"></a>7.1.2 段落</h4><p>空行(即，只包含最左侧星号的行)会出现在段落之间和Javadoc标记(@XXX)之前(如果有的话)。<br>除了第一个段落，每个段落第一个单词前都有标签<code>&lt;p&gt;</code>，并且它和第一个单词间没有空格。</p><h4 id="7-1-3-Javadoc标记"><a href="#7-1-3-Javadoc标记" class="headerlink" title="7.1.3 Javadoc标记"></a>7.1.3 Javadoc标记</h4><p>标准的Javadoc标记按以下顺序出现：<code>@param</code>, <code>@return</code>, <code>@throws</code>, <code>@deprecated</code>, 前面这4种标记如果出现，描述都不能为空。<br>当描述无法在一行中容纳，连续行需要至少再缩进4个空格。</p><h3 id="7-2-摘要片段"><a href="#7-2-摘要片段" class="headerlink" title="7.2 摘要片段"></a>7.2 摘要片段</h3><p>每个类或成员的Javadoc以一个简短的摘要片段开始。这个片段是非常重要的，在某些情况下，它是唯一出现的文本，比如在类和方法索引中。</p><p>这只是一个小片段，可以是一个名词短语或动词短语，但不是一个完整的句子。它不会以<code>A {@code Foo} is a...</code>或<code>This method returns...</code>开头,<br>它也不会是一个完整的祈使句，如<code>Save the record...</code>。然而，由于开头大写及被加了标点，它看起来就像是个完整的句子。</p><blockquote><blockquote><p>Tip：一个常见的错误是把简单的Javadoc写成<code>/** @return the customer ID */</code>，这是不正确的。它应该写成<code>/** Returns the customer ID. */</code>。</p></blockquote></blockquote><h3 id="7-3-哪里需要使用Javadoc"><a href="#7-3-哪里需要使用Javadoc" class="headerlink" title="7.3 哪里需要使用Javadoc"></a>7.3 哪里需要使用Javadoc</h3><p>至少在每个public类及它的每个public和protected成员处使用Javadoc，以下是一些例外：</p><h4 id="7-3-1-例外：不言自明的方法"><a href="#7-3-1-例外：不言自明的方法" class="headerlink" title="7.3.1 例外：不言自明的方法"></a>7.3.1 例外：不言自明的方法</h4><p>对于简单明显的方法如<code>getFoo</code>，Javadoc是可选的(即，是可以不写的)。这种情况下除了写“Returns the foo”，确实也没有什么值得写了。</p><p>单元测试类中的测试方法可能是不言自明的最常见例子了，我们通常可以从这些方法的描述性命名中知道它是干什么的，因此不需要额外的文档说明。</p><blockquote><blockquote><p>Tip：如果有一些相关信息是需要读者了解的，那么以上的例外不应作为忽视这些信息的理由。例如，对于方法名<code>getCanonicalName</code>，<br>就不应该忽视文档说明，因为读者很可能不知道词语<code>canonical name</code>指的是什么。</p></blockquote></blockquote><h4 id="7-3-2-例外：重载"><a href="#7-3-2-例外：重载" class="headerlink" title="7.3.2 例外：重载"></a>7.3.2 例外：重载</h4><p>如果一个方法重载了超类中的方法，那么Javadoc并非必需的。</p><h4 id="7-3-3-可选的Javadoc"><a href="#7-3-3-可选的Javadoc" class="headerlink" title="7.3.3 可选的Javadoc"></a>7.3.3 可选的Javadoc</h4><p>对于包外不可见的类和方法，如有需要，也是要使用Javadoc的。如果一个注释是用来定义一个类，方法，字段的整体目的或行为，<br>那么这个注释应该写成Javadoc，这样更统一更友好。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a><a id="End">后记</a></h2><p>本文档翻译自<a href="http://google-styleguide.googlecode.com/svn/trunk/javaguide.html" target="_blank" rel="noopener">Google Java Style</a>，<br>译者<a href="http://weibo.com/hawstein" target="_blank" rel="noopener">@Hawstein</a>。</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>checkstyle <a href="https://github.com/checkstyle/checkstyle/blob/master/src/main/resources/google_checks.xml" target="_blank" rel="noopener">https://github.com/checkstyle/checkstyle/blob/master/src/main/resources/google_checks.xml</a></p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Google Java编程风格指南 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2015年01月Reading Notes</title>
      <link href="/2015-01-reading-notes/"/>
      <url>/2015-01-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="构建类型安全的SQL查询"><a href="#构建类型安全的SQL查询" class="headerlink" title="构建类型安全的SQL查询"></a>构建类型安全的SQL查询</h2><p><a href="http://spring.io/blog/2011/04/26/advanced-spring-data-jpa-specifications-and-querydsl/" target="_blank" rel="noopener">Advanced Spring Data JPA - Specifications and Querydsl</a></p><p><a href="http://www.querydsl.com/static/querydsl/latest/reference/html/ch02.html#jpa_integration" target="_blank" rel="noopener">Querying JPA document</a></p><p><a href="https://github.com/querydsl/querydsl-jpa-example" target="_blank" rel="noopener">querydsl jpa example</a></p><p><a href="http://www.querydsl.com/" target="_blank" rel="noopener"><code>querysql</code></a>很早之前了解过,当时没有看到他的价值，最近在写某业务系统的分页查询过程中，看到基于<code>Specifications</code>写的复杂查询语句，有点乱，感觉有点点不爽。</p><p>jpa 提供了<code>Metamodel</code>,但是<code>Specifications</code>难用，生成的语法糖也难用。</p><p>下面列出几种在spring-data-jpa中使用查询的例子：</p><h3 id="1-使用querydsl："><a href="#1-使用querydsl：" class="headerlink" title="1.使用querydsl："></a>1.使用querydsl：</h3><pre><code>public List&lt;SchedulerRule&gt; findByOther(String other) {   BooleanBuilder builder = new BooleanBuilder();   builder.or(schedulerRule.memo.containsIgnoreCase(other));   builder.or(schedulerRule.properties.containsIgnoreCase(other));   builder.or(schedulerRule.dGroup.containsIgnoreCase(other));   return new JPAQuery(em).from(schedulerRule).where(builder).orderBy(schedulerRule.id.asc()).list(schedulerRule); }</code></pre><h3 id="2-使用原生sql："><a href="#2-使用原生sql：" class="headerlink" title="2.使用原生sql："></a>2.使用原生sql：</h3><pre><code>public List&lt;SchedulerRule&gt; findByOther(String other) {    return (List&lt;SchedulerRule&gt;) em        .createNativeQuery(            &quot;select * from  scheduler_rule where  memo LIKE :other OR properties LIKE :other OR dGroup LIKE :other order by id&quot;,            SchedulerRule.class).setParameter(&quot;other&quot;, &quot;%&quot; + other + &quot;%&quot;).getResultList();}</code></pre><h3 id="3-使用-Query"><a href="#3-使用-Query" class="headerlink" title="3.使用@Query:"></a>3.使用<code>@Query</code>:</h3><pre><code>@Query(&quot;from SchedulerRule as rule where mod(rule.id, :clusterSize)= :mod and rule.status = &apos;NORMAL&apos;&quot;)List&lt;SchedulerRule&gt; findByClient(@Param(&quot;clusterSize&quot;) int clusterSize, @Param(&quot;mod&quot;) int mod);</code></pre><h3 id="4-使用接口命名生成查询语句："><a href="#4-使用接口命名生成查询语句：" class="headerlink" title="4.使用接口命名生成查询语句："></a>4.使用接口命名生成查询语句：</h3><pre><code>Page&lt;SchedulerRule&gt; findByCreater(String creator, Pageable pageable);</code></pre><p>在使用querydsl时，通过配置annotation processor可以很方便的完成代码生成工作：</p><pre><code>&lt;!--querydsl--&gt;       &lt;plugin&gt;           &lt;groupId&gt;com.mysema.maven&lt;/groupId&gt;           &lt;artifactId&gt;apt-maven-plugin&lt;/artifactId&gt;           &lt;version&gt;1.1.0&lt;/version&gt;           &lt;configuration&gt;               &lt;processor&gt;com.mysema.query.apt.jpa.JPAAnnotationProcessor&lt;/processor&gt;           &lt;/configuration&gt;           &lt;dependencies&gt;               &lt;dependency&gt;                   &lt;groupId&gt;com.mysema.querydsl&lt;/groupId&gt;                   &lt;artifactId&gt;querydsl-apt&lt;/artifactId&gt;                   &lt;version&gt;3.6.0&lt;/version&gt;               &lt;/dependency&gt;           &lt;/dependencies&gt;           &lt;executions&gt;               &lt;execution&gt;                   &lt;phase&gt;generate-sources&lt;/phase&gt;                   &lt;goals&gt;                       &lt;goal&gt;process&lt;/goal&gt;                   &lt;/goals&gt;                   &lt;configuration&gt;                       &lt;outputDirectory&gt;src/gen/java&lt;/outputDirectory&gt;                   &lt;/configuration&gt;               &lt;/execution&gt;           &lt;/executions&gt;       &lt;/plugin&gt;</code></pre><h2 id="ActiveJPA——针对JPA的活动记录模式"><a href="#ActiveJPA——针对JPA的活动记录模式" class="headerlink" title="ActiveJPA——针对JPA的活动记录模式"></a>ActiveJPA——针对JPA的活动记录模式</h2><p><a href="http://www.infoq.com/cn/articles/ActiveJPA" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/ActiveJPA</a></p><p>活动记录模式在使用上来说，还是很happy的。但是造成的问题是：1.<code>entity</code>和<code>DO</code>耦合在一起了，如果业务复杂，还是老老实实的<code>DDD</code>吧。2.复杂的查询可能还是需要借助<code>DAO</code>。如果自己来实现，考虑上关系映射，最后就是活脱脱的一个hibernat出来了。这个框架借助<code>JPA</code>的能力，简单的实现了活动记录模式。</p><p>作者通过<code>java instrument api</code>+<code>javassit</code>来生成便于使用的静态方法(不需要提供类型信息)。</p><h2 id="用betamax-mock掉外部http-https依赖"><a href="#用betamax-mock掉外部http-https依赖" class="headerlink" title="用betamax mock掉外部http/https依赖"></a>用betamax mock掉外部http/https依赖</h2><p><a href="http://freeside.co/betamax/" target="_blank" rel="noopener">http://freeside.co/betamax/</a></p><p><code>betamax</code>在你的应用和外部应用之间架起了proxy.他会录制第一次请求，在本地文件系统中生成<code>Tape</code>，后续的请求就不会调用目标服务了。我们可以把<code>tape</code>存放在<code>VCS</code>中，也可以编辑此文件，满足特殊需求。</p><h2 id="Building-a-Robust-and-Secure-Web-Application-With-Velocity"><a href="#Building-a-Robust-and-Secure-Web-Application-With-Velocity" class="headerlink" title="Building a Robust and Secure Web Application With Velocity"></a>Building a Robust and Secure Web Application With Velocity</h2><p><a href="http://wiki.apache.org/velocity/BuildingSecureWebApplications" target="_blank" rel="noopener">http://wiki.apache.org/velocity/BuildingSecureWebApplications</a></p><p>这篇文章很老了，但是很值得参考下。</p><h3 id="Best-Practices-In-Building-A-Secure-Robust-Velocity-Web-Application"><a href="#Best-Practices-In-Building-A-Secure-Robust-Velocity-Web-Application" class="headerlink" title="Best Practices In Building A Secure, Robust Velocity Web Application"></a>Best Practices In Building A Secure, Robust Velocity Web Application</h3><ol><li><p>Review all context references for unwanted methods.</p><p> 不要在Context中放入能改变程序状态的引用。</p></li><li><p>Encode HTML special characters to avoid cross-scripting vulnerabilities.</p><p> 可以通过<code>EscapeHtmlReference</code>对符合特定模式的引用进行过滤。</p></li><li><p>Use an up-to-date and properly configured app server.</p><p> 里面提到通过<code>Java Security Manager</code>来限制应用的行为。这也是一种不错的方式，只是灵活性不好。可以采用findbugs来检查静态代码，再控制好上传的文件/对系统的直接调用就ok了。</p></li></ol><ol><li><p>Configure Velocity for production use.</p><p> 创建<code>EventCartridge</code>和<code>Event Handlers</code>来捕获异常，并记录进日志。这个工作在<code>com.yjf.common.util.Velocitys</code>里面是做了的。但是spring mvc集成 velocity可以做下。提前发现异常(上次CRSF过滤器配置出错导致的页面乱了)。</p></li></ol><h2 id="jello–Front-End-Integrated-Solution-for-J2EE-Velocity"><a href="#jello–Front-End-Integrated-Solution-for-J2EE-Velocity" class="headerlink" title="jello–Front End Integrated Solution for J2EE Velocity"></a>jello–Front End Integrated Solution for J2EE Velocity</h2><p><a href="https://github.com/fex-team/jello" target="_blank" rel="noopener">https://github.com/fex-team/jello</a></p><p><a href="http://106.186.23.103:8080/" target="_blank" rel="noopener">http://106.186.23.103:8080/</a></p><p>使用velocity的同学可以关注下：jello针对服务端为 JAVA + Velocity 的前端集成解决方案。为优化前端开发效率而生，提供前后端开发分离、自动性能优化、模块化开发机制等功能。</p><p><a href="http://106.186.23.103:8080/velocity/index" target="_blank" rel="noopener">模板技巧</a>部分文档适合学习velocity的同学看看。</p><h2 id="模板引擎的选择"><a href="#模板引擎的选择" class="headerlink" title="模板引擎的选择"></a>模板引擎的选择</h2><p>关于thymeleaf的性能：<a href="http://forum.thymeleaf.org/Performance-issue-td3722763.html" target="_blank" rel="noopener">http://forum.thymeleaf.org/Performance-issue-td3722763.html</a><br>模式freemarker性能最强，thymeleaf性能差距太大</p><p>比较JVM上的模板引擎： <a href="http://www.slideshare.net/jreijn/comparing-templateenginesjvm" target="_blank" rel="noopener">http://www.slideshare.net/jreijn/comparing-templateenginesjvm</a></p><p>thymeleaf的优点主要在和前端结合起来很不错，前端切完图，然后加上动态数据的部分就ok了。页面不需要服务端也能渲染出来。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年12月Reading Notes</title>
      <link href="/2014-12-reading-notes/"/>
      <url>/2014-12-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="CPU-Flame-Graphs"><a href="#CPU-Flame-Graphs" class="headerlink" title="CPU Flame Graphs"></a>CPU Flame Graphs</h2><p><a href="http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html" target="_blank" rel="noopener">http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html</a></p><p>java里可以很方便的通过<code>jvisualvm</code>来采样性能数据,然后分析每个线程栈中比较费时的cpu操作.java以外的程序,通过cpu火焰图来分析性能问题,很直观(比较起来,jvisualvm的cpu sample report没有cpu火焰图直观).</p><p>生成的<code>svg</code>报告中,<code>y轴</code>可以理解为调用栈层次,越大调用层次越深.<code>x轴</code>中的长度是调用占用时间比.</p><p><code>CPU Flame Graphs</code>生成过程需要三步:</p><ol><li>采样性能数据(<a href="https://perf.wiki.kernel.org/index.php/Tutorial#Counting_with_perf_stat" target="_blank" rel="noopener">perf</a>, DTrace, SystemTap, and ktap) </li><li>转换性能数据  </li><li>利用性能数据生成<code>svg</code>报告</li></ol><h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p><a href="http://niusmallnan.github.io/_build/html/_templates/openstack/coroutine_usage.html" target="_blank" rel="noopener">http://niusmallnan.github.io/_build/html/_templates/openstack/coroutine_usage.html</a><br><a href="http://www.dongliu.net/post/5906310176440320" target="_blank" rel="noopener">http://www.dongliu.net/post/5906310176440320</a></p><p>协程是纯软件实现的多任务调度,在软件层面实现任务的保持和恢复.传统的用多线程的方式来实现任务调度,在高并发场景下,CPU创建开销和CPU上下文切换的开销太大.使用协程,任务调度有程序来调度,不涉及到cpu线程切换和cpu大量创建线程,性能会快不少.</p><p>在使用协程时,所有的I/O都需要使用异步I/O,不然性能会大打折扣.</p><p>在协程中,不同的执行单元之间通信可以采用共享内存或者消息机制.由于共享内存又会引入共享资源的同步,推荐采用消息机制.</p><h2 id="基于线程与基于事件的并发编程之争"><a href="#基于线程与基于事件的并发编程之争" class="headerlink" title="基于线程与基于事件的并发编程之争"></a>基于线程与基于事件的并发编程之争</h2><p><a href="http://www.jdon.com/46921" target="_blank" rel="noopener">http://www.jdon.com/46921</a></p><p>基于线程的并发变成带来了很多问题，很难写出高性能的程序。协程和Actor模型也许可以考虑用来降低CS的开销。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年11月Reading Notes</title>
      <link href="/2014-11-reading-notes/"/>
      <url>/2014-11-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Linux-Troubleshooting-Part-I-High-Load"><a href="#Linux-Troubleshooting-Part-I-High-Load" class="headerlink" title="Linux Troubleshooting, Part I: High Load"></a>Linux Troubleshooting, Part I: High Load</h2><p><a href="http://www.linuxjournal.com/magazine/hack-and-linux-troubleshooting-part-i-high-load" target="_blank" rel="noopener">http://www.linuxjournal.com/magazine/hack-and-linux-troubleshooting-part-i-high-load</a></p><p>10月25(This is my big day)日凌晨线上某系统出现<code>load</code>很高的问题,我当时排查问题的思路和这篇文章类似.简单总结下:</p><p><code>load</code>,系统负载,可以理解为现在等待cpu处理的任务数.如何衡量<code>high</code>呢?这个和cpu核心数有关系,8核cpu,load为8,这个也不能称之为high.</p><p>造成high load的原因一般有:</p><ul><li><p>CPU-bound load</p><p>  某些任务太耗cpu了,导致high load.这个通过看top就能看出来.如果<code>top</code>命令中的<code>xx%wa</code>很高,说明这些任务都在等待去了.</p></li><li><p>load caused by out of memory issues</p><p>  由于内存不足,linux在使用swap了,导致high load.这个通过<code>free</code>很容易看出来.</p></li><li><p>I/O-bound load</p><p>  iostat/iotop(需安装)都很容易发现原因所在.</p></li></ul><p>我偏向于使用<code>vmstat</code>,用了它,什么都可以看到了.很悲剧的是,这台线上服务器一切正常.服务器重启后,负载一直很低.服务器重启后,一切都正常了.</p><h2 id="The-Best-Plugins-for-Sublime-Text"><a href="#The-Best-Plugins-for-Sublime-Text" class="headerlink" title="The Best Plugins for Sublime Text"></a>The Best Plugins for Sublime Text</h2><p><a href="http://ipestov.com/the-best-plugins-for-sublime-text/" target="_blank" rel="noopener">http://ipestov.com/the-best-plugins-for-sublime-text/</a></p><p>可以把sublime武装成ide的插件.</p><h2 id="ibatis和mybatis共存"><a href="#ibatis和mybatis共存" class="headerlink" title="ibatis和mybatis共存"></a>ibatis和mybatis共存</h2><p>如果先加载ibatis的jar,会遇到<code>java.lang.reflect.MalformedParameterizedTypeException</code>异常.需要让ibatis后加载.可以修改<code>ibatis</code>依赖的<code>artifactId</code>,比如改为<code>zibatis</code></p><h2 id="MySQL-加锁处理分析"><a href="#MySQL-加锁处理分析" class="headerlink" title="MySQL 加锁处理分析"></a>MySQL 加锁处理分析</h2><p><a href="http://hedengcheng.com/?p=771" target="_blank" rel="noopener">http://hedengcheng.com/?p=771</a></p><p>这篇文章从mysql数据库原理角度来分析锁,很透彻,很深刻.</p><p>比如对于一条简单的sql语句:</p><pre><code>delete from test where id = ?；</code></pre><p>如果id是主键/非空的唯一索引,不会出现gap锁.如果是非索引列,直接锁表(这个太恶心了,因为server和存储引擎分离导致的);如果是非唯一的索引,事务隔离级别是read commit,锁定选取的数据.如果是repeatable read,为了防止幻读,gap lock出现了)</p><p>##面向程序员的数据库访问性能优化法则<br><a href="http://blog.csdn.net/yzsind/article/details/6059209" target="_blank" rel="noopener">http://blog.csdn.net/yzsind/article/details/6059209</a></p><p>这篇文章很系统的介绍了程序员应该掌握的数据库优化知识.<br>首先根据硬件相关知识介绍各种硬件的访问延时/带宽指标:<br><img src="/2014-11-reading-notes/access_delay_bandwidth.gif" alt=""></p><p>通过对上面的指标分析,自然得出优化的层次:</p><ol><li><p>减少数据访问（减少磁盘访问）</p><ul><li>正确创建/使用索引</li><li>只通过索引访问数据(索引节点中存有数据,通过索引就能拿到数据最高效)</li><li>根据查询计划优化索引</li><li>一个表上的索引不能太多,会增加修改操作IO.</li></ul></li><li><p>返回更少数据（减少网络传输或磁盘访问）</p><ul><li>分页(通过rowid分页的方式减少IO,前提是where/order子句都要在索引上)</li><li>只返回需要的字段(别使用select *,带来各种问题,对于我们来说,最头痛的是sql版本兼容性问题.)</li></ul></li></ol><ol><li><p>减少交互次数（减少网络传输）</p><ul><li>batch DML(批量操作走jdbc批量接口)</li><li>In List(多操作合并,依稀记得mysql驱动里也有这样的做法)</li><li>设置Fetch Size(默认fetch size可能不是最优的,需要根据实际情况调整,比如分页查询,一次查询100条,在不OOM的前提下增大此值,减少网络io)</li><li>使用存储过程(这个得看场景)</li><li>使用ResultSet游标处理记录(这一点往往被忽略掉,使用mybatis的RowHandler来解决问题)</li></ul></li><li><p>减少服务器CPU开销（减少CPU及内存开销）</p><ul><li>使用绑定变量(mysql仅仅支持硬解析,<a href="http://www.cnblogs.com/justfortaste/p/3920140.html" target="_blank" rel="noopener">参考</a>)</li><li>合理使用排序</li></ul></li><li><p>利用更多资源（增加资源）</p></li></ol>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年10月Reading Notes</title>
      <link href="/2014-10-reading-notes/"/>
      <url>/2014-10-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Why-does-my-Java-process-consume-more-memory-than-Xmx"><a href="#Why-does-my-Java-process-consume-more-memory-than-Xmx" class="headerlink" title="Why does my Java process consume more memory than Xmx?"></a>Why does my Java process consume more memory than Xmx?</h2><p><a href="https://plumbr.eu/blog/why-does-my-java-process-consume-more-memory-than-xmx" target="_blank" rel="noopener">https://plumbr.eu/blog/why-does-my-java-process-consume-more-memory-than-xmx</a></p><p>java进程内存消耗会大于我们在<code>-Xmx</code>中指定的值.<code>-Xmx</code>仅仅限制了应用程序使用的heap大小.java进的内存消耗主要包括下面的东东:</p><pre><code>Max memory = [-Xmx] + [-XX:MaxPermSize] + number_of_threads * [-Xss]+Other</code></pre><p>Other:</p><ul><li>Garbage collection(GC自己需要消耗内存来记录数据)</li><li>JIT optimization(JIT优化需要记录代码执行行为,Code cache-JIT编译完成后存放机器码)</li><li>Off-heap allocations(NIO/DirectMemory之类的东东)</li><li>JNI code(程序使用第三方JNI代码占用的内存)</li><li>Metaspace(jdk8使用它取代了permgen)</li></ul><h2 id="Understanding-the-OutOfMemoryError"><a href="#Understanding-the-OutOfMemoryError" class="headerlink" title="Understanding the OutOfMemoryError"></a>Understanding the OutOfMemoryError</h2><p><a href="https://plumbr.eu/blog/understanding-java-lang-outofmemoryerror" target="_blank" rel="noopener">https://plumbr.eu/blog/understanding-java-lang-outofmemoryerror</a></p><ul><li><p>java.lang.OutOfMemoryError: Java heap space</p><p>  heap空间不足.一般加大<code>-Xmx</code>.如果还不足就有可能是内存泄漏了.</p></li><li><p>java.lang.OutOfMemoryError: PermGen space</p><p>  permgen空间不足,默认的jvm配置得比较小,需要通过<code>-XX:MaxPermSize</code>加大.动态代码生成技术和容器redeploy资源泄漏也会导致permgen不足</p></li><li><p>java.lang.OutOfMemoryError: GC overhead limit exceeded</p><p>  jvm gc行为中超过98%以上的时间去释放小于2%的堆空间时会报这个错误</p></li><li><p>java.lang.OutOfMemoryError: unable to create new native thread</p><p>  java没创建一个线程,会占用<code>-Xss</code>大小空间.这个异常有可能是系统内存不足导致.如果系统内存充足,往往是ulimit -u限制了一个用户创建最大线程数造成的.</p></li><li><p>java.lang.OutOfMemoryError: Requested array size exceeds VM limit</p><p>  申请的数组大小超过jvm定义的阀值.</p></li><li><p>java.lang.OutOfMemoryError: request <size> bytes for <reason>. Out of swap space?</reason></size></p></li><li>java.lang.OutOfMemoryError: <reason> <stack trace=""> (Native method)</stack></reason></li></ul><h2 id="20-Obstacles-to-Scalability"><a href="#20-Obstacles-to-Scalability" class="headerlink" title="20 Obstacles to Scalability"></a>20 Obstacles to Scalability</h2><p>本文罗列了20个影响伸缩性的瓶颈</p><h3 id="10-Obstacles-to-Scaling-Performance"><a href="#10-Obstacles-to-Scaling-Performance" class="headerlink" title="10 Obstacles to Scaling Performance"></a>10 Obstacles to Scaling Performance</h3><ol><li><p>Two-Phase Commit</p><p> 两阶段提交需要等待参与方确认,延时太大.所以我们基本上使用best-effort 1pc+业务上的重试.</p></li><li><p>Insufficient Caching</p><p> 各个层次都需要引入缓存机制,现在我们对browser cache/page cache还做得比较少.</p></li><li><p>Slow Disk I/O, RAID 5, Multitenant Storage</p><p> 数据库服务起I/O很关键.如果只做raid建议做raid10.当然加上fushion io之类的加速卡更好.</p></li><li><p>Serial Processing</p><p>服务并行处理我们也还思考得比较少.比如对远程服务进行合理并行处理(可以考虑下java8中的CompletableFuture).对于缓存数据的获取,可以考虑批量获取.</p></li><li><p>Missing Feature Flags</p><p> 特性开关,说大点就是服务降级,我们需要却分不同服务的重要等级,适当时候关闭某些服务,保证核心业务正常运行.</p></li><li><p>Single Copy of the Database</p></li><li>Using Your Database for Queuing</li><li>Using a Database for Full-Text Searching</li><li>Object Relational Models(orm很好用,但是缺少能hold住他的人)</li><li>Missing Instrumentation(需要监控/profile工具)</li></ol><h3 id="10-Obstacles-to-Scaling-Beyond-Optimization-Speed"><a href="#10-Obstacles-to-Scaling-Beyond-Optimization-Speed" class="headerlink" title="10 Obstacles to Scaling Beyond Optimization Speed"></a>10 Obstacles to Scaling Beyond Optimization Speed</h3><ol><li>Lack of a Code Repository and Version Control</li><li>Single Points of Failure</li><li>Lack of Browse-Only Mode(对于内容型的网站,此功能非常重要)</li><li>Weak Communication</li><li>Lack of Documentation</li><li>Lack of Fire Drills(却分演练,特别是大的运维调整,此项非常必要)</li><li>Insufficient Monitoring and Metrics</li><li>Cowboy Operations</li><li>Growing Technical Debt</li><li>Insufficient Logging</li></ol>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年09月Reading Notes</title>
      <link href="/2014-09-reading-notes/"/>
      <url>/2014-09-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Mcrouter-基于-Memcached协议的缓存层流量管理工具"><a href="#Mcrouter-基于-Memcached协议的缓存层流量管理工具" class="headerlink" title="Mcrouter:基于 Memcached协议的缓存层流量管理工具"></a>Mcrouter:基于 Memcached协议的缓存层流量管理工具</h2><p><a href="http://www.infoq.com/cn/news/2014/09/mcrouter-memcached" target="_blank" rel="noopener">http://www.infoq.com/cn/news/2014/09/mcrouter-memcached</a></p><p><a href="https://code.facebook.com/posts/296442737213493/introducing-mcrouter-a-memcached-protocol-router-for-scaling-memcached-deployments/" target="_blank" rel="noopener">https://code.facebook.com/posts/296442737213493/introducing-mcrouter-a-memcached-protocol-router-for-scaling-memcached-deployments/</a></p><p>memcache不支持服务端路由,facebook开发了<code>mcrouter</code>(能够处理每秒50亿次的请求).它和memcached之间通过文本协议通信.扮演者memcached服务器的客户端,应用的服务端.他的特性很多,基本上都是我们需要的.我们现在使用的是二进制协议,需要修改为文本协议.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>dubbo线程任务&quot;不均衡&quot;问题分析</title>
      <link href="/dubbo-imbalance/"/>
      <url>/dubbo-imbalance/</url>
      <content type="html"><![CDATA[<p>dubbo应用使用的线程池为<code>com.alibaba.dubbo.common.threadpool.support.fixed.FixedThreadPool</code>,如果当queue设置为0时,会使用<code>SynchronousQueue</code>,这个东东导致了任务线程执行”不均衡”(满足了大家的心理预期,其实这种不均衡方式减少了上下文切换,但是<code>SynchronousQueue</code>没有大小,不能起到任务缓冲的作用).</p><p>请在dubbo:protocol上加上queues大小(参考tomcat默认配置).</p><pre><code>&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;${dubbo.provider.port}&quot; threads=&quot;200&quot; queues=&quot;100&quot;/&gt;</code></pre><p>测试:</p><p>修改前:</p><pre><code>grep DubboServerHandler dubbo-demo.log |awk  -F &apos;-&apos;  &apos;{print $6}&apos; |awk  -F &apos;]&apos;  &apos;{print $1}&apos; |sort -n |uniq -c     1 150  1 151  1 152  1 153  1 154  1 168  1 169  1 170117 171   5386 172714 173   2646 174   3738 175   3105 180   6332 194   2483 195   4940 196   1211 197   5661 198   5428 199   1393 200</code></pre><p>修改后:</p><pre><code>grep DubboServerHandler dubbo-demo.log |awk  -F &apos;-&apos;  &apos;{print $6}&apos; |awk  -F &apos;]&apos;  &apos;{print $1}&apos; |sort -n |uniq -c507 1498 2496 3501 15488 16494 17523 18502 19494 20503 21491 22507 23     ... 507 133495 134498 135494 136507 137508 151490 152494 195496 196496 197506 198493 199489 200</code></pre>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> dubbo </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用零拷贝提高数据传输效率</title>
      <link href="/zero-copy/"/>
      <url>/zero-copy/</url>
      <content type="html"><![CDATA[<p>本文讲了如何用<code>zero copy</code>技术来提高I/O性能.</p><p>静态文件服务器需要把磁盘上的数据发送给客户端.这里cpu消耗比较少,但是效率不高:内核从磁盘读数据,内核/用户空间交换数据,最后写到socket.数据在内核/用户空间转换时,需要拷贝数据,消耗cpu和内存带宽.对于java应用来说,还需要合理的使用缓冲区来减少gc的压力.</p><p>java提供了<code>transferTo</code>方法来使用<code>zero copy</code>技术.他可以让数据直接从一个<code>channel</code>到另外一个<code>channel</code>.避免上面说到的一些问题.</p><h3 id="1-传统的解决办法"><a href="#1-传统的解决办法" class="headerlink" title="1.传统的解决办法"></a>1.传统的解决办法</h3><p>过程类似于下面的代码:</p><pre><code>File.read(fileDesc, buf, len);Socket.send(socket, buf, len);</code></pre><h4 id="1-1数据拷贝"><a href="#1-1数据拷贝" class="headerlink" title="1.1数据拷贝"></a>1.1数据拷贝</h4><p><img src="/zero-copy/figure1.gif" alt=""></p><p>这种方式会有四次内存拷贝</p><h4 id="1-2-上下文切换"><a href="#1-2-上下文切换" class="headerlink" title="1.2 上下文切换"></a>1.2 上下文切换</h4><p><img src="/zero-copy/figure2.gif" alt=""></p><p>这种方式会有四次上下文切换.</p><h4 id="1-3-过程说明"><a href="#1-3-过程说明" class="headerlink" title="1.3 过程说明"></a>1.3 过程说明</h4><ol><li><code>read</code>方法导致一次从<code>user mode</code>到<code>kernel mode</code>的上下文切换.系统调用<code>sys_read</code>从文件读取数据,通过DMA,把磁盘上的数据读到<code>kernel address space buffer</code>.</li><li>数据从<code>kernel address space buffer</code>拷贝到<code>user buffer</code>.<code>read</code>返回,导致从<code>kernel mode</code>到<code>user mode</code>的上下文切换.现在数据被读到了<code>user address space buffer</code>.</li><li><code>send</code>方法导致一次<code>user mode</code>到<code>kernel mode</code>的上下文切换.第三次拷贝把拷贝到<code>kernel address space buffer</code>.此buffer关联着<code>destination socket</code></li><li>系统<code>send</code>调用返回时导致第四次上下文切换,DMA把<code>kernel address space buffer</code>中的数据发送到协议引擎导致第四次数据拷贝.</li></ol><h4 id="1-4-intermediate-kernel-buffer"><a href="#1-4-intermediate-kernel-buffer" class="headerlink" title="1.4 intermediate kernel buffer"></a>1.4 intermediate kernel buffer</h4><p>使用<code>intermediate kernel buffer</code>主要为了提高性能,读的时候扮演缓存的角色,写的时候可以让应用程序实现异步(应用程序写到kernel buffer就返回).不幸的是,当我们处理的数据大于内核缓冲大小时,这样的拷贝是完全没有任何意义的.</p><h3 id="2-零拷贝的方式"><a href="#2-零拷贝的方式" class="headerlink" title="2.零拷贝的方式"></a>2.零拷贝的方式</h3><p>使用如下的代码来完成零拷贝</p><p>java方法:</p><pre><code>public void transferTo(long position, long count, WritableByteChannel target);</code></pre><p>系统调用:</p><pre><code>#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);</code></pre><h4 id="2-1-数据拷贝"><a href="#2-1-数据拷贝" class="headerlink" title="2.1 数据拷贝"></a>2.1 数据拷贝</h4><p><img src="/zero-copy/figure3.gif" alt=""></p><p>涉及到3次数据拷贝.</p><h4 id="2-2-上下文切换"><a href="#2-2-上下文切换" class="headerlink" title="2.2 上下文切换"></a>2.2 上下文切换</h4><p><img src="/zero-copy/figure4.gif" alt=""></p><p>涉及到2次上下文切换</p><h4 id="2-3-过程说明"><a href="#2-3-过程说明" class="headerlink" title="2.3 过程说明"></a>2.3 过程说明</h4><ol><li><code>transferTo</code>方法让DMA把磁盘文件读到<code>kernel read buffer</code>.然后内核把<code>kernel read buffer</code>中的数据拷贝到<code>socket buffer</code>.</li><li><code>DMA</code>把<code>socket buffer</code>中的数据拷贝到协议引擎.</li></ol><h3 id="3-更好的方式"><a href="#3-更好的方式" class="headerlink" title="3 更好的方式"></a>3 更好的方式</h3><p>通过上面使用这种方式,上下文切换从4次变为了2次.数据拷贝减少了一次.如果网卡支持<code>gather operations</code>,linux 2.4内核就开始提供更好的解决方案.</p><p><img src="/zero-copy/figure5.gif" alt=""></p><ol><li><code>transferTo</code>方法让<code>DMA engine</code>把磁盘文件内容拷贝到内核缓冲区.</li><li>数据不需要拷贝到<code>socket buffer</code>.<code>socket buffer</code>里只需写入数据的地址和长度.<code>DMA engine</code>从内核缓冲区把数据读到协议引擎.</li></ol><p>通过内核带来的特性,数据拷贝变为了2次(这两次拷贝都是DMA在做).cpu copy变为了0.</p><h3 id="4-写在最后"><a href="#4-写在最后" class="headerlink" title="4 写在最后"></a>4 写在最后</h3><p>文章地址<code>http://www.ibm.com/developerworks/library/j-zerocopy/</code>,里面有性能测试结果.后面附带有性能测试程序.不过这个测试程序不太恰当,应该都用nio的api来测试<code>tansferTo</code>和非<code>tansferTo</code>.</p><p>静态文件服务器一般都有静态资源缓存(apache可以配置,其他的服务器不了解).如果使用内存缓存,减少了读的过程.内存拷贝变为cpu copy <code>application buffer</code> -&gt; <code>socket buffer</code>,DMA copy <code>socket buffer</code> -&gt;<code>NIC buffer</code>,磁盘io大大降低了.</p><p><code>NIO</code>不是很熟悉,不知道通过<code>ByteBuffer.allocateDirect()</code>+<code>transferTo</code>+<code>gather operations</code>能不能让copy变为一次.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zero copy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何跟踪数据库结构变动</title>
      <link href="/database-version/"/>
      <url>/database-version/</url>
      <content type="html"><![CDATA[<p>昨天和澎湃聊了这个事情,当时的想法是数据库中有表记录版本,项目代码中存储变更脚本.无意中看到数据库版本控制工具<a href="http://www.liquibase.org/index.html" target="_blank" rel="noopener">liquibase</a>.最开始还是有点担心,怕这东西把数据库玩坏了.看了看官方文档,再粗略看了下主流程的源代码,发掘下我想要的功能,这个工具已经足够强大了,我们用好就行.</p><p>下面以cs为例,讲讲整个过程.</p><h3 id="1-在cs-dal中添加maven依赖"><a href="#1-在cs-dal中添加maven依赖" class="headerlink" title="1. 在cs-dal中添加maven依赖."></a>1. 在cs-dal中添加maven依赖.</h3><pre><code>    &lt;build&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.liquibase&lt;/groupId&gt;            &lt;artifactId&gt;liquibase-maven-plugin&lt;/artifactId&gt;            &lt;version&gt;3.2.2&lt;/version&gt;            &lt;configuration&gt;                &lt;!--数据库变更主文件--&gt;                &lt;changeLogFile&gt;src/main/resources/db/changelog/db.master.xml&lt;/changeLogFile&gt;                &lt;!--数据库相关配置文件--&gt;                &lt;propertyFile&gt;src/main/resources/db/config/dal-${spring.profiles.active}.properties&lt;/propertyFile&gt;            &lt;/configuration&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;phase&gt;process-resources&lt;/phase&gt;                    &lt;goals&gt;                        &lt;goal&gt;update&lt;/goal&gt;                    &lt;/goals&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;</code></pre><h3 id="2-编写数据库变更脚本"><a href="#2-编写数据库变更脚本" class="headerlink" title="2. 编写数据库变更脚本"></a>2. 编写数据库变更脚本</h3><h4 id="2-1-数据库变更主文件"><a href="#2-1-数据库变更主文件" class="headerlink" title="2.1 数据库变更主文件"></a>2.1 数据库变更主文件</h4><p><code>db.master.xml</code>:</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;databaseChangeLog    xmlns=&quot;http://www.liquibase.org/xml/ns/dbchangelog&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xsi:schemaLocation=&quot;http://www.liquibase.org/xml/ns/dbchangelog     http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.2.xsd&quot;&gt;    &lt;!--数据库变更文件.注意:保证顺序,脚本执行顺序和include的先后有关系.includeAll可以加载所有脚本,加载顺序和文件命名有关系,容易犯错误,建议不使用.--&gt;    &lt;include relativeToChangelogFile=&quot;true&quot; file=&quot;db.1.0.sql&quot;/&gt;       &lt;include relativeToChangelogFile=&quot;true&quot; file=&quot;db.2.0.sql&quot;/&gt;&lt;/databaseChangeLog&gt;</code></pre><h4 id="2-2-变更脚本"><a href="#2-2-变更脚本" class="headerlink" title="2.2 变更脚本"></a>2.2 变更脚本</h4><p><code>db.1.0.sql</code>:</p><pre><code>--liquibase formatted sql--changeset qiubo:1create table test1 (    id int primary key,    name varchar(255));--rollback drop table test1;</code></pre><p><code>db.2.0.sql</code>:</p><pre><code>--liquibase formatted sql--changeset qiubo:2insert into test1 (id, name) values (1, &apos;name 1&apos;);insert into test1 (id, name) values (2, &apos;name 2&apos;);</code></pre><p>语法参考:<a href="http://www.liquibase.org/documentation/sql_format.html" target="_blank" rel="noopener">http://www.liquibase.org/documentation/sql_format.html</a></p><h4 id="2-3-数据库配置文件"><a href="#2-3-数据库配置文件" class="headerlink" title="2.3 数据库配置文件"></a>2.3 数据库配置文件</h4><p>dal-local.properties</p><pre><code>driver=com.mysql.jdbc.Driverurl=jdbc:mysql://127.0.0.1:3306/yjf_cs?useUnicode=true&amp;characterEncoding=UTF8&amp;zeroDateTimeBehavior=convertToNullusername=rootpassword=root#数据库schema名changelogSchemaName=yjf_cs</code></pre><p>建议大家把原来的数据库配置文件中的key改为和这个一致,没必要搞多份配置.</p><h3 id="3-路径结构"><a href="#3-路径结构" class="headerlink" title="3.路径结构"></a>3.路径结构</h3><p>确保xxx-dal如下的路径结构,请大家统一:</p><pre><code>|---pom.xml|---src|    |---main|    |    |---java|    |    |---resources|    |    |        |---db|    |    |        |    |---changelog|    |    |        |    |        |---db.1.0.sql|    |    |        |    |        |---db.2.0.sql|    |    |        |    |        |---db.master.xml|    |    |        |    |---config|    |    |        |    |     |---dal-dev.properties|    |    |        |    |     |---dal-local.properties|    |    |        |    |     |---dal-net.properties|    |    |        |    |     |---dal-online.properties|    |    |        |    |     |---dal-pnet.properties|    |    |        |    |     |---dal-sdev.properties|    |    |        |    |     |---dal-snet.properties|    |    |        |    |     |---dal-stest.properties|    |    |        |    |     |---dal-test.properties</code></pre><h3 id="4-执行"><a href="#4-执行" class="headerlink" title="4.执行"></a>4.执行</h3><p>在cs-dal目录执行:</p><pre><code>mvn liquibase:update -Dspring.profiles.active=local</code></pre><p>上面的脚本会以local环境执行,读取<code>dal-local.properties</code>中的数据库配置,执行数据库变更脚本.执行成功后,会在数据库中新建两个表.<code>DATABASECHANGELOG</code>会记录数据库变更信息,<code>DATABASECHANGELOGLOCK</code>用于防止多台服务器同时部署时的并发问题.</p><h3 id="5-注意事项"><a href="#5-注意事项" class="headerlink" title="5.注意事项"></a>5.注意事项</h3><ol><li>先不要搞线上.</li><li>变更脚本命名:我现在做得简单<code>db.1.0.sql</code>,最好版本号为项目版本号,便于跟踪.</li><li>新项目建议采用此方案,跟踪数据库所有的开发变动.</li><li>老项目可以采用全量的方式使用.全量,先根据数据库的基础数据生成变更脚本<a href="http://www.liquibase.org/documentation/generating_changelogs.html" target="_blank" rel="noopener">generating_changelogs</a>,然后同步版本(changeLogSync)到数据库中.这样做的好处是,以后可以从无到有的创建当前版本的数据库了.参考<a href="http://www.liquibase.org/documentation/existing_project.html" target="_blank" rel="noopener">Adding Liquibase on an Existing project</a></li><li>老项目也可以采用增量的方式使用,增量的方式不会管以前的数据版本.如果采用这种方式,在新环境搭建数据库,你需要先用数据库工具还原到没有版本之前的状态,然后再执行变更脚本.参考<a href="http://www.liquibase.org/documentation/existing_project.html" target="_blank" rel="noopener">Adding Liquibase on an Existing project</a></li><li>请不要修改(脚本内容/脚本路径)之前的数据库变更脚本,liquibase会对每个Changesets生成摘要,执行时会去对比,如果你修改了以前的Changesets,会报错(所有的变更在事务中执行,出错了会回滚,不用担心会影响到数据库).</li><li>官方文档很全,想深入的同学请阅读<a href="http://www.liquibase.org/faq.html" target="_blank" rel="noopener">FAQ</a>/<a href="http://www.liquibase.org/bestpractices.html" target="_blank" rel="noopener">BEST PRACTICES</a>/<a href="http://www.liquibase.org/documentation/maven/index.html" target="_blank" rel="noopener">Maven Liquibase Plugin</a>.遇到问题之前先检查配置是否正确,有bug可以找我^_^.</li></ol>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库版本 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>webservice优化</title>
      <link href="/cxf-tuning/"/>
      <url>/cxf-tuning/</url>
      <content type="html"><![CDATA[<p>很早之前写的一篇文字,一直没有搬上blog,以后会慢慢把有些东西放到blog上来.</p><p>webservice的性能实在是敢恭维。曾经因为webservice吞吐量上不去，对webservice进行了一些性能方面的优化:</p><h2 id="1-分析"><a href="#1-分析" class="headerlink" title="1.分析"></a>1.分析</h2><h3 id="1-1-FastInfoset"><a href="#1-1-FastInfoset" class="headerlink" title="1.1 FastInfoset"></a>1.1 FastInfoset</h3><p>采用了<a href="http://en.wikipedia.org/wiki/Fast_Infoset" target="_blank" rel="noopener">FastInfoset</a>(简称FI)，效果很明显，极端条件下的大数据量传输，性能提高60%，他可以减少传输成本，序列化成本和xml解析成本。cxf基于http协商机制(检查请求header中<code>Accept: application/fastinfoset</code>)来启用FI。</p><h3 id="1-2-Gzip"><a href="#1-2-Gzip" class="headerlink" title="1.2 Gzip"></a>1.2 Gzip</h3><p>客户端和服务器端是否使用Gzip压缩，也是基于http协议协商的(检查请求header 中是否有<code>Accept-encoding:gzip</code>)。但是这里需要仔细权衡下。对于小数据量，启用gzip压缩支持是吃力不讨好的行为，数据量很小的时候，gzip压缩结果不明显，还浪费cpu。</p><h3 id="1-3-unexpected-element异常"><a href="#1-3-unexpected-element异常" class="headerlink" title="1.3 unexpected element异常"></a>1.3 unexpected element异常</h3><p>见:<a href="http://bohr.me/cxf-unexpected-element/">http://bohr.me/cxf-unexpected-element/</a></p><h3 id="1-4-处理过程分析"><a href="#1-4-处理过程分析" class="headerlink" title="1.4 处理过程分析"></a>1.4 处理过程分析</h3><p>cxf 中通过一些列interceptor来完成数据解析处理操作，每个interceptor绑定到特定的阶段，下面是GZIP 和FI interceptor所处的阶段</p><table><thead><tr><th>类型</th><th>Direction</th><th>Phase</th></tr></thead><tbody><tr><td>Gzip</td><td>IN</td><td>Phase.RECEIVE</td></tr><tr><td></td><td>Out</td><td>Phase.PREPARE_SEND</td></tr><tr><td> FI</td><td>IN</td><td>Phase.POST_STREAM</td></tr><tr><td></td><td>Out</td><td>Phase.PRE_STREAM</td></tr></tbody></table><p>数据进来时，先<code>RECEIVE</code>阶段适配InputStream对象为GZIPInputStream，然后在<code>POST_STREAM</code>阶段解析数据。完成gzip解压缩，FI解析数据过程。</p><p>数据出去时，在<code>PREPARE_SEND</code>阶段适配OutputStream对象为GZipThresholdOutputStream，在<code>PRE_STREAM</code>阶段再序列化为二进制数据传输出去。完成FI序列化数据，GZIP压缩数据过程。</p><p>测试发送20250byte数据，仅仅启用FI时，发送数据量为20181byte，再启用Gzip压缩后，发送数据量为258byte。</p><h2 id="2-操作步骤"><a href="#2-操作步骤" class="headerlink" title="2.操作步骤"></a>2.操作步骤</h2><h3 id="2-1添加依赖"><a href="#2-1添加依赖" class="headerlink" title="2.1添加依赖"></a>2.1添加依赖</h3><p>cxf版本修改为2.7.0并加入FastInfoset</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;com.sun.xml.fastinfoset&lt;/groupId&gt;    &lt;artifactId&gt;FastInfoset&lt;/artifactId&gt;    &lt;version&gt;1.2.9&lt;/version&gt;&lt;/dependency&gt;</code></pre><h3 id="2-2-修改cxf配置"><a href="#2-2-修改cxf配置" class="headerlink" title="2.2    修改cxf配置"></a>2.2    修改cxf配置</h3><h4 id="2-2-1-删除引入的cxf配置"><a href="#2-2-1-删除引入的cxf配置" class="headerlink" title="2.2.1 删除引入的cxf配置"></a>2.2.1 删除引入的cxf配置</h4><pre><code>&lt;import resource=&quot;classpath:META-INF/cxf/cxf.xml&quot; /&gt;&lt;import resource=&quot;classpath:META-INF/cxf/cxf-extension-soap.xml&quot; /&gt;&lt;import resource=&quot;classpath:META-INF/cxf/cxf-servlet.xml&quot; /&gt;</code></pre><p>我们项目中很多spring配置文件都加入了上面的东东，这个不是必须的，不删除这东东会导致配置不生效。</p><h4 id="2-2-2-配置gzip和FI"><a href="#2-2-2-配置gzip和FI" class="headerlink" title="2.2.2 配置gzip和FI"></a>2.2.2 配置gzip和FI</h4><p>Spring配置文件中引入cxf namespace<br><code>xmlns:cxf=http://cxf.apache.org/core和xsi:schemaLocationhttp://cxf.apache.org/core  http://cxf.apache.org/schemas/core.xsd</code></p><p>然后加入配置</p><pre><code>&lt;cxf:bus&gt;    &lt;cxf:features&gt;        &lt;cxf:fastinfoset force=&quot;false&quot; /&gt;        &lt;bean class=&quot;org.apache.cxf.transport.common.gzip.GZIPFeature&quot;&gt;            &lt;property name=&quot;threshold&quot;&gt;                &lt;value&gt;2048&lt;/value&gt;            &lt;/property&gt;        &lt;/bean&gt;    &lt;/cxf:features&gt;&lt;/cxf:bus&gt;</code></pre><p>注意这些特性client和server端都要配置。</p><h2 id="3-写在最后"><a href="#3-写在最后" class="headerlink" title="3.写在最后"></a>3.写在最后</h2><p>启用<code>gzip</code>和<code>FastInfoset</code>,性能基本上也到达webservice的极致了.通过<code>IgnoreUnexpectedElementValidationEventHandler</code>再解决易用性问题,基本完美.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> webservice </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>java开发工程师可以了解的常用命令</title>
      <link href="/monitor-tools/"/>
      <url>/monitor-tools/</url>
      <content type="html"><![CDATA[<p>先总结下常用的一些监控工具:</p><h2 id="linux命令"><a href="#linux命令" class="headerlink" title="linux命令"></a>linux命令</h2><ul><li><p><code>w</code></p><p>  系统负载</p></li><li><p><code>lsof -p pid</code></p><p>  进程打开的文件</p></li><li><p><code>lsof -i:port</code></p><p>  端口的运行情况</p></li><li><p><code>free -m</code></p><p>  内存情况</p></li><li><p><code>vmstat</code></p><p>  进程、内存、内存分页、堵塞IO、traps及CPU活动的信息</p></li><li><p><code>iostat</code></p><p>  磁盘io情况</p></li><li><p><code>top -n 1</code></p><p>  cpu/负载/内存等使用情况.</p></li><li><p><code>iotop</code></p><p>  磁盘io</p></li><li><p><code>ps aux | sort -k6nr | head -n 10</code></p><p>  查看linux 实际内存占用最多的10个</p></li><li><p><code>ps aux | sort -k5nr | head -n 10</code></p><p>  查看linux 虚拟内存占用最多的10个</p></li><li><p><code>dstat -lamps</code></p><p>  查看系统整体状况</p></li><li><p><code>pstree -al pid|head -n 1</code></p><p>  查看进程启动命令</p></li><li><p><code>strace -T -p pid</code></p><p>  查看进程系统调用.开销很大,使用时要小心.</p></li><li><p><code>netstat</code></p><p>  <code>netstat -an |grep port</code> 查看端口连接情况</p><p>  <code>netstat -alnp |grep pid</code> 通过pid查看进程所有端口情况</p></li><li><p><code>ss -lntp |grep port</code></p><p>  通过端口查看进程</p></li><li><p><code>nmon</code></p><p>  强大的监控工具.也可以方便的出报表.我一般用来在压力测试时监控系统性能.</p></li><li><p><code>latencytop</code></p><p>  用于查看系统内部慢.以前做mysql性能优化,多亏有这东东.</p></li><li><p><code>cat /proc/pid/status  |grep Threads</code></p><p>  查看进程内线程个数</p></li></ul><h2 id="java工具"><a href="#java工具" class="headerlink" title="java工具"></a>java工具</h2><ul><li><p><code>jvisualvm</code></p><p>  jvm的运行情况/各种dump的分析都可以干,没有JRMC牛.oracle承诺会把JRockit的特性迁移到HotSpot上面来.现在jdk下已经有jmc了.</p></li><li><p><code>jps -lv</code></p><p>  查看所有java进程.</p></li><li><p><code>jinfo -sysprops pid</code></p><p>  查看java进程系统参数</p></li><li><p><code>jinfo  -flag jvmflag pid</code></p><p>  查看jvm flag.比如查看xss,<code>jinfo  -flag ThreadStackSize pid</code></p></li><li><p><code>jstack pid</code></p><p>  查看线程栈信息</p></li><li><p><code>jmap -dump:live,format=b,file=xxx.hprof pid</code></p><p>  生成heap dump</p></li><li><p><code>jmap -histo pid</code></p><p>  查看java堆中对象统计信息</p></li><li><p><code>java -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsFinal</code> </p><p>  查看jvm flag</p><pre><code>The first column appears to reflect the data type of the option (intx, uintx, uint64_t, bool, double, ccstr, ccstrlist). The second column is the name of the flag and the third column is the value, if any, that the flag is set to.The fourth column appears to indicate the type of flag and has values such as {product},{pd product}, {C1 product} for client or {C2 product} for server, {C1 pd product} for client or {C2 pd product} for server, {product rw}, {diagnostic} (only if -XX:+UnlockDiagnosticVMOptions was specified), {experimental}, and {manageable}. See Eugene Kuleshov&apos;s The most complete list of -XX options for Java 6 JVM for a brief description of most of these categories as well as a listing of most of these options themselves.</code></pre></li><li><p><a href="http://visualvm.java.net/plugins.html​" target="_blank" rel="noopener">tda</a></p><p>  线程栈分析器,这个是jvisualvm的插件.</p></li><li><p><a href="http://www.eclipse.org/mat/" target="_blank" rel="noopener">mat</a></p><p>  基于eclipse的heap dump分析工具,这个工具是比jvisualvm在heap分析这块专业.不过jvisualvm能cover住大多数场景,基本上我都只用jvisualvm了.</p></li><li><p><code>jmap -heap pid</code></p><p>  检查heap情况</p></li><li><p><a href="https://github.com/chewiebug/GCViewer" target="_blank" rel="noopener">GCViewer</a></p><p>  GC日志分析</p></li><li><p><code>jstat  -gcutil pid</code></p><p>  查看gc总体情况</p><pre><code>S0  — Heap上的 Survivor space 0 区已使用空间的百分比S1  — Heap上的 Survivor space 1 区已使用空间的百分比E   — Heap上的 Eden space 区已使用空间的百分比O   — Heap上的 Old space 区已使用空间的百分比P   — Perm space 区已使用空间的百分比YGC — 从应用程序启动到采样时发生 Young GC 的次数YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒)FGC — 从应用程序启动到采样时发生 Full GC 的次数FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒)GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)</code></pre></li><li><p><code>btrace</code></p><p>  神器,线上出问题了,想知道某个方法的调用情况,入参之类的,就靠btrace了.<br>此工具大致原理如下:</p><ol><li><code>btrace-client</code> attach 目标进程(<code>com.sun.tools.attach.VirtualMachine#attach</code>)</li><li>加载agent <code>btrace-agent</code> (<code>com.sun.tools.attach.VirtualMachine#loadAgent</code>)</li><li>agent启动服务端,开启监听端口</li><li><code>brace-client</code> 把编译好的用户btrace代码发送到服务端,并等待服务端响应</li><li><code>btrace-agent</code> 通过asm修改运行时代码,织入用户btrace代码逻辑.监控到信息后,发给<code>btrace-client</code></li></ol></li><li><p>jmc</p><p>  生成记录</p><pre><code>#检查特性是否开启jcmd 23385 VM.check_commercial_features#开启商业特性jcmd 23385 VM.unlock_commercial_features#检查JFR状态jcmd 23385 JFR.check#执行180sJFR收集jcmd 23385 JFR.start name=recording filename=/root/recording.jfr duration=180s</code></pre></li></ul>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 常用命令 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年08月Reading Notes</title>
      <link href="/2014-08-reading-notes/"/>
      <url>/2014-08-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="My-WordPress-Development-Toolbox"><a href="#My-WordPress-Development-Toolbox" class="headerlink" title="My WordPress Development Toolbox"></a>My WordPress Development Toolbox</h2><p><a href="http://tommcfarlin.com/wordpress-developer-toolbox/" target="_blank" rel="noopener">http://tommcfarlin.com/wordpress-developer-toolbox/</a></p><p>本来是准备找git的客户端,看到这篇文章.不喜欢tower,大爱<a href="http://www.sourcetreeapp.com/" target="_blank" rel="noopener">SoureTree</a>.</p><p><a href="http://www.browserstack.com/" target="_blank" rel="noopener">browserstack</a>也挺好的,适合做浏览器兼容性测试.</p><h2 id="JVM-plus-Docker-Better-together"><a href="#JVM-plus-Docker-Better-together" class="headerlink" title="JVM plus Docker: Better together"></a>JVM plus Docker: Better together</h2><p><a href="http://www.javaworld.com/article/2456960/java-app-dev/jvm-plus-docker-better-together.html" target="_blank" rel="noopener">http://www.javaworld.com/article/2456960/java-app-dev/jvm-plus-docker-better-together.html</a></p><p>docker刚好弥补jvm对资源管理(CPU/IO)的不足.</p><h2 id="SharedHashMap-vs-Redis"><a href="#SharedHashMap-vs-Redis" class="headerlink" title="SharedHashMap vs Redis"></a>SharedHashMap vs Redis</h2><p><a href="http://vanillajava.blogspot.jp/2014/05/sharedhashmap-vs-redis.html" target="_blank" rel="noopener">http://vanillajava.blogspot.jp/2014/05/sharedhashmap-vs-redis.html</a></p><p>这位哥异常牛掰,java低延迟方面的专家.把性能做到极致啊!!!<code>It was designed to be used in Java in a pause less, garbage free manner.</code>狂赞!!!先留着,有时间了看看源代码.</p><h2 id="高性能服务器架构"><a href="#高性能服务器架构" class="headerlink" title="高性能服务器架构"></a>高性能服务器架构</h2><p><a href="http://blog.csdn.net/zhoudaxia/article/details/14223755" target="_blank" rel="noopener">http://blog.csdn.net/zhoudaxia/article/details/14223755</a></p><p>这些经验可以参考下:</p><ul><li><p>数据拷贝</p><p>  特别是java,很多数据拷贝的代码埋得深,比如<code>StringBuilder</code>扩容,集合扩容等等.java中的数据拷贝除了带来cpu的压力,也会给gc带来压力.</p><p>  参考:<a href="/zero-copy/">使用零拷贝提高数据传输效率</a></p></li><li><p>上下文切换</p><p>  线程越多,上下文切换就会越多.需要合理评估处理模型和系统情况.按照SEDA的方式把一个请求划分为多个阶段,但是多个阶段的独立线程池真的会增加上下文的切换,但这样可能会让系统利用率最高.</p></li><li><p>内存分配</p><p>  采用类似于Buddy memory allocation的策略来减少开销.</p></li><li><p>锁竞争</p><p>  一定要控制好锁的粒度.某些场景用map来存放锁对象,而不要使用一把大锁.</p></li></ul><h2 id="数据库版本控制工具liquibase"><a href="#数据库版本控制工具liquibase" class="headerlink" title="数据库版本控制工具liquibase"></a>数据库版本控制工具liquibase</h2><p><a href="http://www.liquibase.org/quickstart.html" target="_blank" rel="noopener">http://www.liquibase.org/quickstart.html</a></p><p>今天和勇哥讨论了如何来控制数据库版本.我们想的方案是,数据库里面有张versions表,里面记录当前的版本是多少.然后数据库更新文件存在项目中,并以目录来区分.这样就可以在项目启动时,来对比是否有新版本,是否需要升级.这样可以做到全自动化,需要规范现在的开发同学的行为,更重要的一点是,没有人来做这个事情.</p><p>liquibase正好在做这个事情,他也支持sql格式的版本,学习成本相当低.而且有内置的数据库版本和集群场景的检测,给力,先试试.</p><p>参考:<a href="/database-version/">如何跟踪数据库结构变动</a></p><h2 id="可伸缩性最佳实践：来自eBay的经验"><a href="#可伸缩性最佳实践：来自eBay的经验" class="headerlink" title="可伸缩性最佳实践：来自eBay的经验"></a>可伸缩性最佳实践：来自eBay的经验</h2><p>(<a href="http://www.infoq.com/cn/articles/ebay-scalability-best-practices)[http://www.infoq.com/cn/articles/ebay-scalability-best-practices]" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/ebay-scalability-best-practices)[http://www.infoq.com/cn/articles/ebay-scalability-best-practices]</a></p><p>手里有本2011年的架构师特刊,翻开看到的第一篇文章.虽然有点老了,但是经验还是值得我们借鉴.</p><ul><li>按功能分割</li></ul><p>咱们现在的架构体系基本上遵循这条最佳实践.借助于dubbo/cxf实现功能服务化.应用层可以实现水平线性扩展.</p><ul><li>水平切分</li></ul><p>应用层面的无状态很重要,会话之类的东西可以放在缓存服务器上,尽量让LB来实现水平切分.</p><p>数据库层面读写分离/分区/分库/分表.</p><ul><li>避免分布式事务</li></ul><p>分布式第一定律,不要使用分布式.特别是两阶段提交,对系统的吞吐影响很大.ebuy通过周密调整数据库操作的次序、异步恢复事件，以及数据核对（reconciliation）或者集中决算（settlement batches）来实现最终一致性.</p><ul><li>用异步策略解耦程序</li></ul><p>组件之间的异步带来的好处是解耦/缓冲压力.组件内的异步能提供跟灵活的资源管理策略(当然带来了上下文切换的开销).我们还需要异步任务管理/确保机制.</p><ul><li>将过程转变为异步的流</li><li>虚拟化所有层次</li></ul><p>虚拟化所有层次我们还做的不够好.硬件资源层面的虚拟化可以通过docker来实现.目前docker最缺少的是资源的管理/发现/注册能力.通用资源服务层面的虚拟化也可以通过注册中心来实现.结合配置管理系统/框架组件化,可以做到对应用的透明.</p><ul><li>适当地使用缓存</li></ul><p>缓存组件很多,分布式/集中式/进程内,不要选花了眼.同类型的我们只需要一种缓存组件,他必须要能支持丰富的数据结构,如果能提供持久话的能力最好(前提是在down掉的情况下要保证数据的一直.).</p><h2 id="Why-Choose-Jetty"><a href="#Why-Choose-Jetty" class="headerlink" title="Why Choose Jetty?"></a>Why Choose Jetty?</h2><p><a href="https://webtide.com/why-choose-jetty/" target="_blank" rel="noopener">https://webtide.com/why-choose-jetty/</a></p><p>一直有想法把jetty嵌入到我们的程序中来运行,jetty自身的体系结构优势便于我们去裁剪或者新增功能.</p><p>jetty的设计哲学很酷:</p><blockquote><p>Don’t put your application into Jetty, put Jetty into your application.</p></blockquote><h2 id="http-proxy"><a href="#http-proxy" class="headerlink" title="http proxy"></a>http proxy</h2><p><a href="http://rehorn.github.io/livepool/" target="_blank" rel="noopener">http://rehorn.github.io/livepool/</a></p><p><a href="http://mitmproxy.org/" target="_blank" rel="noopener">http://mitmproxy.org/</a></p><p>两个都是好东东.可以看下手机里面在干啥,吐槽下某些粗制滥造的app.也可以用来模拟http请求.</p><h2 id="jvm-flag"><a href="#jvm-flag" class="headerlink" title="jvm flag"></a>jvm flag</h2><p><a href="http://stas-blogspot.blogspot.jp/2011/07/most-complete-list-of-xx-options-for.html" target="_blank" rel="noopener">http://stas-blogspot.blogspot.jp/2011/07/most-complete-list-of-xx-options-for.html</a></p><p>最全的jvm flag.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> docker </tag>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hibernate应用报could not initialize proxy - no Session分析</title>
      <link href="/hibernate-no-session-in-dubbo/"/>
      <url>/hibernate-no-session-in-dubbo/</url>
      <content type="html"><![CDATA[<h3 id="1-场景描述"><a href="#1-场景描述" class="headerlink" title="1.场景描述:"></a>1.场景描述:</h3><p>某项目使用hibernate,在切换到dubbo后,在构造结果对象时从延迟加载对象中获取数据时,报<code>org.hibernate.LazyInitializationException: could not initialize proxy - no Session</code></p><p>构造结果对象的操作没有在事务环境下执行.</p><h3 id="2-原因分析"><a href="#2-原因分析" class="headerlink" title="2.原因分析:"></a>2.原因分析:</h3><p>cxf不报错是因为在web.xml中配置了<code>org.springframework.orm.jpa.support.OpenEntityManagerInViewFilter</code>,在请求到达web filter后,创建了<code>EntityManager</code>,请求结束后关闭<code>EntityManager</code>.在请求线程处理过程中,都可以拿到<code>EntityManager</code>,所以不会报错(至少可以从ThreadLocal中拿到).</p><p>切换为dubbo后,请求不会经过web filter,在事务模版代码中执行业务操作,可以正确的拿到<code>EntityManager</code>,不会报错.但是执行到构造结果对象时,就悲剧了.</p><h3 id="3-解决办法"><a href="#3-解决办法" class="headerlink" title="3.解决办法:"></a>3.解决办法:</h3><p>1.修改模版方法,把构造结果对象部分的代码也放到事务中执行.</p><p>2.编写支持dubbo的OpenEntityManagerInViewFilter</p><p>  可以通过<code>TransactionSynchronizationManager</code>做到如果<code>EntityManagerFactory</code>在线程变量中不存在则创建<code>EntityManager</code>,服务处理结束时,关闭<code>EntityManager</code>.</p><h3 id="4-优劣分析"><a href="#4-优劣分析" class="headerlink" title="4.优劣分析"></a>4.优劣分析</h3><ol><li><p>性能考虑</p><p> <code>open session in veiw</code>模式还是不怎么优雅,事务执行链路太长了,会影响性能.而且对于我们提供的服务接口来说,构造结果对象已经是最后一步了,后面再也不需要延迟加载对象,不需要在filter里面来做此操作.</p><p> web应用有在渲染模版时读取延迟加载对象的场景,这种场景使用还有意义.</p></li><li><p>功能角度</p><p> 如果遇到应用内的两个dubbo服务调用,dubbo会走injvm协议.此时请求不会经过io栈,但是会执行所有的dubbo filter.</p><p> 比如外部请求调用服务A,服务A调用内部服务B.</p><p> 外部请求调A时,filter创建<code>EntityManager</code>,然后调用服务B时,filter不创建<code>EntityManager</code>,但是在请求B结束时,filter关闭了<code>EntityManager</code>.在请求A中处理剩下的业务逻辑,如果遇到要操作数据库,就只有哭了.</p><p> 为什么web请求就不怕这种filter重入呢?web请求在forward时,你必须把request对象带进去,所以可以在request对象的attribute里面记录是否进过了这个filter.可以参考<code>org.springframework.web.filter.OncePerRequestFilter</code>.但是调用dubbo时,你只需要拿到服务代理对象就ok了,没有办法来知道整个请求链的情况.</p></li></ol><h3 id="5-最后结论"><a href="#5-最后结论" class="headerlink" title="5.最后结论"></a>5.最后结论</h3><p>还是修改下我们自己的代码,把构造结果对象部分的代码也放到事务中执行.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hibernate </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用vagrant</title>
      <link href="/vagrant/"/>
      <url>/vagrant/</url>
      <content type="html"><![CDATA[<p>vagrant挺火的,用于快速搭建开发环境.官方网站一行大字<code>Development environments made easy.</code>很惹眼.他可以实现可分发的环境搭建.</p><p>我们现在要快速搭建开发测试环境的需求很强烈,我们希望使用TA来快速搭建我们的开发测试环境.so,begin…</p><h2 id="1-Centos上安装Virtaul-Box-1"><a href="#1-Centos上安装Virtaul-Box-1" class="headerlink" title="1.Centos上安装Virtaul Box[^1]"></a>1.<code>Centos</code>上安装<code>Virtaul Box</code>[^1]</h2><h3 id="1-1-安装问题unable-to-find-the-sources-of-your-current-Linux-kernel-Specify-KERN-DIR-lt-directory-gt-and-run-Make-again-2"><a href="#1-1-安装问题unable-to-find-the-sources-of-your-current-Linux-kernel-Specify-KERN-DIR-lt-directory-gt-and-run-Make-again-2" class="headerlink" title="1.1 安装问题unable to find the sources of your current Linux kernel. Specify KERN_DIR=&lt;directory&gt; and run Make again.[^2]"></a>1.1 安装问题<code>unable to find the sources of your current Linux kernel. Specify KERN_DIR=&lt;directory&gt; and run Make again.</code>[^2]</h3><p>Virtaul Box原因是<code>uname -r</code>和<code>ls /usr/src/kernels/</code>版本不一致,需要执行<code>yum update</code>,可以把国内的yum镜像用起来,会快点.完了重启下.</p><p>参考:</p><pre><code>http://rationallyparanoid.com/articles/virtualbox-centos-6.2.htmlhttps://www.centos.org/forums/viewtopic.php?t=5603</code></pre><h2 id="2-Centos上安装vagrant-3"><a href="#2-Centos上安装vagrant-3" class="headerlink" title="2.Centos上安装vagrant[^3]"></a>2.<code>Centos</code>上安装<code>vagrant</code>[^3]</h2><h3 id="2-1-static-IP-on-a-bridged-interface"><a href="#2-1-static-IP-on-a-bridged-interface" class="headerlink" title="2.1 static IP on a bridged interface"></a>2.1 <code>static IP on a bridged interface</code></h3><p>由于是公用的环境,会有很多个童鞋去访问,所以需要固定ip,并且上面的服务大家也可以自由访问,所以需要桥接网络.<br>但是官方网站上没有这样的配置,最后在github[^4]上发现了解决方案,测试了N遍,终于对头了:</p><pre><code>config.vm.network &quot;public_network&quot;, :bridge =&gt; &quot;eth0&quot;, :ip =&gt; &quot;192.168.46.51&quot;</code></pre><p>如果是mac上,就用:</p><pre><code>config.vm.network &quot;public_network&quot;, :bridge =&gt; &quot;en0: Wi-Fi (AirPort)&quot;, :ip   =&gt; &quot;192.168.1.222&quot;</code></pre><p>这样也需要注意下,如果要搭建多套环境,最好还是开一个新的网段,别和其他系统的ip冲突了.</p><p>如果只是你自己一个人玩,使用host-only吧,很简单.</p><h3 id="2-2-ext4-file-system-inconsistency系统稳定性问题"><a href="#2-2-ext4-file-system-inconsistency系统稳定性问题" class="headerlink" title="2.2 ext4 file system inconsistency系统稳定性问题"></a>2.2 <code>ext4 file system inconsistency</code>系统稳定性问题</h3><p>不知道什么原因,过段时间就启动不了,最后通过<code>ssh tunneling</code>打开<code>Virtaul Box</code>图形化界面才发现了这个<code>ext4 file system inconsistency</code>问题.</p><p>错误日志如下:</p><pre><code>There is a known Linux kernel bug which can lead to the corruption of the virtual disk image under these conditions.Either enable the host I/O cache permanently in the VM settings or put the disk image and the snapshot folder onto a different file system.The host I/O cache will now be enabled for this medium.</code></pre><p>这是一个kernel的bug,centos forum上遇到这个问题[^5],其他的虚拟化vmware也有同样的问题.</p><p>如果<code>enable host I/O cache</code>,又会遇到各种问题[^6].比如<code>data loss</code>,<code>I/O errors</code>,<code>I/O requests time out</code>,<code>Physical memory waste</code>都是童鞋们不能接受的.</p><p>只有选择使用不同的文件系统,<code>fdisk -l</code>看下<code>/home</code>还比较大,有上T的空间.</p><pre><code>#卸载home分区umount /dev/mapper/VolGroup-lv_home#格式化mkfs.ext3 /dev/mapper/VolGroup-lv_home#装载home分区mount /dev/mapper/VolGroup-lv_home /home</code></pre><p>最后需要修改 <code>/etc/fstab</code>,改变挂载分区为<code>ext3</code>,重启后<code>sudo parted -l</code>看生效没有.现在可以在<code>/home</code>目录启动vagrant.</p><h3 id="2-3-guest分配多核反而更慢"><a href="#2-3-guest分配多核反而更慢" class="headerlink" title="2.3 guest分配多核反而更慢"></a>2.3 guest分配多核反而更慢</h3><p>如果开启多核(比如设置为20核),又遇到启动很慢的问题[^7].原因是:</p><blockquote><p>VMs with multiple vCPUs require that all allocated cores be free before processing can begin. This means, if you have a 2 vCPU machine,2 physical cores must be available, and a 4 vCPU requires 4 physical cores</p></blockquote><p>我开启20核,等了半个小时实在等不下去了.</p><p>查看cpu个数<code>grep &#39;physical id&#39; /proc/cpuinfo | sort -u</code>,2个物理cpu.查看每个cpu核心数,<code>grep &#39;core id&#39; /proc/cpuinfo | sort -u | wc -l</code>,每个cpu6个核心. 按照</p><blockquote><p>One point to note is that if you assign many more vCPUs than you have physical CPUs the system may run slower because the host spends more time scheduling threads than actually running them.</p></blockquote><p>,理论上12个应该是最优的,但是感觉还是不太靠谱,测试某app启动性能:</p><table><thead><tr><th>cpus</th><th>启动费时1</th><th>启动费时2</th></tr></thead><tbody><tr><td>1</td><td>34664</td><td>34291</td></tr><tr><td>2</td><td>29040</td><td>29104</td></tr><tr><td>4</td><td>26205</td><td>26495</td></tr><tr><td>6</td><td>27207</td><td>28566</td></tr><tr><td>8</td><td>48087</td><td>44483</td></tr></tbody></table><p>根据上面的测试,给vm配置4 cpus是最优的.卧槽,咱这服务两个物理cpu,每个cpu6 个核心,在加上<code>Hyperthreading</code>,<code>processor</code>都有24个了.如果这台服务器上有多个vm,咱这个测试最优的cpu数还会更少.</p><h2 id="3-制作package"><a href="#3-制作package" class="headerlink" title="3.制作package"></a>3.制作package</h2><h3 id="3-1-初始化vagrant环境"><a href="#3-1-初始化vagrant环境" class="headerlink" title="3.1 初始化vagrant环境"></a>3.1 初始化vagrant环境</h3><p>下载一个官方提供的base box[^8],用于初始化环境.这里我们选择CentOS 6.4 x86_64[^9].<br>在前面提到的ext3分区上进行:</p><pre><code>#添加镜像到 Vagrantvagrant box add yiji package.box#初始化环境vagrant init yiji</code></pre><p>当前目录会有一个<code>Vagrantfile</code>文件,加上前面测试的东东:</p><pre><code>config.vm.network &quot;public_network&quot;, :bridge =&gt; &quot;eth0&quot;, :ip =&gt; &quot;192.168.46.51&quot;config.vm.provider :virtualbox do |vb|    vb.gui = false    #设置内存    vb.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, &quot;5120&quot;]    #设置虚拟机ip    vb.customize [&quot;modifyvm&quot;, :id, &quot;--cpus&quot;, &quot;4&quot;]    #设置ioapic,启用多个cpu时,必须设置.如果就一个cpu就不要设置,影响性能    vb.customize [&quot;modifyvm&quot;, :id, &quot;--ioapic&quot;, &quot;on&quot;]    #vb.customize [&quot;modifyvm&quot;, :id, &quot;--cpuexecutioncap&quot;, &quot;50&quot;]end</code></pre><p>启动虚拟机并ssh登陆:</p><pre><code>#启动虚拟机vagrant up#ssh登陆vagrant ssh</code></pre><h3 id="3-2-初始化VM环境"><a href="#3-2-初始化VM环境" class="headerlink" title="3.2 初始化VM环境"></a>3.2 初始化VM环境</h3><p>ssh登陆后,此时是用vagrant用户登陆的,这个时候神马事情都干不了,切换到root用户</p><pre><code>#修改root密码sudo passwd root#切换到root账户su - root</code></pre><p>配置路由和dns服务器:</p><pre><code>sudo route del defaultsudo route add default gw 192.168.46.254echo &quot;nameserver 192.168.45.10&quot; &gt; /etc/resolv.confecho &quot;nameserver 8.8.8.8&quot; &gt;&gt; /etc/resolv.conf</code></pre><p>添加定时常用定时任务:</p><pre><code>#每12小时时间服务同步0 */12 * * * rdate -s time.nist.gov#每天清理日志0 0 * * * /script/deletelog.sh</code></pre><p>关闭防火墙:</p><pre><code>chkconfig ip6tables offchkconfig iptables off</code></pre><p>为了集中控制jvm的启动参数,定义java应用依赖环境变量:</p><pre><code>export APP_JAVA_OPTS=&quot;-Xms256m -Xmx512m&quot;</code></pre><p>所有的java应用启动脚本中把<code>APP_JAVA_OPTS</code>加在启动参数的最后,它的优先级最高,就很方便的控制所有的jvm进程内存大小了.</p><p>上面有些东西可以脚本化的,尽量就脚本化,比如在<code>/etc/rc.d/rc.local</code>增加启动脚本<code>init.sh</code> .其他脚本分为 <code>init_network.sh</code> <code>init_env.sh</code> <code>init_common_app.sh</code> <code>init_app.sh</code></p><h3 id="3-3-安装memcache"><a href="#3-3-安装memcache" class="headerlink" title="3.3 安装memcache"></a>3.3 安装memcache</h3><p>安装:</p><pre><code>yum install memcached</code></pre><p>配置文件:</p><pre><code>/etc/sysconfig/memcached</code></pre><p>命令:</p><pre><code>service memcached start/stop/restart/status</code></pre><p>设置开机启动:</p><pre><code>chkconfig memcached on</code></pre><p>修改<code>/etc/init.d/memcached</code>可以修改memcache启动参数</p><h3 id="3-4-安装rabbitmq"><a href="#3-4-安装rabbitmq" class="headerlink" title="3.4 安装rabbitmq"></a>3.4 安装rabbitmq</h3><p>安装:</p><pre><code>yum install rabbitmq #安装webui rabbitmq-plugins enable rabbitmq_management #启用guest账户 访问web ui echo &quot;[{rabbit, [{loopback_users, []}]}].&quot; &gt;/etc/rabbitmq/rabbitmq.config</code></pre><p>常用命令:</p><pre><code>service rabbitmq-server stop/start/etc.</code></pre><p>web ui访问地址,账号密码guest/guest:</p><pre><code>http://192.168.46.51:15672/</code></pre><p>设置开机启动:</p><pre><code>chkconfig rabbitmq-server on</code></pre><h3 id="3-5-安装其他软件"><a href="#3-5-安装其他软件" class="headerlink" title="3.5 安装其他软件"></a>3.5 安装其他软件</h3><p>jdk/maven/memcache/zookeeper/rabbitmq/dubbo-monitor-simple/dubbo-admin</p><h3 id="3-6-服务列表说明"><a href="#3-6-服务列表说明" class="headerlink" title="3.6 服务列表说明"></a>3.6 服务列表说明</h3><table><thead><tr><th>服务</th><th>服务端口</th><th>web ui 端口</th></tr></thead><tbody><tr><td>memcache</td><td>11211</td><td>无</td></tr><tr><td>zookeeper</td><td>2181</td><td>无</td></tr><tr><td>rabbitmq</td><td>5672</td><td>15672</td></tr><tr><td>dubbo-monitor</td><td>7070</td><td>7071</td></tr><tr><td>dubbo-admin</td><td>无</td><td>7073</td></tr></tbody></table><h3 id="3-7-制作分发包"><a href="#3-7-制作分发包" class="headerlink" title="3.7 制作分发包"></a>3.7 制作分发包</h3><pre><code>vagrant package</code></pre><p>上面命令会在当前目录生成一个<code>package.box</code>文件,此文件拷贝到其他服务器,就可以快速搭建系统了.</p><h3 id="3-8-常用vagrant-命令"><a href="#3-8-常用vagrant-命令" class="headerlink" title="3.8 常用vagrant 命令"></a>3.8 常用vagrant 命令</h3><pre><code>#初始化环境,此命令会生成Vagrantfile配置文件,如果当前目录有Vagrantfile,不要执行此命令,直接up吧vagrant init#启动虚拟机  vagrant up#关闭虚拟机  vagrant halt# 重新启动虚拟机,如果Vagrantfile被修改后,执行此命令才能生效.#但是修改cpu相关参数,此命令也不能重新加载配置,这个时候把虚拟机先停下来,#通过ssh tunneling在gui界面里调整vagrant reload #SSH至虚拟机vagrant ssh#查看虚拟机运行状态vagrant status# 销毁当前虚拟机vagrant destroy  #add boxvagrant box add boxname xxx.box#remove boxvagrant box remove boxname#list boxvagrant box list</code></pre><h2 id="4-写在最后"><a href="#4-写在最后" class="headerlink" title="4.写在最后"></a>4.写在最后</h2><p><code>virtual box</code>的性能让人担忧,如果部署应用太多需要仔细权衡下,如果只是搭建单机环境,使用vagrant还是很ok的.</p><p>[^1]: <a href="https://www.virtualbox.org/wiki/Linux_Downloads" target="_blank" rel="noopener"><code>Virtual Box</code>下载地址</a><br>[^2]: <a href="https://www.centos.org/forums/viewtopic.php?t=5603" target="_blank" rel="noopener">unable to find the sources of your current Linux kernel</a><br>[^3]: <a href="http://www.vagrantup.com/downloads.htmlhttp://www.vagrantup.com/downloads.html" target="_blank" rel="noopener"><code>vagrant</code>下载地址</a><br>[^4]: <a href="https://github.com/mitchellh/vagrant/pull/1745" target="_blank" rel="noopener">Static ip addresses on public networks</a><br>[^5]: <a href="https://www.centos.org/forums/viewtopic.php?t=4436" target="_blank" rel="noopener">ext4 file system inconsistency</a><br>[^6]: <a href="https://www.virtualbox.org/manual/ch05.html#iocaching" target="_blank" rel="noopener">Host I/O caching</a><br>[^7]: <a href="http://www.reddit.com/r/linux/comments/1tqlsz/adding_cpus_to_virtualbox_guests_makes_guests/" target="_blank" rel="noopener">Adding CPUs to Virtualbox guests makes guests boot SLOWER</a><br>[^8]: <a href="http://www.vagrantbox.es/" target="_blank" rel="noopener">vagrant base box</a><br>[^9]: <a href="https://github.com/2creatives/vagrant-centos/releases/download/v6.4.2/centos64-x86_64-20140116.box" target="_blank" rel="noopener">vagrant base box CentOS 6.4 x86_64</a></p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vagrant </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年06月Reading Notes</title>
      <link href="/2014-06-reading-notes/"/>
      <url>/2014-06-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Awesome-Sysadmin"><a href="#Awesome-Sysadmin" class="headerlink" title="Awesome Sysadmin"></a>Awesome Sysadmin</h2><p><a href="https://github.com/kahun/awesome-sysadmin" target="_blank" rel="noopener">https://github.com/kahun/awesome-sysadmin</a></p><p>系统管理员的开源资源,资源暴多,技术选型时参考.</p><h2 id="Tengine"><a href="#Tengine" class="headerlink" title="Tengine"></a>Tengine</h2><p><a href="http://dmsimard.com/2014/06/21/a-use-case-of-tengine-a-drop-in-replacement-and-fork-of-nginx/" target="_blank" rel="noopener">http://dmsimard.com/2014/06/21/a-use-case-of-tengine-a-drop-in-replacement-and-fork-of-nginx/</a></p><p>使用tengine来做LB,通过Tengine的<code>unbuffered requests</code>特性实现了上传性能提升.</p><p>不过我自己装tengine启动就遇到了问题.</p><pre><code>the configuration file //Users/bohr/software/tengine/conf/nginx.conf syntax is oknginx: [emerg] mkdir() &quot;//Users/bohr/software/tengine/logs/access.log&quot; failed (21: Is a directory)configuration file //Users/bohr/software/tengine/conf/nginx.conf test failed</code></pre><h2 id="服务器操作系统应该选择-Debian-Ubuntu-还是-CentOS？"><a href="#服务器操作系统应该选择-Debian-Ubuntu-还是-CentOS？" class="headerlink" title="服务器操作系统应该选择 Debian/Ubuntu 还是 CentOS？"></a>服务器操作系统应该选择 Debian/Ubuntu 还是 CentOS？</h2><p><a href="http://www.zhihu.com/question/19599986" target="_blank" rel="noopener">http://www.zhihu.com/question/19599986</a></p><p>生产环境选择操作系统还是要慎重.现在我厂在线上用ubuntu,遇到过几次诡异事件(服务器无缘无故挂了,没有任何日志,时间跳变),看了这篇文章,SA应该会把线上的linux服务器统一了吧.</p><h2 id="web-starter-kit"><a href="#web-starter-kit" class="headerlink" title="web-starter-kit"></a>web-starter-kit</h2><p><a href="https://github.com/google/web-starter-kit" target="_blank" rel="noopener">https://github.com/google/web-starter-kit</a></p><p>Web Starter Kit is a starting point for multi-screen web development. It encompasses opinionated recommendations on boilerplate and tooling for building an experience that works great across multiple devices.</p><h2 id="微服务：分解应用以实现可部署性和可扩展性"><a href="#微服务：分解应用以实现可部署性和可扩展性" class="headerlink" title="微服务：分解应用以实现可部署性和可扩展性"></a>微服务：分解应用以实现可部署性和可扩展性</h2><p><a href="http://www.infoq.com/cn/articles/microservices-intro" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/microservices-intro</a><br><a href="http://microservices.io/index.html" target="_blank" rel="noopener">http://microservices.io/index.html</a></p><p>文章讨论了整体架构和微服务构架的优缺点.对于大型应用而言,微服务架构当然是首选.</p><p>API网关模式用于解耦应用客户端和微服务.我们可能没有考虑对不同的客户端提供不同粒度的服务(不同客户端的网络环境不一样).</p><p>对于非强一致性数据要求的场景,<code>事件驱动的异步更新</code>(服务发布事件声明有些数据发生了变化，其他的服务订阅这些事件并更新它们的数据)解耦了事件的生产者和消费者,简化了开发也提升了可用性.某应用,很多配置数据都存在memcache中,一笔业务需要查询缓存&gt;5次,每次都要去查,感觉很不爽.还是使用本地缓存+事件驱动的异步更新来做比较好.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> tengine </tag>
            
            <tag> web-starter-kit </tag>
            
            <tag> microservice </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年05月Reading Notes</title>
      <link href="/2014-05-reading-notes/"/>
      <url>/2014-05-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="面向GC的Java编程"><a href="#面向GC的Java编程" class="headerlink" title="面向GC的Java编程"></a>面向GC的Java编程</h2><p><a href="http://coolshell.cn/articles/11541.html" target="_blank" rel="noopener">http://coolshell.cn/articles/11541.html</a></p><p>好文,总结的很不错.</p><h2 id="spring-boot-Initializr"><a href="#spring-boot-Initializr" class="headerlink" title="spring boot Initializr"></a>spring boot Initializr</h2><p><a href="http://start.spring.io/" target="_blank" rel="noopener">http://start.spring.io/</a></p><p>有了这个,创建spring boot项目就快了.</p><h2 id="OOM-Killer"><a href="#OOM-Killer" class="headerlink" title="OOM Killer"></a>OOM Killer</h2><p>很早听说OOM Killer这个东东,感觉很神秘.而且以前分析某次线上故障,我得出的结论是OOM Killer,但是没有找到日志,囧!最近在玩vagrant,用的ubuntu box,虚拟机内存分配512m,某应用配置jvm内存<code>-Xms256M -Xmx512m -XX:PermSize=64m -XX:MaxPermSize=256m</code>.应用在启动过程中日志刷了一会儿就不动了,<code>command+c</code>结束后,console报出:</p><pre><code>INFO: Initializing Spring root WebApplicationContext^C./tomcat.sh: line 6:  7649 Killed                  nohup mvn clean tomcat7:run -Dspring.profiles.active=$env -Dsys.name=$sysname &gt; &quot;$logfile&quot; 2&gt;&amp;1 &lt; /dev/null</code></pre><p>找了很久,在<code>/var/log/syslog</code>发现如下日志:</p><pre><code>May 22 09:47:41 vagrant-ubuntu-saucy-64 kernel: [ 5499.448534] Out of memory: Kill process 7649 (java) score 788 or sacrifice childMay 22 09:47:41 vagrant-ubuntu-saucy-64 kernel: [ 5499.449012] Killed process 7649 (java) total-vm:1460964kB, anon-rss:407220kB, file-rss:0kB</code></pre><p>这篇文章解释如何处理<a href="http://www.vpsee.com/2013/10/how-to-configure-the-linux-oom-killer/" target="_blank" rel="noopener">oom</a></p><h2 id="vagrant"><a href="#vagrant" class="headerlink" title="vagrant"></a>vagrant</h2><p><a href="https://github.com/astaxie/Go-in-Action/blob/master/ebook/zh/01.2.md" target="_blank" rel="noopener">https://github.com/astaxie/Go-in-Action/blob/master/ebook/zh/01.2.md</a></p><p><a href="http://blog.segmentfault.com/fenbox/1190000000264347" target="_blank" rel="noopener">http://blog.segmentfault.com/fenbox/1190000000264347</a></p><p><a href="http://docs.vagrantup.com/v2/getting-started/index.html" target="_blank" rel="noopener">http://docs.vagrantup.com/v2/getting-started/index.html</a></p><p>如果mac环境下虚拟机出现Failed to load VMMR0.r0 (VERR_SUPLIB_WORLD_WRITABLE),执行<code>sudo chmod o-w /Applications</code>再试试.</p><h2 id="构建高可用系统的常用招数"><a href="#构建高可用系统的常用招数" class="headerlink" title="构建高可用系统的常用招数"></a>构建高可用系统的常用招数</h2><p> <a href="http://bluedavy.me/?p=468" target="_blank" rel="noopener">http://bluedavy.me/?p=468</a></p><p>大牛的总结,分享+总结下:</p><ol><li><p>监控和报警</p><p>  监控和报警能提前发现问题/缩短故障时间,前提是得能正确的评估监控点.</p></li><li><p>SPoF(Single Point of Failure)</p><p>  单点故障也分层次的,不过我们coder一般只关注服务层面.服务尽量做到无状态,只需要做负载就ok了.不能做成无状态的就需要做集群了.实在不行的就做成主备.</p></li><li><p>解耦</p><p> 后端业务通过消息/事件来解耦(Eventbus也不错),前端页面模块化,互相不影响.</p></li><li><p>隔离</p><p> 隔离既要防止依赖的系统之间相互影响(防止故障传播),也要防止同一节点上的不同服务相互影响(资源隔离).</p><p> 宏观层面,区分服务重要性,如果都能服务化就好做了.不同服务可以选择配置不同个数的服务节点.重要的,访问量大的就多加点节点.这需要监控系统能准确评估服务访问情况.</p><p> 微观层面,在服务内部,服务对外提供的能力一般通过线程池大小和请求队列长度来控制.在这里,大不一定就好,多也不定就好.</p></li></ol><ol><li><p>容灾</p><p>  这里谈了几点:超时控制/非关键业务自动降级(用dubbo实现就很方便)/手动降级/自恢复能力(比如druid连接池)/自我保护能力</p></li></ol><p>自己补充点,快速故障恢复能力(日志很重要)/避免人为故障(减少开发人员犯错误的机会)/简单可依赖(能简单做的就绝对不玩花哨) </p><h2 id="Uses-MySQL-to-store-schema-less-data"><a href="#Uses-MySQL-to-store-schema-less-data" class="headerlink" title="Uses MySQL to store schema-less data"></a>Uses MySQL to store schema-less data</h2><p><a href="http://backchannel.org/blog/friendfeed-schemaless-mysql" target="_blank" rel="noopener">http://backchannel.org/blog/friendfeed-schemaless-mysql</a></p><p>如何用mysql来存储schema-less的数据,实现很简单.</p><p>数据表:</p><pre><code>CREATE TABLE entities (    added_id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,    id BINARY(16) NOT NULL,        updated TIMESTAMP NOT NULL,    body MEDIUMBLOB,    UNIQUE KEY (id),    KEY (updated)) ENGINE=InnoDB;</code></pre><p>假如内容是:</p><pre><code>{    &quot;id&quot;: &quot;71f0c4d2291844cca2df6f486e96e37c&quot;,    &quot;user_id&quot;: &quot;f48b0440ca0c4f66991c4d5f6a078eaf&quot;,    &quot;feed_id&quot;: &quot;f48b0440ca0c4f66991c4d5f6a078eaf&quot;,    &quot;title&quot;: &quot;We just launched a new backend system for FriendFeed!&quot;,    &quot;link&quot;: &quot;http://friendfeed.com/e/71f0c4d2-2918-44cc-a2df-6f486e96e37c&quot;,    &quot;published&quot;: 1235697046,    &quot;updated&quot;: 1235697046,}</code></pre><p>如果要给title建立索引,创建新表</p><pre><code>CREATE TABLE index_title (    title varchar(100) ,    entity_id BINARY(16) NOT NULL UNIQUE,       PRIMARY KEY (user_id, entity_id)) ENGINE=InnoDB;</code></pre><p>查询的时候先从索引表查出entity_id,然后在去entities表查询详细数据.可以存储数据为text,方便数据库直接操作(必要性不是很大,text太占内存了),当然最好还是存储压缩后的二进制数据.不是经常改动的数据,应用层在加上一层cache.</p><p>索引可以异步建立,定时任务周期性的去找updated的新数据.</p><h2 id="为什么tomcat应用三分钟还关不掉"><a href="#为什么tomcat应用三分钟还关不掉" class="headerlink" title="为什么tomcat应用三分钟还关不掉"></a>为什么tomcat应用三分钟还关不掉</h2><p>这种问题一般是因为还有非deamon线程在容器关闭时没有正确的关闭导致的.可以在执行tomcat shutdown脚本后,jstack线程栈,看下还有哪些非deamon线程在执行.</p><p>应用使用线程持一定要记得关闭线程池,可以用spring提供的.</p><pre><code>&lt;bean id=&quot;taskExecutor&quot;      class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt;    &lt;property name=&quot;corePoolSize&quot; value=&quot;10&quot;/&gt;    &lt;property name=&quot;keepAliveSeconds&quot; value=&quot;200&quot;/&gt;    &lt;property name=&quot;maxPoolSize&quot; value=&quot;50&quot;/&gt;    &lt;property name=&quot;queueCapacity&quot; value=&quot;1000&quot;/&gt;    &lt;property name=&quot;awaitTerminationSeconds&quot; value=&quot;60&quot;/&gt;    &lt;property name=&quot;waitForTasksToCompleteOnShutdown&quot; value=&quot;true&quot;/&gt;&lt;/bean&gt;</code></pre><p>注意最后面两个参数.</p><h2 id="The-New-RBAC-Resource-Based-Access-Control"><a href="#The-New-RBAC-Resource-Based-Access-Control" class="headerlink" title="The New RBAC: Resource-Based Access Control"></a>The New RBAC: Resource-Based Access Control</h2><p>最近看看shiro的相关资料,看到这篇文章.以前也隐隐约约思考过权限控制,也感觉<a href="http://en.wikipedia.org/wiki/Role-Based_Access_Control" target="_blank" rel="noopener">RBAC</a>控制粒度太粗了.作者提到<code>Explicit Access Control</code>概念,通过资源来解耦角色,控制粒度更细.从权限的分配角度来说,这样使用也更方便,可以把权限分配到某个用户/某个组/某个角色.</p><p>当然,我们把资源的权限和角色一一对于,角色有层次关系并且可以继承,RBAC也可以胜任细粒度的权限控制.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> OOM Killer </tag>
            
            <tag> vagrant </tag>
            
            <tag> cxf unexpected element </tag>
            
            <tag> 构建高可用系统 </tag>
            
            <tag> tomcat </tag>
            
            <tag> maven </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>maven 传递依赖检查</title>
      <link href="/maven-transitive-dependency-exception/"/>
      <url>/maven-transitive-dependency-exception/</url>
      <content type="html"><![CDATA[<h2 id="传递依赖检查"><a href="#传递依赖检查" class="headerlink" title="传递依赖检查"></a>传递依赖检查</h2><p>我们通过maven插件<code>org.apache.maven.plugins:maven-enforcer-plugin</code>启用<code>&lt;requireUpperBoundDeps/&gt;</code><br>来检查传递依赖是否高于直接依赖,如果传递依赖的版本比直接依赖的版本高,则打包失败.</p><p><code>&lt;requireUpperBoundDeps/&gt;</code>解释如下:</p><pre><code>IF:    A--&gt;B1--&gt;C2    A--&gt;C1    C2&gt;C1THEN:    throw Exception;</code></pre><p>我觉得这个检查很有必要,但是解析的范围太宽了.一个项目依赖了很多的开源组件,我们最好是限制这个检查只检查我们自己的jar包.</p><p>修改插件默认行为,在<code>org.apache.maven.plugins.enforcer.RequireUpperBoundDeps$RequireUpperBoundDepsVisitor#containsConflicts</code>中加入:</p><pre><code>String key=  resolvedPair.constructKey();if(key!=null &amp;&amp; !key.startsWith(&quot;com.xxx&quot;)){//不检查groupId中包括非com.xxx开头的jar包      return false;}    </code></pre><h2 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h2><p>下面说下检查出来的提示信息分析,比如下面的情况:</p><pre><code>Failed while enforcing RequireUpperBoundDeps. The error(s) are [    Require upper bound dependencies error for xxx.interchange:interchange-facade-settle:1.0.0.20121009 paths to dependency are:    +-xxx.ppm:ppm-integration:1.0.1.6          +-xxx.interchange:interchange-facade-settle:1.0.0.20121009    and    +-xxx.ppm:ppm-integration:1.0.1.6          +-xxx.core.payengine:payengine-facade:2.0.0.20140314                +-xxx.interchange:interchange-facade-settle:1.0.0.20121009 (managed) &lt;-- xxx.interchange:interchange-facade-settle:1.3.0.20140303</code></pre><p>第一个告诉我们<code>ppm-integration</code>–&gt;<code>interchange-facade-settle:1.0.0.20121009</code>.</p><p>第二个告诉我们<code>ppm-integration</code>–&gt;<code>payengine-facade:2.0.0.20140314</code>–&gt;<code>interchange-facade-settle:1.3.0.20140303</code></p><p>根据maven <code>最短路径优先原则</code>,<code>ppm-integration</code>最终会依赖<code>interchange-facade-settle:1.0.0.20121009</code>.但是<code>payengine-facade:2.0.0.20140314</code>它依赖<code>interchange-facade-settle:1.3.0.20140303</code>.如果classpath中只有<code>interchange-facade-settle:1.0.0.20121009</code>,运行时<code>payengine-facade</code>就有可能报找不到类,找不到方法之类的错误.</p><p>遇到这样的场景,最好是修改我们项目的直接依赖,让<code>ppm-integration</code>–&gt;<code>interchange-facade-settle:1.3.0.20140303</code>,然后测试下是否ok.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> maven </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>烦人的cxf unexpected element 异常</title>
      <link href="/cxf-unexpected-element/"/>
      <url>/cxf-unexpected-element/</url>
      <content type="html"><![CDATA[<h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1.背景"></a>1.背景</h3><p>当cxf传输的数据对象结构变化时,比如请求对象减少了字段,响应对象增加了字段,在jaxb unmarsh时会抛出异常,导致接口访问失败.</p><pre><code>javax.xml.bind.UnmarshalException: unexpected element (uri:&quot;&quot;, local:&quot;name&quot;). Expected elements are &lt;{}name&gt;</code></pre><p>上面这是一个典型的<code>unexpected element</code>异常,如果cxf客户端请求中多了一个<code>name</code>属性,或者cxf服务端响应中多了一个<code>name</code>属性,都会导致此异常.</p><h3 id="2-源代码分析"><a href="#2-源代码分析" class="headerlink" title="2.源代码分析"></a>2.源代码分析</h3><p>翻了下源代码:</p><p><code>com.sun.xml.bind.v2.runtime.unmarshaller.StructureLoader#childElement</code>检查是否是新增属性</p><pre><code> @Overridepublic void childElement(UnmarshallingContext.State state, TagName arg) throws SAXException {    ChildLoader child = childUnmarshallers.get(arg.uri,arg.local);    if(child==null) {//检查是否新增属性        child = catchAll;        if(child==null) {            super.childElement(state,arg);            return;        }    }    state.loader = child.loader;    state.receiver = child.receiver;}</code></pre><p>在<code>com.sun.xml.bind.v2.runtime.unmarshaller.Loader</code>中检查是否处理此问题</p><pre><code> public void childElement(UnmarshallingContext.State state, TagName ea) throws SAXException {    // notify the error, then recover by ignoring the whole element.    reportUnexpectedChildElement(ea, true);    state.loader = Discarder.INSTANCE;    state.receiver = null;}@SuppressWarnings({&quot;StringEquality&quot;})protected final void reportUnexpectedChildElement(TagName ea, boolean canRecover) throws SAXException {    if(canRecover &amp;&amp; !UnmarshallingContext.getInstance().parent.hasEventHandler())    //这里默认会有个EventHandler,不会直接忽略此问题        // this error happens particurly often (when input documents contain a lot of unexpected elements to be ignored),        // so don&apos;t bother computing all the messages and etc if we know that        // there&apos;s no event handler to receive the error in the end. See #286         return;     //下面的代码抛出异常    if(ea.uri!=ea.uri.intern() || ea.local!=ea.local.intern())        reportError(Messages.UNINTERNED_STRINGS.format(), canRecover );    else        reportError(Messages.UNEXPECTED_ELEMENT.format(ea.uri,ea.local,computeExpectedElements()), canRecover );}</code></pre><p>在<code>org.apache.cxf.jaxb.io.DataReaderImpl#createUnmarshaller</code>中设置了<code>EventHandler</code>,注意这里的<code>veventHandler</code>,默认是没有的.</p><pre><code>if (setEventHandler) {            um.setEventHandler(new WSUIDValidationHandler(veventHandler));}</code></pre><p> <code>org.apache.cxf.jaxb.io.DataReaderImpl.WSUIDValidationHandler</code>的代码很简单:</p><pre><code>private static class WSUIDValidationHandler implements ValidationEventHandler {    ValidationEventHandler origHandler;    WSUIDValidationHandler(ValidationEventHandler o) {        origHandler = o;    }    public boolean handleEvent(ValidationEvent event) {        String msg = event.getMessage();        System.out.println(&quot;WSUIDValidationHandler&quot;+msg);        if (msg != null                &amp;&amp; msg.contains(&quot;:Id&quot;)                &amp;&amp; (msg.startsWith(&quot;cvc-type.3.1.1: &quot;)                || msg.startsWith(&quot;cvc-type.3.2.2: &quot;)                || msg.startsWith(&quot;cvc-complex-type.3.1.1: &quot;)                || msg.startsWith(&quot;cvc-complex-type.3.2.2: &quot;))) {            return true;        }        if (origHandler != null) {            return origHandler.handleEvent(event);        }        return false;    }}</code></pre><p>先自己处理,自己处理不了的交给<code>origHandler</code>,那我们只需要自己构建一个<code>javax.xml.bind.ValidationEventHandler</code>来专门处理<code>unexpected element</code>异常,问题就得到了解决.</p><p><code>org.apache.cxf.jaxb.io.DataReaderImpl#setProperty</code>中有段代码:</p><pre><code>veventHandler = (ValidationEventHandler)m.getContextualProperty(&quot;jaxb-validation-event-handler&quot;);       if (veventHandler == null) {           veventHandler = databinding.getValidationEventHandler();       }</code></pre><p> 如果配置了<code>jaxb-validation-event-handler</code>属性,就可以让我们自己的<code>javax.xml.bind.ValidationEventHandler</code>来处理此异常.也可以设置<code>setEventHandler</code>为<code>false</code>,不设置异常处理器,忽略所有unmarsh异常,不过这样我感觉太暴力了点,这样做也忽略了<code>org.apache.cxf.jaxb.io.DataReaderImpl.WSUIDValidationHandler</code>的逻辑,点儿都不科学.</p><h3 id="3-实现"><a href="#3-实现" class="headerlink" title="3.实现"></a>3.实现</h3><p> 上面分析清楚了,实现就很简单,实现<code>javax.xml.bind.ValidationEventHandler</code></p><pre><code>public class IgnoreUnexpectedElementValidationEventHandler implements ValidationEventHandler {        private static final Logger logger = LoggerFactory.getLogger(IgnoreUnexpectedElementValidationEventHandler.class);        @Override        public boolean handleEvent(ValidationEvent event) {                String msg = event.getMessage();                if (msg != null &amp;&amp; msg.startsWith(&quot;unexpected element&quot;)) {                    logger.warn(&quot;{}&quot;, msg);                    return true;             }              return false;        }}</code></pre><p> 在<code>cxf:bus</code>中配置下就ok</p><pre><code>  &lt;cxf:bus&gt;    &lt;cxf:properties&gt;        &lt;entry key=&quot;jaxb-validation-event-handler&quot;&gt;            &lt;bean class=&quot;IgnoreUnexpectedElementValidationEventHandler&quot;/&gt;        &lt;/entry&gt;    &lt;/cxf:properties&gt;&lt;/cxf:bus&gt;</code></pre><p> 建议只在线上环境启用此东东,线下还是不要开启,早点发现问题是好事.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cxf </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>java对象属性复制</title>
      <link href="/pojo-perperty/"/>
      <url>/pojo-perperty/</url>
      <content type="html"><![CDATA[<p>java对象属性复制的工具类很多,常用的有<code>org.springframework.beans.BeanUtils#copyProperties</code>,<code>org.apache.commons.beanutils.BeanUtils#copyProperties</code>,这两个都是通过反射实现的,性能嘛,你关心TA就在那里,你不关心TA还是在那里.<br><a id="more"></a><br>高级点的有<code>net.sf.cglib.beans.BeanCopier</code>,通过生成源代码实现属性复制,但是他的api很难使用.而且不支持基本类型和包装器类型的转换(java的boxing和unboxing只是语法糖而已).</p><p>so,重新造了个轮子,采用javassit来生成源代码,并且提供方便使用的api.</p><p>使用就像下面这样:</p><pre><code>TestBean target = new TestBean();Copier.copy(TestBean1.createTest(), target);</code></pre><p>TA生成的源代码如下:</p><pre><code>public class CopierImpl1002  implements Copier.Copy{  public void copy(Object paramObject1, Object paramObject2)  {    TestBean localTestBean = (TestBean)paramObject1;    TestBean1 localTestBean1 = (TestBean1)paramObject2;    if (localTestBean.getA1() != null)          localTestBean1.setA1(localTestBean.getA1().longValue());    localTestBean1.setA10(localTestBean.getA10());        localTestBean1.setA2(localTestBean.isA2());       localTestBean1.setA3(Integer.valueOf(localTestBean.getA3()));       localTestBean1.setB8(Short.valueOf(localTestBean.getB8()));        localTestBean1.setList(localTestBean.getList());  }}</code></pre><p>源代码见:<a href="https://gist.github.com/bohrqiu/5046a2a7d983996f0e5a" target="_blank" rel="noopener">https://gist.github.com/bohrqiu/5046a2a7d983996f0e5a</a></p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java properties copy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年04月Reading Notes</title>
      <link href="/2014-04-reading-notes/"/>
      <url>/2014-04-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="oh-my-zsh"><a href="#oh-my-zsh" class="headerlink" title="oh-my-zsh"></a><a id="zsh">oh-my-zsh</a></h2><p><a href="https://github.com/robbyrussell/oh-my-zsh/wiki/Plugins-Overview" target="_blank" rel="noopener">https://github.com/robbyrussell/oh-my-zsh/wiki/Plugins-Overview</a></p><p><a href="https://github.com/robbyrussell/oh-my-zsh/wiki/Themes" target="_blank" rel="noopener">https://github.com/robbyrussell/oh-my-zsh/wiki/Themes</a></p><p>zsh才是王道啊,各种插件,很爽.</p><p>我用<code>colored-man colorize sublime mvn terminalapp</code>插件.theme用<code>avit</code>,再装上<a href="http://ethanschoonover.com/solarized" target="_blank" rel="noopener">Solarized Dark</a>,prefect!!!</p><a id="more"></a><h2 id="Portia-the-open-source-visual-web-scraper"><a href="#Portia-the-open-source-visual-web-scraper" class="headerlink" title="Portia, the open source visual web scraper!"></a>Portia, the open source visual web scraper!</h2><p><a href="http://blog.scrapinghub.com/2014/04/01/announcing-portia/" target="_blank" rel="noopener">http://blog.scrapinghub.com/2014/04/01/announcing-portia/</a></p><p><a href="https://github.com/scrapinghub/portia" target="_blank" rel="noopener">https://github.com/scrapinghub/portia</a></p><p>可视化的网页抓取工具,多么牛掰啊.</p><h2 id="java8-javadoc对格式要求更严格了"><a href="#java8-javadoc对格式要求更严格了" class="headerlink" title="java8,javadoc对格式要求更严格了."></a>java8,javadoc对格式要求更严格了.</h2><p><a href="http://docs.oracle.com/javase/8/docs/technotes/guides/javadoc/whatsnew-8.html" target="_blank" rel="noopener">http://docs.oracle.com/javase/8/docs/technotes/guides/javadoc/whatsnew-8.html</a></p><p>The javadoc tool now has support for checking the content of javadoc comments for issues that could lead to various problems, such as invalid HTML or accessibility issues, in the files that are generated by javadoc. The feature is enabled by default, and can also be controlled by the new -Xdoclint option. For more details, see the output from running “javadoc -X”. This feature is also available in javac, although it is not enabled by default there.</p><p>所以以前能成功生成文档的现在变为:</p><pre><code>/Users/bohr/code/yjf/maven-plugin/target/generated-sources/plugin/com/yiji/maven/HelpMojo.java:26: warning: no description for @author * @author   ^/Users/bohr/code/yjf/maven-plugin/target/generated-sources/plugin/com/yiji/maven/    HelpMojo.java:27: warning: no description for @version * @version   ^</code></pre><p>修改maven doc插件如下,忽略异常先:</p><pre><code> &lt;plugin&gt;    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;    &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;    &lt;version&gt;2.9.1&lt;/version&gt;    &lt;configuration&gt;        &lt;failOnError&gt;false&lt;/failOnError&gt;    &lt;/configuration&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;attach-javadocs&lt;/id&gt;            &lt;goals&gt;                &lt;goal&gt;jar&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;</code></pre><h2 id="Performance-Considerations-in-Distributed-Applications"><a href="#Performance-Considerations-in-Distributed-Applications" class="headerlink" title="Performance Considerations in Distributed Applications"></a>Performance Considerations in Distributed Applications</h2><p><a href="http://apmblog.compuware.com/2009/09/28/performance-considerations-in-distributed-applications/" target="_blank" rel="noopener">http://apmblog.compuware.com/2009/09/28/performance-considerations-in-distributed-applications/</a></p><p>一篇老文,主要谈到了分布式应用中一些性能关注点.文章部分内容加上自己总结如下:</p><h3 id="The-devil-in-disguise"><a href="#The-devil-in-disguise" class="headerlink" title="The devil in disguise"></a>The devil in disguise</h3><ol><li><p>序列化</p><p> 序列化的重要性体现在,序列化本身需要消耗的cpu时间,而且序列化后的内容的大小也会影响传输时间.一般来说用二进制协议效率更高.soap协议最好还是不要在内部使用了:第一,序列化和反序列化效率不高(<a href="https://fi.java.net/" target="_blank" rel="noopener">FI</a>应该会快,没亲测);第二,里面无意义的信息太多了.</p><p> 除了性能,还要考虑易用性,也就是说序列化后数据的兼容性问题.这个处理不好就会引起非常严重的事故.so,我们现在的dubbo序列化选hessian,分布式缓存/消息中间件中用到序列化的地方用的是兼容性的kryo(带有字段信息).等以后性能问题凸显的时候,会考虑用dubbo自带的序列化或者kryo.在数据量较大的交互时,还需要考虑提供阀值压缩数据.</p><p> 虽然分布式服务框架一般会提供多版本功能,理论上是不要考虑兼容性的.每次升级接口时,升级版本就搞定.但是在服务器不是足够多的情况下,还是不考虑了,增加了运维成本.</p></li><li><p>CONNECTIONS</p><p> 这个不多说,长连接+连接池.这里需要注意的是,长连接一定要有心跳机制来保活.</p></li><li><p>线程模型</p><p> 原文只是谈到了同步和异步处理,现在比较好的做法是有专门的io线程来io请求.不过最好不要在io线程上做序列化和反序列的操作.让io线程单纯点,io处理能力更强.</p></li><li><p>网络</p><p> 这点确实容易忽掉,而且很多开发人员对网络都不是很熟悉(include me!),万兆(40G?)交换机+千兆网卡应该是必须的吧.</p></li></ol><h3 id="The-beauty-of-remoting-technologies-is-…"><a href="#The-beauty-of-remoting-technologies-is-…" class="headerlink" title="The beauty of remoting technologies is …"></a>The beauty of remoting technologies is …</h3><p>   这部分作者说了不少,我的观点是:java自带的序列化比较慢,最好不要用;distributed garbage collector 最好不要碰;内部系统不要玩<code>WS-*</code>;消息中间件是个好东东,一般企业到后期还是会需要到消息总线,不过神马都往总线里面丢,最终ESB implementor自己就是瓶颈,合理的规划业务很重要.</p><h3 id="What-can-go-wrong"><a href="#What-can-go-wrong" class="headerlink" title="What can go wrong"></a>What can go wrong</h3><ol><li><p>Anti Pattern: Wrong Protocol</p><p> 选择合适的协议,内部通信就不要用webservice了.涉及到互操性的场景,可以考虑hessian提供的二进制协议.</p></li><li><p>Anti Pattern: Chatty Application</p><p> 总的来说就是,<code>分布式对象设计第一定律:不要分布式使用对象</code>,尽量减少远程调用+粗粒度的接口+读缓存.</p></li><li><p>Anti Pattern: Big Messages</p><p> 接口不要携带多余的,不相关的信息.这条和上条需要仔细权衡了.</p></li><li><p>Anti Pattern: Distributed Deployment</p><p> 还是分布式对象设计第一定律.</p></li></ol><h2 id="Don‘t-Trust-Your-Log-Files-How-and-Why-to-Monitor-ALL-Exceptions"><a href="#Don‘t-Trust-Your-Log-Files-How-and-Why-to-Monitor-ALL-Exceptions" class="headerlink" title="Don‘t Trust Your Log Files: How and Why to Monitor ALL Exceptions"></a><a id="Exceptions">Don‘t Trust Your Log Files: How and Why to Monitor ALL Exceptions</a></h2><p><a href="http://apmblog.compuware.com/2014/04/01/dont-trust-your-log-files-how-and-why-to-monitor-all-exceptions/" target="_blank" rel="noopener">http://apmblog.compuware.com/2014/04/01/dont-trust-your-log-files-how-and-why-to-monitor-all-exceptions/</a></p><p>异常开销比较大,所以,业务异常尽量不要去收集栈信息,还要去属性第三方api,减少异常被吞掉的情况.可以参考下这篇<a href="http://bohr.me/jdk7-exception/">blog</a>.</p><h2 id="Heartbleed-test"><a href="#Heartbleed-test" class="headerlink" title="Heartbleed test"></a>Heartbleed test</h2><p><a href="http://filippo.io/Heartbleed/" target="_blank" rel="noopener">http://filippo.io/Heartbleed/</a></p><p>c语言没处理好是多么的恐怖啊.</p><h2 id="tomcat关闭时出现NoClassDefFoundError"><a href="#tomcat关闭时出现NoClassDefFoundError" class="headerlink" title="tomcat关闭时出现NoClassDefFoundError"></a><a id="tomcat_NoClassDefFoundError">tomcat关闭时出现NoClassDefFoundError</a></h2><p>某dubbo应用,在tomcat在关闭时,报了下面的异常,</p><pre><code>java.lang.NoClassDefFoundError: org/jboss/netty/util/internal/ExecutorUtil</code></pre><p>so,顺便分析下tomcat容器关闭时的内存泄漏检测机制.</p><p>首先有个三个东东:</p><ol><li><p><code>org.apache.catalina.core.JreMemoryLeakPreventionListener</code></p><p> 普通的java程序的类加载顺序是由父到子(先在父classloader中找,找不到在到子classloader中加载),这样做是为了安全和节省内存.web容器类加载器为了做到隔离,一般先是在子classloader中找,找不到在委托给父classloader.</p><p> 此listener主要是通过使用java classloader或者tomcat 系统classloader来加载类,避免<code>WebappClassLoader</code>加载类后reload释放不了,同时也避免了内存浪费.还对一些东东进行了调整.</p><p> 源代码中段话说的很形象:<code>Use the system classloader as the victim for all this ClassLoader pinning we&#39;re about to do.</code></p></li><li><p><code>org.apache.catalina.loader.WebappClassLoader</code></p><p> 相关逻辑主要在<code>stop</code>方法中:</p><ul><li>调用<code>org.apache.catalina.loader.JdbcLeakPrevention</code> 来deregister Driver</li><li>找出所有应用线程,如果线程还在执行,则打印警告信息.如果启用了<code>clearReferencesStopThreads</code>,使用反射来关闭线程池或者线程.</li><li>清理ThreadLocal</li><li>清理各种cache…</li><li>清理资源路径</li></ul></li></ol><pre><code>&lt;a id=&quot;load_class_step&quot; class=&quot;anchor&quot;&gt;加载类步骤&lt;/a&gt;:1. 判断WebappClassLoader是否关闭,如果已关闭,报异常,打印日志2. 检查resourceEntries缓存3. 使用当前类加载器加载4. 使用SystemClassLoader加载5. 如果启用delegate,从父加载器加载6. 从`WEB-INFO/classes`和`WEB-INFO/lib`目录加载7. 用父类加载器来加载8. 加载不到抛出`ClassNotFoundException`</code></pre><ol><li><p><code>org.apache.catalina.core.ThreadLocalLeakPreventionListener</code></p><p> 清理线程池.</p></li></ol><p>再分析下dubbo怎么关闭的:</p><ol><li>dubbo中的每个provide都是<code>ServiceBean</code>对象,此对象实现<code>DisposableBean</code>.在容器关闭时,<code>ServiceBean</code>取消注册.</li><li><code>com.alibaba.dubbo.config.AbstractConfig</code>中注册了一个<code>ShutdownHook</code>,调用<code>ProtocolConfig.destroyAll()</code>,清理资源(比如关闭和注册中心的连接和关闭netty)</li></ol><p>这里需要注意下,调用<code>org.apache.catalina.loader.WebappClassLoader#stop</code>和调用<code>ProtocolConfig.destroyAll()</code>的不是同一个线程.而且<code>org.apache.catalina.loader.WebappClassLoader#started</code>字段并不是<code>volatile</code>的,有可能出现并发状态下的的不一致.这个时候,<code>WebappClassLoader</code>已经<code>started=true</code>了,然而<code>ShutdownHook</code>线程读到的值为false,继续去加载类,由于各种缓存也清空了,最终会抛出<code>ClassNotFoundException</code>(参考<a href="#load_class_step">加载步骤</a>)</p><p>参考:</p><pre><code>http://wiki.apache.org/tomcat/MemoryLeakProtection</code></pre><h2 id="实战-Groovy-使用闭包、ExpandoMetaClass-和类别进行元编程"><a href="#实战-Groovy-使用闭包、ExpandoMetaClass-和类别进行元编程" class="headerlink" title="实战 Groovy: 使用闭包、ExpandoMetaClass 和类别进行元编程"></a>实战 Groovy: 使用闭包、ExpandoMetaClass 和类别进行元编程</h2><p><a href="http://www.ibm.com/developerworks/cn/java/j-pg06239.html" target="_blank" rel="noopener">http://www.ibm.com/developerworks/cn/java/j-pg06239.html</a></p><p><code>println &quot;ifconfig en0&quot;.execute().text</code>,这行代码使用fluent api+元编程,执行linux命令,打印结果.</p><p>这个特性对于测试同学来说就非常重要,就这么直接mock原类的行为,很方便.</p><h2 id="Venkat-Subramaniam-讨论多语言编程、JVM-和多核处理"><a href="#Venkat-Subramaniam-讨论多语言编程、JVM-和多核处理" class="headerlink" title="Venkat Subramaniam 讨论多语言编程、JVM 和多核处理"></a>Venkat Subramaniam 讨论多语言编程、JVM 和多核处理</h2><p>这篇文章很精彩,看了这篇文章有学习scala和groovy的冲动.摘录一些原文比较精彩的内容:</p><h3 id="1-关于多语言编程"><a href="#1-关于多语言编程" class="headerlink" title="1.关于多语言编程"></a>1.关于多语言编程</h3><p>Ola Bini 曾在他的语言金字塔中很好地阐述关于语言。在语言金字塔中,Scala 或 Java 可以非常有效地编写基础架构代码。在此基础之上，他谈到了一个更具动态性的分层。在这一层中，利用元编程功能。可以说，元编程带来的最大优势就是能够减少您需要编写的代码量。最直观的体验就是代码数量的减少，您可以在代码中编写非常灵活的内容。在此基础之上，金字塔的塔尖是更为特定于领域的语言层，即 DSL 层。</p><p>使用动态语言编程时，最重要的是设定更出色的准则，以便指导单元测试的编写，确保代码不会偏离原意，准确执行您希望的操作</p><h3 id="2-关于多核并行"><a href="#2-关于多核并行" class="headerlink" title="2.关于多核并行:"></a>2.关于多核并行:</h3><p>一种方法是推行不可变性，也就是说：我不会更改任何东西。您处理的所有数据都是不可变，由于不可变，因此也不需<br>要同步。这解决了冲突问题，但我要如何在线程间通信？如何交换数据？为此，我们可以使用 Erlang 和 Scala 奉行的基于 Actor 的模型。使用 Actor，然后通过来回传递数据在 Actor 之间通信，但数据仍然保持不可变，整个过程极为安全。</p><p>软件事务处理内存模型所做的是将您的数据访问绑定到事务边界内，就像数据库为您提供 ACID（原子性、一致性、隔离和持久性）时一样。它为您提供了这种功能，但您无法在内存中实现数据持久性，因此它会处理原子性、一致性和隔离。<br>您可以通过三种方法处理并行性。<strong><em>在解决并行性时,最糟糕的方法就是共享的可变性，这就是同步模型。更好的方法是采用基于 Actor 的模型，在线程间传输不可变数据。如果存在不频繁的写入操作和极其频繁的读取操作，那么第三个选择就是事务软件内存。</em></strong></p><h2 id="Baby’s-First-Garbage-Collector"><a href="#Baby’s-First-Garbage-Collector" class="headerlink" title="Baby’s First Garbage Collector"></a>Baby’s First Garbage Collector</h2><p><a href="http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/" target="_blank" rel="noopener">http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/</a></p><p><a href="">https://github.com/munificent/mark-sweep/blob/master/main.c</a></p><p>用c实现的一个简单的gc,采用Marking and sweeping的方式,大致能明白gc如何工作了.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> zsh </tag>
            
            <tag> javadoc </tag>
            
            <tag> NoClassDefFoundError </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年03月Reading Notes</title>
      <link href="/2014-03-reading-notes/"/>
      <url>/2014-03-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Volatile-Vs-Static-in-JAVA"><a href="#Volatile-Vs-Static-in-JAVA" class="headerlink" title="Volatile Vs Static in JAVA"></a>Volatile Vs Static in JAVA</h2><p><a href="http://malalanayake.wordpress.com/2013/09/12/volatile-vs-static-in-java/" target="_blank" rel="noopener">http://malalanayake.wordpress.com/2013/09/12/volatile-vs-static-in-java/</a></p><p>volatile能保证原子性和可见性.对static field的内存模型认识不足导致有些概念模糊了.内存结构见图:</p><p><img src="/2014-03-reading-notes/volatilevsstaticinjava.png" alt=""></p><a id="more"></a><h2 id="101-个-MySQL-的调优贴士"><a href="#101-个-MySQL-的调优贴士" class="headerlink" title="101 个 MySQL 的调优贴士"></a>101 个 MySQL 的调优贴士</h2><p><a href="http://www.oschina.net/translate/101-tips-to-mysql-tuning-and-optimization?print" target="_blank" rel="noopener">http://www.oschina.net/translate/101-tips-to-mysql-tuning-and-optimization?print</a></p><p>看数据库相关的文章看到”双缓存””问题.数据库服务把OS cache打开会导致无意义的”预读取”(操作系统层面的随机或者顺序读取文件)和”后写入”(批处理),而且会导致”双缓冲”和昂贵的内存拷贝.”双缓冲”浪费了系统内存,并且浪费了额外的资源处理时间(读:从磁盘到os cache到DBMS cache;写:从DBMS cache 到OS cache 到磁盘).</p><p>搜索双缓存相关的东东,把这篇文章搜索出来了.有几点可以说说(数据库管理层面的I DONT CARE!).</p><pre><code>74.为了 避免在更新前SELECT，使用INSERT ON DUPLICATE KEY或者INSERT IGNORE ,不要用UPDATE去实现。 (这深有体会,以前处于二逼阶段写的存储过程由17行变成了7行,简单依赖啊,减少了查询,减少了并发时的异常处理)81.使用DROP TABLE，CREATE TABLE DELETE FROM从表中删除所有数据。 (为毛不用truncate?)95. 为了更快的进行导入，在导入时临时禁用外键约束。96. 为了更快的进行导入，在导入时临时禁用唯一性检测。</code></pre><h2 id="zookeeper-分布式锁的实现"><a href="#zookeeper-分布式锁的实现" class="headerlink" title="zookeeper 分布式锁的实现"></a>zookeeper 分布式锁的实现</h2><p><a href="http://bohr.me/zookeeper-dev-ops/">http://bohr.me/zookeeper-dev-ops/</a></p><p>给自己写的zookeeper相关的分析添加一个链接地址.</p><h2 id="Spring-Data-Repositories-A-Deep-Dive"><a href="#Spring-Data-Repositories-A-Deep-Dive" class="headerlink" title="Spring Data Repositories - A Deep Dive"></a>Spring Data Repositories - A Deep Dive</h2><p><a href="https://github.com/olivergierke/repositories-deepdive" target="_blank" rel="noopener">https://github.com/olivergierke/repositories-deepdive</a></p><p><a href="http://spring.io/blog/2011/04/26/advanced-spring-data-jpa-specifications-and-querydsl/" target="_blank" rel="noopener">http://spring.io/blog/2011/04/26/advanced-spring-data-jpa-specifications-and-querydsl/</a></p><p>最近在看jpa,spring对jpa的支持确实比较犀利.Querydsl结合APT可以写出类型安全,易读的查询语句.不知道性能如何?</p><pre><code>@Testpublic void testQuerydsl() throws Exception {    QTask $ = QTask.task;    BooleanExpression titleStartWith = $.title.startsWith(&quot;Study&quot;);    BooleanExpression descEndWith = $.description.endsWith(&quot;org/&quot;);    Iterable&lt;Task&gt; result = taskDao.findAll(titleStartWith.and(descEndWith));    for (Task task : result) {        System.out.println(task);    }}</code></pre><p>上面这段代码最后生成的sql如下:</p><pre><code>select    id,raw_add_time,raw_update_time,description,title,user_idfrom    t_task  where    (title like ? escape &apos;!&apos;)    and (description like ? escape &apos;!&apos;)</code></pre><h2 id="ROCA-Resource-oriented-Client-Architecture"><a href="#ROCA-Resource-oriented-Client-Architecture" class="headerlink" title="ROCA Resource-oriented Client Architecture"></a>ROCA Resource-oriented Client Architecture</h2><p>A collection of simple recommendations for decent Web application frontends.<br>可以参考下,</p><h2 id="加盐密码哈希：如何正确使用"><a href="#加盐密码哈希：如何正确使用" class="headerlink" title="加盐密码哈希：如何正确使用"></a>加盐密码哈希：如何正确使用</h2><p><a href="http://blog.jobbole.com/61872/" target="_blank" rel="noopener">http://blog.jobbole.com/61872/</a></p><p>The Enemy Knows The System.看了这篇文章,感觉我们做的东西太少了,对于密码的重视程度还不够,简单总结下:</p><ol><li>永远不要告诉用户到底是用户名错了，还是密码错了</li><li>不要使用短盐值和盐值重复(明白了某开源项目为什么用户表里有个salt字段)</li><li>盐值应该使用基于加密的伪随机数生成器来生成,java里面用<code>java.security.SecureRandom</code></li><li>使用慢哈希函数,java里面用<code>PBKDF2WithHmacSHA1</code>(需要权衡,太慢了会把登录做成DDOS攻击)</li><li>不要使用过时的hash算法,比如MD5或SHA1</li><li>密码重置时令牌应该要有有效期,并且重置时需要生成新的盐值.</li><li>不要过于频繁地强制你的用户修改密码，最多6个月1次(呵呵,bops)</li></ol><p>这些用上基本上就够了.附带赠送一个能够破解任何8位及以下长度MD5值的<a href="https://www.freerainbowtables.com/en/tables2/" target="_blank" rel="noopener">彩虹表</a></p><h2 id="Java中的CopyOnWrite容器"><a href="#Java中的CopyOnWrite容器" class="headerlink" title="Java中的CopyOnWrite容器"></a>Java中的CopyOnWrite容器</h2><p><a href="http://coolshell.cn/articles/11175.html" target="_blank" rel="noopener">http://coolshell.cn/articles/11175.html</a></p><p>以前只是把CopyOnWrite用于拦截器这些场景,看来用于黑/白名单也挺适合的.特别是<code>CopyOnWriteMap</code>,很适合读写比例很大的场景.</p><p>不过原文中提到的<code>内存占用问题</code>,我不赞同此问题,map本身的数据结构是Entry,这个Entry会上百M?<code>Arrays.copyOf</code>和<code>java.util.HashMap#HashMap(java.util.Map&lt;? extends K,? extends V&gt;)</code>都不是深拷贝.</p><h2 id="5-Techniques-to-Improve-Your-Server-Logging"><a href="#5-Techniques-to-Improve-Your-Server-Logging" class="headerlink" title="5 Techniques to Improve Your Server Logging"></a>5 Techniques to Improve Your Server Logging</h2><p><a href="http://www.takipiblog.com/2014/02/27/5-techniques-to-improve-your-server-logging/" target="_blank" rel="noopener">http://www.takipiblog.com/2014/02/27/5-techniques-to-improve-your-server-logging/</a></p><p>文章提到5个处理服务器端日志的细节.值得分享下:</p><ol><li><p>Hello my (Thread) name is</p><p>给线程取一个合理的名字.在开发云消息中间件时,考虑到便于跟踪业务执行轨迹,统一用msgid来作为线程的名字.</p><p>现在想起来还是比较土,当时不知道有<a href="http://logback.qos.ch/manual/mdc.html" target="_blank" rel="noopener">MDC</a>这个概念(2012年看到这个概念还很<a href="http://www.weibo.com/1880205234/yyHbX4elU?mod=weibotime" target="_blank" rel="noopener">兴奋</a>).现在我写的系统中,基本上都引入了MDC这个东东,方便自己定位问题.</p></li><li><p>Distributed identifiers</p><p> 每个业务请求需要一个唯一的业务标识.这个必须有,写了<code>ID</code>就是来干这事的.我很赞同作者的观点,<code>every inbound operation going into your system should have a unique ID which will travel with it until it’s completed.</code>,我们的gid改造还没有结束,哈哈.</p></li><li><p>Dont text + drive. Don’t log + loop</p><p> 在循环里面处理日志要小心,作者举的例子是加了一个打印日志次数的限制.在<code>while</code>循环里处理东东都要小心,最近给某项目分析定时任务没有执行的问题,发现循环中插入数据库,结果悲剧了,死循环一直插,数据库表示好伤啊.</p></li><li><p>Uncaught handlers</p><p> 给线程加上未捕获的异常处理器.</p><p> 在和peigen讨论摘要日志时,提到了要加这个东东,结果真的给忘了.哎,真的老了么?忘事太容易了.真得注意下防御性编程了.openapi使用摘要日志api有问题,导致空指针异常,我在代码中加了一行error日志<code>由于api使用不当导致线程本地变量DL被清空,请仔细检查您的代码.本次操作会重新生成DL对象</code>.但是还有个洞没有塞住.万一使用<code>SDL</code>时,没有在<code>final block</code>中调用<code>SDL.end()</code>,最终会导致OOM.在<code>Thread.setDefaultUncaughtExceptionHandler</code>时,来清除<code>SDL</code>,也算是一个不错的方式.</p><p> 摘要日志API的设计过程中主要想着能给大家提供方便使用的api.现在易用性已经达到了,但是感觉用得不当太危险了.特别是<code>SDL</code>,<code>ThreadLocal</code>中有个<code>ArrayDeque</code>,万一没有调用<code>SDL.end()</code>,迟早会有OOM.</p><p> 线程变量真可怕!!!</p></li><li><p>Catch external calls</p><p> 外部调用都要catch异常并记录日志.最好也别把异常吞了,重新抛出一个程序内部定义的运行时异常吧.分布式应用外部调用都很多,建议还是统一来处理日志和异常转换,AOP派上用场了.</p></li></ol><p>评论更精彩,有童鞋建议外部调用记录处理时长,用csv来记录日志便于后期处理.摘要日志中有记录时长的,我们用的json来记录日志,更方便处理,只是业务线程需要承担序列化的开销.</p><h2 id="The-Logging-Olympics-–-A-Race-Between-Today’s-Top-5-Java-Logging-Frameworks"><a href="#The-Logging-Olympics-–-A-Race-Between-Today’s-Top-5-Java-Logging-Frameworks" class="headerlink" title="The Logging Olympics – A Race Between Today’s Top 5 Java Logging Frameworks"></a>The Logging Olympics – A Race Between Today’s Top 5 Java Logging Frameworks</h2><p><a href="http://www.takipiblog.com/2013/12/18/the-logging-olympics-a-race-between-todays-top-5-logging-frameworks/" target="_blank" rel="noopener">http://www.takipiblog.com/2013/12/18/the-logging-olympics-a-race-between-todays-top-5-logging-frameworks/</a></p><p>比较了几种日志框架,以前在写<a href="http://bohr.me/2013/07/09/log-tuning.html">日志优化</a>时,注意到了log4j2异常牛掰,特别是采用了<a href="http://logging.apache.org/log4j/2.x/manual/async.html" target="_blank" rel="noopener">disruptor</a>的异步日志,在多线程下的表现非常夸张.不过我们已经被绑架到logback了,只是看看而已.</p><h2 id="First-class-functions-in-Java-8"><a href="#First-class-functions-in-Java-8" class="headerlink" title="First-class functions in Java 8"></a>First-class functions in Java 8</h2><p><a href="http://www.youtube.com/watch?v=Rd-sqHjmfB0" target="_blank" rel="noopener">http://www.youtube.com/watch?v=Rd-sqHjmfB0</a></p><p>这动画做的挺有意思,只是Java8还离我们比较远啊.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> mysql </tag>
            
            <tag> Spring Data Repositories </tag>
            
            <tag> 加盐密码哈希 </tag>
            
            <tag> CopyOnWrite </tag>
            
            <tag> log </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年02月Reading Notes</title>
      <link href="/2014-02-reading-notes/"/>
      <url>/2014-02-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="HTTP-1-1-Upgrade-header"><a href="#HTTP-1-1-Upgrade-header" class="headerlink" title="HTTP/1.1 Upgrade header"></a>HTTP/1.1 Upgrade header</h2><p><a href="http://en.wikipedia.org/wiki/HTTP/1.1_Upgrade_header" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/HTTP/1.1_Upgrade_header</a></p><p>通过http upgrade header来实现协议转换,比如把http协议转换为websocket协议.<a href="http://wildfly.org/news/2014/02/11/WildFly8-Final-Released/" target="_blank" rel="noopener">wildfly</a>走得更远,8080端口支持HTTP (Servlet, JAX-RS, JAX-WS), Web Sockets, HTTP Upgraded Remoting (EJB Invocation, Remote JNDI).<a href="http://jaitechwriteups.blogspot.com/2013/07/wildfly-800alpha3-released-with-support.html" target="_blank" rel="noopener">这篇文章</a>讲述了一些细节.</p><h2 id="When-should-I-not-kill-9-a-process"><a href="#When-should-I-not-kill-9-a-process" class="headerlink" title="When should I not kill -9 a process?"></a>When should I not kill -9 a process?</h2><p><a href="http://unix.stackexchange.com/questions/8916/when-should-i-not-kill-9-a-process" target="_blank" rel="noopener">http://unix.stackexchange.com/questions/8916/when-should-i-not-kill-9-a-process</a></p><p>Generally, you should use kill -15 before kill -9 to give the target process a chance to clean up after itself. </p><h2 id="Java里快如闪电的线程间通讯"><a href="#Java里快如闪电的线程间通讯" class="headerlink" title="Java里快如闪电的线程间通讯"></a>Java里快如闪电的线程间通讯</h2><p><a href="http://www.infoq.com/cn/articles/High-Performance-Java-Inter-Thread-Communications" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/High-Performance-Java-Inter-Thread-Communications</a></p><p>多线程中,锁是一个很大的性能开销.如果采用无锁实现,会发现原来世界可以更美好.</p><h2 id="elasticsearch中文学习文档"><a href="#elasticsearch中文学习文档" class="headerlink" title="elasticsearch中文学习文档"></a>elasticsearch中文学习文档</h2><p><a href="https://github.com/medcl/elasticsearch-rtf" target="_blank" rel="noopener">https://github.com/medcl/elasticsearch-rtf</a></p><p><a href="http://tanjianna.diandian.com/post/2013-07-27/elasticsearch-study" target="_blank" rel="noopener">http://tanjianna.diandian.com/post/2013-07-27/elasticsearch-study</a></p><p>elasticsearch中文发行版，针对中文集成了相关插件，并带有Demo，方便新手学习,或者在生产环境中直接使用</p><h2 id="elasticsearch中文学习文档-1"><a href="#elasticsearch中文学习文档-1" class="headerlink" title="elasticsearch中文学习文档"></a>elasticsearch中文学习文档</h2><p><a href="http://webappchecklist.com/" target="_blank" rel="noopener">http://webappchecklist.com/</a><br>Web开发者必备：Web应用检查清单</p><h2 id="Cache-coherence"><a href="#Cache-coherence" class="headerlink" title="Cache coherence"></a>Cache coherence</h2><p><a href="http://en.wikipedia.org/wiki/Cache_coherence" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Cache_coherence</a></p><p>In a shared memory multiprocessor system with a separate cache memory for each processor, it is possible to have many copies of any one instruction operand: one copy in the main memory and one in each cache memory. When one copy of an operand is changed, the other copies of the operand must be changed also.</p><p><strong>Cache coherence</strong> is the discipline that ensures that changes in the values of shared operands are propagated throughout the system in a timely fashion.</p><h2 id="高性能、高流量Java-Web站点打造的22条建议"><a href="#高性能、高流量Java-Web站点打造的22条建议" class="headerlink" title="高性能、高流量Java Web站点打造的22条建议"></a>高性能、高流量Java Web站点打造的22条建议</h2><p><a href="http://www.csdn.net/article/2013-12-20/2817861-22-recommendations-for-building-effective-high-traffic-web-application" target="_blank" rel="noopener">http://www.csdn.net/article/2013-12-20/2817861-22-recommendations-for-building-effective-high-traffic-web-application</a></p><ul><li><p>通过使用类似Lucene的索引器做表的索引，使用一个允许在结果集上做基于其他字段的查询.</p><p>  对于复杂的查询,在数据库中直接做是很影响性能的,通过使用搜索引擎,能减轻数据库的压力.</p></li><li><p>考虑使用Oracle或者MySQL分片</p><p>  数据量大时,做分片能获得不错的性能提升.</p></li><li><p>不要使用session stickiness</p><p>  会话粘滞会带来一系列的问题.我们的分布式session方案中,默认要求LB启用会话粘滞,这样做的目的是能让本地缓存生效.当需要failover时,才去后端memcached中取数据.能同时兼顾性能和高可用.</p></li><li><p>终止反向代理商的SSL</p><p>  在反向代理或者LB上卸载ssl,能够减轻web应用服务器的压力.</p></li><li><p>拥抱一切“reactor”</p></li></ul>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> Upgrade header </tag>
            
            <tag> linux kill </tag>
            
            <tag> elasticsearch </tag>
            
            <tag> Cache coherence </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>序列化框架选型</title>
      <link href="/serialization-framework/"/>
      <url>/serialization-framework/</url>
      <content type="html"><![CDATA[<h3 id="序列化框架选型"><a href="#序列化框架选型" class="headerlink" title="序列化框架选型"></a>序列化框架选型</h3><p>分布式应用中,序列化很关键,选择一个合适的序列化框架能给分布式应用带来性能红利,还能减少不必要的麻烦.本文仅仅从我遇到的一些实际问题来说明序列化的选型.更深入部分也可以参考<a href="http://bohr.me/2012/04/02/java-serialization.html">java序列化</a></p><p>序列化框架的性能可以参考<a href="https://github.com/eishay/jvm-serializers/wiki" target="_blank" rel="noopener">jvm-serializers</a>,<code>Kryo</code>的性能还是很牛叉的.</p><p>除了性能,还要考虑兼容性/序列化后的大小.如果仅仅考虑性能,我们选择<code>Kryo</code>就足够了.但是Kryo有些用着不爽的地方,比如不是线程安全的/兼容性.</p><h4 id="1-兼容性"><a href="#1-兼容性" class="headerlink" title="1.兼容性"></a>1.兼容性</h4><p>字段增删不兼容,这个问题有时候很麻烦.比如用memache做缓存,把对象序列化后存入memcache,如果出现字段增删的情况,必须在服务重启的时候把缓存清空,不然就会导致<a href="http://bohr.me/2013/11/03/kryo-oom.html">灰常严重的BUG</a>.但是如果应用服务器有多台,这个问题还是避免不了.总会有个时间窗口会出现不同服务器上的同一个应用有不同的类版本,仍然可能会出现灰常严重的BUG.</p><p>现在的<code>Kryo</code>提供了兼容性的支持,使用<code>CompatibleFieldSerializer.class</code>,在<code>kryo.writeClassAndObject</code>写入的信息如下:</p><pre><code>class name|field lenght|field1 name|field2 name|field1 value| filed2 value</code></pre><p>读入<code>kryo.readClassAndObject</code>时,会先读入<code>field names</code>.然后匹配当前反序列化类的field和顺序,构造结果.</p><p>子类和父类中有同名的字段时，kryo反序列化会丢失字段值,出现问题的原因和<a href="http://bohr.me/2013/11/29/hessian-java-serialization.html">hessian</a>出问题一样.</p><p>给kryo提交了一个<a href="https://github.com/EsotericSoftware/kryo/pull/187" target="_blank" rel="noopener">improvement</a>,在初始化类型信息时,去掉父类中重复名称的field.</p><h4 id="2-线程安全"><a href="#2-线程安全" class="headerlink" title="2.线程安全"></a>2.线程安全</h4><p>非线程安全也很好处理,每次都new对象出来,当然这样不是最佳的使用方式.通过线程变量来解决会比较合理,保证了性能还能提供很方便使用的工具类.</p><h4 id="3-如何生成对象"><a href="#3-如何生成对象" class="headerlink" title="3.如何生成对象"></a>3.如何生成对象</h4><p>对于没有无参构造器的类来说，生成新对象是个问题，可以使用java内部的机制来new一个对象。<br>可以参考下<a href="https://github.com/magro/kryo-serializers/blob/master/src/main/java/de/javakaffee/kryoserializers/KryoReflectionFactorySupport.java" target="_blank" rel="noopener">KryoReflectionFactorySupport</a>的实现方式</p><h4 id="4-性能"><a href="#4-性能" class="headerlink" title="4.性能"></a>4.性能</h4><p>下面测试了java下的各种序列化实现方式的性能</p><pre><code>0 Serialisation    write=4,206ns read=16,945ns total=21,151ns 1 Serialisation    write=3,626ns read=18,205ns total=21,831ns0 MemoryByteBuffer write=270ns read=324ns total=594ns 1 MemoryByteBuffer write=270ns read=330ns total=600ns 0 MemoryByteBufferWithNativeOrder  write=357ns read=360ns total=717ns 1 MemoryByteBufferWithNativeOrder  write=323ns read=359ns total=682ns 0 DirectByteBuffer write=236ns read=325ns total=561ns 1 DirectByteBuffer write=231ns read=301ns total=532ns 0 DirectByteBufferWithNativeOrder  write=261ns read=310ns total=571ns 1 DirectByteBufferWithNativeOrder  write=243ns read=290ns total=533ns 0 UnsafeMemory write=28ns read=82ns total=110ns 1 UnsafeMemory write=24ns read=75ns total=99ns 0 kryo write=373ns read=348ns total=721ns 1 kryo write=390ns read=386ns total=776ns 0 kryoWithCompatibleFields write=1,037ns read=1,625ns total=2,662ns 1 kryoWithCompatibleFields write=1,038ns read=1,657ns total=2,695ns 0 kryoWithCompatibleFieldsAndDuplicateFieldAccept  write=1,077ns read=1,560ns total=2,637ns 1 kryoWithCompatibleFieldsAndDuplicateFieldAccept  write=1,064ns read=1,583ns total=2,647ns 0 kryoWithUnsafe   write=164ns read=204ns total=368ns 1 kryoWithUnsafe   write=168ns read=210ns total=378ns 0 fastjson write=1,942ns read=5,834ns total=7,776ns 1 fastjson write=1,873ns read=5,879ns total=7,752ns</code></pre><p>每种序列化执行1000000次,并且有预热. 各组数据相对比较,可以得出一些结论:</p><ul><li>直接调用unsafe,最快,但是最麻烦</li><li>java自带的序列化很慢,最好不要用</li><li>kryo2.22提供的unsafe支持,性能非常卓越</li><li>kryo兼容性序列化器,开销挺大.写需要写入字段名,读的时候还需要做匹配撮合,读比写慢</li><li>fastjson也挺快的,兼容性\跨语言互操性俱佳.</li></ul><p>序列化后的字节大小可以参考<a href="https://github.com/eishay/jvm-serializers/wiki" target="_blank" rel="noopener">jvm-serializers</a></p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 序列化 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2014年01月Reading Notes</title>
      <link href="/2014-01-reading-notes/"/>
      <url>/2014-01-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="LINUX上MYSQL优化三板斧"><a href="#LINUX上MYSQL优化三板斧" class="headerlink" title="LINUX上MYSQL优化三板斧"></a>LINUX上MYSQL优化三板斧</h2><p><a href="http://www.woqutech.com/?p=1200" target="_blank" rel="noopener">http://www.woqutech.com/?p=1200</a></p><p>讲了如何优化linux mysql服务器,主要讲了操作系统层面的优化</p><ul><li><p>CPU方面</p><p>  关闭电源保护模式(充分利用cpu资源)</p></li><li><p>内存：</p><p>  vm.swappiness = 0 (尽量少swap)</p><p>  关闭numa     (在NUMA架构下，本地内存的访问和非本地内存的访问代价是不一样的)</p></li><li><p>文件系统：</p><p>  用noatime(不用更新文件的access time)，nobarrier(不用文件系统强制底层设备刷新缓存,由RAID卡或者Flash卡来保证)挂载系统</p><p>  IO调度策略修改为deadline。(IO调度策略采用deadline,它是非公平的调度策略,但是能兼顾一个请求不会在队列中等待太久导致饿死)</p></li></ul><h2 id="Java-Multi-Threading-and-Concurrency-Interview-Questions-with-Answers"><a href="#Java-Multi-Threading-and-Concurrency-Interview-Questions-with-Answers" class="headerlink" title="Java Multi-Threading and Concurrency Interview Questions with Answers"></a>Java Multi-Threading and Concurrency Interview Questions with Answers</h2><p> <a href="http://www.journaldev.com/1162/java-multi-threading-concurrency-interview-questions-with-answers" target="_blank" rel="noopener">http://www.journaldev.com/1162/java-multi-threading-concurrency-interview-questions-with-answers</a></p><p> 虽然是面试题,但是讲了很多java线程中的基础概念</p><h2 id="禁用Spotlight后-Alfred找不到app"><a href="#禁用Spotlight后-Alfred找不到app" class="headerlink" title="禁用Spotlight后,Alfred找不到app"></a>禁用Spotlight后,Alfred找不到app</h2><p> 个人感觉Alfred要比spotlight好用得多,特别是装了某些workflows后,操作效率明显提高.本着不要浪费性能的原则,参考<a href="http://hi.baidu.com/omyss/item/168dd67555a0d75c0d0a0717" target="_blank" rel="noopener">MAC OS X 关闭 spotlight 降温的大法</a>把spotlight服务给全禁用掉了.</p><p> 用了两天感觉不对,一些常用软件在Alfred中找不到,官方回答了<a href="http://support.alfredapp.com/kb:spotlight" target="_blank" rel="noopener">Can Alfred work without Spotlight enabled?</a>,看来还得启用spotlight才行.悲剧的是降温大法里面提到的启用办法老是报错.下面的命令能解决这个问题:</p><pre><code>sudo mv Search2.bundle/ Search.bundle/sudo launchctl load -w /System/Library/LaunchDaemons/com.apple.metadata.mds.plistsudo mdutil -a -i on</code></pre><h2 id="markdown中出现了特殊字符导致blog一直不更新"><a href="#markdown中出现了特殊字符导致blog一直不更新" class="headerlink" title="markdown中出现了特殊字符导致blog一直不更新"></a>markdown中出现了特殊字符导致blog一直不更新</h2><p>前几天写了一篇博文,提交到github后,一直主页都刷不出来,以为是github出问题了.专门去twiter看了下,没有发现风吹草动,这下必须得把测试预览环境搭建起来.</p><pre><code>sudo gem install jekyll#安装markdwon解析插件sudo gem install rdiscount#切换到项目路径cd bohrqiu.github.com#启动jekyll服务并监听文件变动jekyll serve --watch</code></pre><p>启动起来后,居然看到markdown解析失败了</p><pre><code>| Maruku tells you:+-----| Malformed HTML starting at &quot;&lt;v2,则打包失败)&quot;| -----| gin`来规范传递依赖,要求当前依赖的版本和传递依赖版本一样或者比传递依赖版本高(比如A-&gt;Cv1 ,A-&gt;D-&gt;Cv2,如果v1&lt;v2,则打包失败)EOF</code></pre><p>没想到<code>&lt;</code>符号还不能直接使用~~!</p><h2 id="git-api-总结"><a href="#git-api-总结" class="headerlink" title="git api 总结"></a>git api 总结</h2><p>git很久没有用了,加上现在有github的客户端,基本上把命令都忘完了,偶然看到<br><a href="http://www.weibo.com/heiniuhaha" target="_blank" rel="noopener">@<strong>heiniuhaha</strong></a> 妹纸总结的git api,太详细了,收了.</p><p><img src="/2014-01-reading-notes/images/git-api.png" width="500" height="500"></p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> linux mysql tunning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>打造环境感知的应用</title>
      <link href="/env-aware/"/>
      <url>/env-aware/</url>
      <content type="html"><![CDATA[<h2 id="打造环境感知的应用"><a href="#打造环境感知的应用" class="headerlink" title="打造环境感知的应用"></a>打造环境感知的应用</h2><p>这里说的<code>环境感知的应用</code>是指,应用放在不同的环境,就可以使用不同环境的配置,不需要重新打包.</p><h3 id="1-我眼中理想的环境和应用"><a href="#1-我眼中理想的环境和应用" class="headerlink" title="1.我眼中理想的环境和应用"></a>1.我眼中理想的环境和应用</h3><ul><li>应用不用管环境配置</li><li>参数配置在配置管理系统中的</li><li>框架从配置管理中加载配置</li><li>只有操作系统或者应用服务器知道环境的概念</li></ul><p>理想很丰满,现实很惨…,揉醒了,继续面对现实.要实现这个目标,还有很多需要做的.现在我们尽可能要做的是,开发童鞋自己把环境搞定,不给其他童鞋添堵.</p><h3 id="2-适合我们的环境感知的应用"><a href="#2-适合我们的环境感知的应用" class="headerlink" title="2.适合我们的环境感知的应用"></a>2.适合我们的<code>环境感知</code>的应用</h3><p>我们的系统大多数用的是tomcat作为应用服务器,最好是让应用服务器来提供环境标识,在应用中结合spring profile机制来实现环境感知</p><h3 id="3-如何操作"><a href="#3-如何操作" class="headerlink" title="3.如何操作"></a>3.如何操作</h3><h4 id="3-1在操作系统中添加环境变量"><a href="#3-1在操作系统中添加环境变量" class="headerlink" title="3.1在操作系统中添加环境变量"></a>3.1在操作系统中添加环境变量</h4><p>比如在10测试环境,在<code>/etc/profile</code>中增加如下东东:</p><pre><code>export CATALINA_OPTS=&apos; -Dspring.profiles.active=dev &apos;</code></pre><p>然后执行<code>. /etc/profile</code>解析</p><h4 id="3-2配置日志"><a href="#3-2配置日志" class="headerlink" title="3.2配置日志"></a>3.2配置日志</h4><p>并不是所有系统都会针对不同环境启用不同的日志配置文件,即便有logback可以很方便的来解决这些问题.</p><h5 id="3-2-1-在logback配置内区分环境"><a href="#3-2-1-在logback配置内区分环境" class="headerlink" title="3.2.1 在logback配置内区分环境"></a>3.2.1 在logback配置内区分环境</h5><p>比如我们在本地测试的时候,把日志输出到console,便于我们查问题.<br>可以在logback.xml中加入:</p><pre><code>&lt;if condition=&apos;property(&quot;os.name&quot;).toUpperCase().contains(&quot;WINDOWS&quot;)||property(&quot;os.name&quot;).toUpperCase().contains(&quot;MAC&quot;)&apos;&gt;    &lt;then&gt;        &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;            &lt;encoder&gt;                &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger{0}:%L-%X{ID}- %msg%n&lt;/pattern&gt;            &lt;/encoder&gt;        &lt;/appender&gt;        &lt;root&gt;            &lt;appender-ref ref=&quot;STDOUT&quot; /&gt;        &lt;/root&gt;    &lt;/then&gt;&lt;/if&gt;</code></pre><p>上面的配置会在windows和mac中启用console日志输出</p><p>在logback中引入外部配置文件,也可以区分不同的环境</p><pre><code>&lt;property resource=&quot;spring/log/log-${spring.profiles.active}.properties&quot; /&gt;</code></pre><p>上面会根据<code>spring.profiles.active</code>的配置读取不同的配置文件</p><h5 id="3-2-2-不同环境区分不同的日志配置文件"><a href="#3-2-2-不同环境区分不同的日志配置文件" class="headerlink" title="3.2.2 不同环境区分不同的日志配置文件"></a>3.2.2 不同环境区分不同的日志配置文件</h5><p>如果您有针对不同环境不同的日志文件,<code>com.yjf.common.log.LogbackConfigListener</code>提供了支持.</p><pre><code>&lt;context-param&gt;      &lt;param-name&gt;logbackConfigLocation&lt;/param-name&gt;      &lt;param-value&gt;WEB-INF/logback-${spring.profiles.active}.xml&lt;/param-value&gt;  &lt;/context-param&gt;</code></pre><h4 id="3-3-配置应用"><a href="#3-3-配置应用" class="headerlink" title="3.3 配置应用"></a>3.3 配置应用</h4><p>数据库和外部资源配置,一般会放入到单独的配置文件中,我们可以使用spring提供的能力来实现环境感知</p><h5 id="3-3-1-使用properties文件"><a href="#3-3-1-使用properties文件" class="headerlink" title="3.3.1 使用properties文件"></a>3.3.1 使用properties文件</h5><pre><code>&lt;bean id=&quot;propertyConfigurerForJDBC&quot;    class=&quot;com.yjf.common.dal.EncryptablePropertyPlaceholderConfigurer&quot;&gt;    &lt;property name=&quot;order&quot; value=&quot;1&quot; /&gt;    &lt;property name=&quot;ignoreUnresolvablePlaceholders&quot; value=&quot;true&quot; /&gt;    &lt;property name=&quot;location&quot;        value=&quot;classpath:jdbc-${spring.profiles.active}.properties&quot; /&gt;&lt;/bean&gt;</code></pre><p>上面会根据<code>spring.profiles.active</code>的配置读取不同jdbc配置文件</p><h5 id="3-3-2-使用spring-profile"><a href="#3-3-2-使用spring-profile" class="headerlink" title="3.3.2 使用spring profile"></a>3.3.2 使用spring profile</h5><pre><code>&lt;beans profile=&quot;production&quot;&gt;     &lt;bean id=&quot;xxx&quot; class=&quot;xxxxBEAN&quot; /&gt;  &lt;/beans&gt;&lt;beans profile=&quot;test&quot;&gt;     &lt;bean id=&quot;xxx&quot; class=&quot;xxxxBEAN&quot; /&gt;  &lt;/beans&gt;</code></pre><p>spring profile通过读取系统或者环境变量<code>spring.profiles.active</code>来启用不同的bean.</p><h5 id="3-3-2-硬编码实现"><a href="#3-3-2-硬编码实现" class="headerlink" title="3.3.2 硬编码实现"></a>3.3.2 硬编码实现</h5><p><code>com.yjf.common.env.Env</code>提供了在编写java code时,区分不同的环境</p><pre><code>private void doIt() {    if (Env.isOnline()) {        //do anything you like.    }}</code></pre><p>上面的代码只在生成环境运行,<code>com.yjf.common.env.Env</code>通过读取<code>spring.profiles.active</code>来判断环境</p><h4 id="3-4-配置测试"><a href="#3-4-配置测试" class="headerlink" title="3.4 配置测试"></a>3.4 配置测试</h4><p>通过上面的一些列配置,环境都由<code>spring.profiles.active</code>控制.在本地测试时,也需要启用此环境变量.</p><h5 id="3-4-1-tomcat-jetty-启动类"><a href="#3-4-1-tomcat-jetty-启动类" class="headerlink" title="3.4.1 tomcat/jetty 启动类"></a>3.4.1 tomcat/jetty 启动类</h5><p><code>TomcatBootstrapHelper</code>启动时,默认会在系统变量里增加<code>spring.profiles.active=dev</code></p><pre><code>new TomcatBootstrapHelper(11111).start();</code></pre><p>上面的代码会使用<code>dev</code>环境配置.如果您按照3.3.1配置,此时会读取<code>jdbc-dev.properties</code></p><p>我没有写jetty的启动帮助类,主要原因是为了和线上保持一致,减少一些不可预知的问题.如果要使用jetty,请增加如下代码:</p><pre><code>static{    System.setProperty(&quot;spring.profiles.active&quot;, &quot;dev&quot;);}</code></pre><h5 id="3-4-1-单元测试"><a href="#3-4-1-单元测试" class="headerlink" title="3.4.1 单元测试"></a>3.4.1 单元测试</h5><p>在测试类或者测试父类中增加:</p><pre><code>static{    System.setProperty(&quot;spring.profiles.active&quot;, &quot;dev&quot;);}</code></pre>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 环境感知 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>依赖管理</title>
      <link href="/dependency-management/"/>
      <url>/dependency-management/</url>
      <content type="html"><![CDATA[<h1 id="依赖管理"><a href="#依赖管理" class="headerlink" title="依赖管理"></a>依赖管理</h1><p>项目依赖问题很让人头痛，也出了很多事故，线上线下都很闹心。本着让大家都能开心的原则😄，在<strong>@培根</strong>童鞋的要求下，刚好我对maven很熟，刚好我对公司遇到的依赖问题也很了解，写了此文档。</p><p>请您带着一个大大的问号<strong>?</strong>阅读此文档.您可以把您遇到的依赖问题(此文档没有包含的)发给我,丰富案例库.您可以补充依赖检查中的不足之处,毕竟我个人的能力有限.您可以分享一些灰常有用的插件,方便大家.您可以谈谈您对依赖风险控制的想法.<strong>Help Me Help You!</strong></p><h2 id="一-依赖管理目标"><a href="#一-依赖管理目标" class="headerlink" title="一.依赖管理目标"></a>一.依赖管理目标</h2><ol><li>此规范更新后,使用方不需要修改代码</li><li>规范开源jar包版本</li><li>检查传递依赖</li><li>检查项目classpath中是否有类名相同的依赖jar包</li><li>检查已知不能使用的jar包</li><li>定义常用插件</li><li>优化yjf-common-util依赖,不是每个项目都使用的包定义为provided,由项目自己引入</li></ol><h2 id="二-如何实现目标"><a href="#二-如何实现目标" class="headerlink" title="二.如何实现目标"></a>二.如何实现目标</h2><h3 id="1-创建公共父pom"><a href="#1-创建公共父pom" class="headerlink" title="1.创建公共父pom"></a>1.创建公共父pom</h3><ul><li>定义所有易极付项目都依赖的父pom <code>com.yiji.yiji-parent</code></li><li>此pom为SNAPSHOT</li><li>此pom在<code>dependencyManagement</code>中定义常用jar包的版本</li><li>此pom显示依赖<code>yjf-common-util</code> <code>guava</code> <code>log</code></li><li>此pom使用<code>maven-enforcer-plugin</code>来规范传递依赖,要求当前依赖的版本和传递依赖版本一样或者比传递依赖版本高(比如A-&gt;Cv1 ,A-&gt;D-&gt;Cv2,如果<code>v1&lt;v2</code>,则打包失败)</li><li>此pom使用<code>maven-enforcer-plugin</code>来规范引入会导致已知问题的包(比如我们的项目都使用<code>slf4j</code>和<code>logback</code>,那我们的依赖中不能出现<code>org.slf4j:slf4j-log4j12</code>)</li><li>此pom使用<code>com.yiji.maven.yiji-maven-plugin</code>来检查classpath中是否有类名相同的jar包出现.如果有,在<code>console</code>中也会提示警告,在执行打包命令的目录生成<code>dependency-check.log</code>文件,此文件中会记录检查了哪些包.同时,以后我们也可以通过此日志文件来了解我们项目间的依赖情况.</li><li>此pom包含常用maven插件<code>maven-compiler-plugin</code> <code>maven-source-plugin</code> <code>maven-eclipse-plugin</code> <code>findbugs-maven-plugin</code> <code>maven-pmd-plugin</code>方便大家日常使用</li><li>此pom中的开源依赖,我会定期check是否有更新,是否有bug修复</li></ul><h3 id="2-开发com-yiji-maven-yiji-maven-plugin"><a href="#2-开发com-yiji-maven-yiji-maven-plugin" class="headerlink" title="2.开发com.yiji.maven.yiji-maven-plugin"></a>2.开发<code>com.yiji.maven.yiji-maven-plugin</code></h3><p>此插件已开发完毕,代码也很简单,可以发现一些类加载顺序不一致导致的潜在的问题.</p><p>目前此插件只检查不同的jar包中是否有相同的类名.还可以增加对资源文件的检查,文件名相同还可以增加对内容的检查.这些需求如有必要,以后在加上.此插件也是SNAPSHOT的,以后我升级了,大家不用改动任何代码.</p><h3 id="3-定制settings-xml"><a href="#3-定制settings-xml" class="headerlink" title="3.定制settings.xml"></a>3.定制<code>settings.xml</code></h3><ul><li>此文件定义<code>snapshot</code>依赖为每次打包检查</li><li>其他大多人不需要关心的东东</li></ul><h2 id="三-如何实施"><a href="#三-如何实施" class="headerlink" title="三.如何实施"></a>三.如何实施</h2><p>目前已完成cs项目的改造,使用上面的东东,cs的pom文件还廋身不少.</p><p>由于传递依赖,不敢贸然大规模推广,先选择被依赖较少的项目使用.和<strong>@培根</strong>商量,先选择<strong>boss项目\易融通项目\易房保项目</strong>使用,使用过程中出现任何问题,请联系我(也可以顺带请我喝茶)</p><p>如果这几个项目把雷踩完了,需要找一个统一的时间点,大家一起修改\测试\上线</p><h2 id="四-如何搞"><a href="#四-如何搞" class="headerlink" title="四.如何搞"></a>四.如何搞</h2><h3 id="1-替换setting-xml"><a href="#1-替换setting-xml" class="headerlink" title="1.替换setting.xml"></a>1.替换<code>setting.xml</code></h3><p>下载<code>svn://192.168.45.206/common/yiji-parent/settings.xml</code>,替换maven安装目录中的<code>setting.xml</code></p><h3 id="2-配置项目父pom"><a href="#2-配置项目父pom" class="headerlink" title="2.配置项目父pom"></a>2.配置项目父pom</h3><p>拿cs为例，在cs的父pom中加入</p><pre><code>&lt;parent&gt;    &lt;groupId&gt;com.yiji&lt;/groupId&gt;    &lt;artifactId&gt;yiji-parent&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;</code></pre><p>去掉dependencyManagement中的开源jar依赖(公司内部的依赖不要去掉， <code>com.yiji.yiji-parent</code>中没有定义这些东东)。检查项目中的开源依赖是否有版本号，如果有并且IDE提示重复的定义，去掉此版本号；如果没有提示，应该是在 <code>com.yiji.yiji-parent</code>里没有加入此依赖，请联系我。</p><h3 id="3-测试打包"><a href="#3-测试打包" class="headerlink" title="3.测试打包"></a>3.测试打包</h3><p>执行<code>mvnp</code>试试，如果有传递依赖问题，打包会失败，请先联系我。如果打包成功，请检查<code>dependency-check.log</code>文件中有没有警告</p><h3 id="4-测试项目"><a href="#4-测试项目" class="headerlink" title="4.测试项目"></a>4.测试项目</h3><p>运行单元测试用例，看会不会出现问题，最好找<strong>@翼德</strong>同学全量回归下。</p><h2 id="五-FAQ"><a href="#五-FAQ" class="headerlink" title="五.FAQ"></a>五.FAQ</h2><h3 id="1-为什么不提供方便发布的东东"><a href="#1-为什么不提供方便发布的东东" class="headerlink" title="1.为什么不提供方便发布的东东"></a>1.为什么不提供方便发布的东东</h3><h5 id="原因有："><a href="#原因有：" class="headerlink" title="原因有："></a>原因有：</h5><ul><li>容易出错，命令很简单，容易把发往生产的包发到测试环境，除非你很了解</li><li>setting.xml里不支持定义<code>distributionManagement</code>，只能在pom里面定义。因为我们有多套nexus，需要通过profile来定义不同环境对应不同的nexus，但是profile不能继承(我测试是这样的)</li><li>我们大多数项目，只能把facade发布到nexus，即便profile支持继承，我也不敢把这玩意儿加到<code>com.yiji.yiji-parent</code>中。万一某童鞋在项目根目录执行了mvn deploy，<strong>@培根</strong>会不开心的…😠</li></ul><h5 id="如何解决："><a href="#如何解决：" class="headerlink" title="如何解决："></a>如何解决：</h5><p>可以参考<code>com.yiji.yiji-parent</code>中的profiles部分，请在facade中定义这个玩意儿，然后执行命令</p><h3 id="2-有哪些常用的mvn命令，可以方便大家使用"><a href="#2-有哪些常用的mvn命令，可以方便大家使用" class="headerlink" title="2.有哪些常用的mvn命令，可以方便大家使用"></a>2.有哪些常用的mvn命令，可以方便大家使用</h3><p>非window用户，请在~/.bash_profile中加入</p><pre><code>alias mvni=&apos;mvn -T 1C clean install -Dmaven.test.skip=true&apos;alias mvnp=&apos;mvn -T 1C clean package -Dmaven.test.skip=true&apos;alias mvnv=&apos;mvn versions:set -DgenerateBackupPoms=false&apos;alias mvnd=&apos;mvn -T 1C clean deploy -Dmaven.test.skip=true&apos;alias mvndd=&apos;mvn -T 1C clean deploy -P dev  -Dmaven.test.skip=true&apos;alias mvndo=&apos;mvn -T 1C clean deploy -P online -Dmaven.test.skip=true&apos;alias mvnc=&apos;mvn -T 1C clean eclipse:clean idea:clean&apos;alias mvne=&apos;mvn -T 1C clean eclipse:clean eclipse:eclipse  -DdownloadSources=true&apos;</code></pre><p>不知道各命令啥意思的童鞋请google.</p><p>window用户请把<code>svn://192.168.45.206/common/yiji-parent/script</code>中的脚本添加到PATH中，have a try.</p><h3 id="3-为毛不加入自动生成doc文档插件"><a href="#3-为毛不加入自动生成doc文档插件" class="headerlink" title="3.为毛不加入自动生成doc文档插件"></a>3.为毛不加入自动生成doc文档插件</h3><p><code>yjf-common-util</code>里面用<code>maven-javadoc-plugin</code>来生成doc文档并在发布时上传到nexus。不过这很费时，而且我们以前使用的<code>codetemplates</code>里面有很多javadoc不认识的东东，警告一大堆，看着惨不忍睹。</p><h3 id="4-IDE里面安装maven插件有什么好处"><a href="#4-IDE里面安装maven插件有什么好处" class="headerlink" title="4.IDE里面安装maven插件有什么好处"></a>4.IDE里面安装maven插件有什么好处</h3><p>好处很多，它可以检查一些pom编写错误，也可以方便看依赖树。eclipse对maven支持很牛，依赖树看着会很爽，简单的依赖问题，用它就可以搞定。IDEA的智能提示很牛，添加依赖快捷键就可以搞定。</p><p>以后有依赖问题的童鞋，先用IDE提供的依赖树功能发现问题。找我也可以，但别让我给你安装maven插件，生命是短暂的啊。</p><h3 id="5-maven我不熟怎么办"><a href="#5-maven我不熟怎么办" class="headerlink" title="5.maven我不熟怎么办"></a>5.maven我不熟怎么办</h3><p>肯定不是凉拌，可以先看看<code>http://www.infoq.com/cn/minibooks/maven-in-action</code> <code>http://www.juvenxu.com/category/maven/</code><br>后面我会给大家分享maven一些基本的东东。</p><h3 id="6-依赖问题除了maven导致的-还有其他导致的-如何解决"><a href="#6-依赖问题除了maven导致的-还有其他导致的-如何解决" class="headerlink" title="6.依赖问题除了maven导致的,还有其他导致的,如何解决?"></a>6.依赖问题除了maven导致的,还有其他导致的,如何解决?</h3><p>主要是把场景找出来,然后分析这些问题,我们自己来添加些防御手段.比如今天<strong>@周洋</strong>同学遇到的两个spring bean id配置一样了,导致本地开发测试ok,199启动确不正常.我们可以给spring添加点东东来检查重复id的问题.</p><h3 id="7-我依赖的某jar版本就是不一样"><a href="#7-我依赖的某jar版本就是不一样" class="headerlink" title="7.我依赖的某jar版本就是不一样"></a>7.我依赖的某jar版本就是不一样</h3><p>有这样的的需求,现在问题比较突出的应该是金融这块.金融依赖很多银行提供的jar包,这些包可能会冲突.比如金融某项目,既依赖<code>httpclient3</code>又依赖<code>httpclient4</code>.</p><p>这种情况只能在项目里面指定版本了,使用<code>com.yiji.maven.yiji-maven-plugin</code>里提供的版本不是强制约束.但是建议大家都别这样做,除非没办法.</p><h3 id="8-spring4-0都发布了-我们是不是该升级了"><a href="#8-spring4-0都发布了-我们是不是该升级了" class="headerlink" title="8.spring4.0都发布了,我们是不是该升级了."></a>8.spring4.0都发布了,我们是不是该升级了.</h3><p>我们现在用的是spring 3.1,可能有项目用的spring3.2.</p><p><a href="http://docs.spring.io/spring/docs/3.2.6.RELEASE/spring-framework-reference/htmlsingle/#new-in-3.2" target="_blank" rel="noopener">spring3.2</a> 有很多新特性,比如test framework,此次升级也把spring升级到3.2.6.</p><p><a href="http://docs.spring.io/spring/docs/4.0.0.RELEASE/spring-framework-reference/htmlsingle/#spring-whats-new" target="_blank" rel="noopener">spring 4.0</a>改动太大,暂时不考虑</p><h3 id="9-在公共父pom中升级一个版本-风险怎么把控"><a href="#9-在公共父pom中升级一个版本-风险怎么把控" class="headerlink" title="9.在公共父pom中升级一个版本,风险怎么把控"></a>9.在公共父pom中升级一个版本,风险怎么把控</h3><p>以后大家都继承此父pom,升级一个版本意味着大家都升级了.风险确实很大.</p><p>首先,我们会去分析此依赖的<code>release notes</code>,评估升级的必要性和影响面.</p><p>然后,我们会找bops这样的大杂烩项目来做测试,测试相关特性是否受影响.  </p><h3 id="10-为什么不把setting-xml的配置移到pom中"><a href="#10-为什么不把setting-xml的配置移到pom中" class="headerlink" title="10.为什么不把setting.xml的配置移到pom中"></a>10.为什么不把<code>setting.xml</code>的配置移到pom中</h3><p>这样做的目的是为了做到环境感知,不同环境的maven <code>setting.xml</code>会不一样,这是信息中心和我需要做的事情.对于大家,只需要使用svn repos中的<code>setting.xml</code>.放到pom中,这个pom需要定义不同的profile,还需要修改我们现有的各个环境的打包脚本.</p><h3 id="11-常见踩雷问题"><a href="#11-常见踩雷问题" class="headerlink" title="11.常见踩雷问题"></a>11.常见踩雷问题</h3><h4 id="11-1-java-lang-NoClassDefFoundError-org-springframework-ui-velocity-VelocityEngineFactory"><a href="#11-1-java-lang-NoClassDefFoundError-org-springframework-ui-velocity-VelocityEngineFactory" class="headerlink" title="11.1 java.lang.NoClassDefFoundError: org/springframework/ui/velocity/VelocityEngineFactory"></a>11.1 java.lang.NoClassDefFoundError: org/springframework/ui/velocity/VelocityEngineFactory</h4><p>这个原因是spring把相关的类放到了spring-context-support里面.如果你用spring的声明式cache,也会遇到找不到类,都加入下面的依赖.</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><h4 id="11-2-velocity报错"><a href="#11-2-velocity报错" class="headerlink" title="11.2 velocity报错"></a>11.2 velocity报错</h4><pre><code>java.lang.IllegalStateException: Cannot convert value of type     [org.springframework.web.servlet.view.velocity.VelocityConfigurer] to required type [org.apache.velocity.app.VelocityEngine] for property &apos;velocityEngine&apos;: no matching editors or conversion strategy foundat org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:267)</code></pre><p>报错是因为配置的bean <code>org.springframework.web.servlet.view.velocity.VelocityConfigurer</code> id为<code>velocityEngine</code>.此id覆盖了默认的velocityEngine,把这个id改为<code>velocityConfigurer</code>就ok</p><h4 id="11-3-net-sf-ehcache-util-UpdateChecker-Update-check-failed"><a href="#11-3-net-sf-ehcache-util-UpdateChecker-Update-check-failed" class="headerlink" title="11.3  net.sf.ehcache.util.UpdateChecker - Update check failed:"></a>11.3  net.sf.ehcache.util.UpdateChecker - Update check failed:</h4><p>关闭ehcache启动时检查版本,在ehcache配置根元素上添加属性<code>updateCheck=&quot;false&quot;</code> </p><h4 id="11-4-BeanCopier报错"><a href="#11-4-BeanCopier报错" class="headerlink" title="11.4 BeanCopier报错"></a>11.4 <code>BeanCopier</code>报错</h4><p>‘net.sf.cglib.core.TypeUtils.parseType(Ljava/lang/String;)Lorg/objectweb/asm/Type;’<br>这是以为spring 3.2对asm有改动<a href="http://docs.spring.io/spring/docs/3.2.6.RELEASE/spring-framework-reference/htmlsingle/#migration-3.2" target="_blank" rel="noopener">Migrating to Spring Framework 3.2</a>(D.3和D.4讲了这些东东),咱也得跟着改动,遇到这个错误,去掉cglib-nodep的依赖就ok</p><p>加入下面的依赖:</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;cglib&lt;/groupId&gt;    &lt;artifactId&gt;cglib&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.ow2.asm&lt;/groupId&gt;    &lt;artifactId&gt;asm-util&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><h4 id="11-5-Spring-MVC-controller-处理ajax请求报错-406-Not-Acceptable"><a href="#11-5-Spring-MVC-controller-处理ajax请求报错-406-Not-Acceptable" class="headerlink" title="11.5 Spring MVC controller 处理ajax请求报错 406 Not Acceptable"></a>11.5 <code>Spring MVC controller</code> 处理ajax请求报错 <code>406 Not Acceptable</code></h4><p><code>spring 3.2</code>引入了内容协商的概念,此概念很REST,资源输出格式由客户端来定义.目前支持三种:</p><ul><li>请求后缀名<br>比如getUser.html getUser.xml  getUser.json 分别代表请求输出为html/xml/json</li><li>参数<br>比如请求为getUser?type=xml getUser?type=json</li><li>http header<br>在http请求中设置<code>Accept</code> header,由客户端编程定义接收什么格式的返回.</li></ul><p>这三种方式,我个人觉得第三种最优雅,很适合编程实现对资源的访问.第一种很直观,第二种有点破坏REST的味道了.参考<a href="http://spring.io/blog/2013/05/11/content-negotiation-using-spring-mvc" target="_blank" rel="noopener">Content Negotiation using Spring MVC</a></p><p>遇到这个错误,很可能是因为我们在<code>Controller</code>中定义<code>@RequestMapping</code>的<code>value</code>带有html后缀,但是我们在方法上也加上了<code>@ResponseBody</code>,这让spring很困惑,你请求为html,返回输出又要去解析为json.</p><h5 id="配置"><a href="#配置" class="headerlink" title="配置:"></a>配置:</h5><p>1.引入正确的schema<br>把schemaLocation中spring mvc schema版本去掉</p><pre><code>http://www.springframework.org/schema/mvc  http://www.springframework.org/schema/mvc/spring-mvc.xsd</code></pre><p>2.配置<code>contentNegotiationManager</code></p><pre><code>&lt;bean id=&quot;contentNegotiationManager&quot;      class=&quot;org.springframework.web.accept.ContentNegotiationManagerFactoryBean&quot;&gt;    &lt;property name=&quot;favorPathExtension&quot; value=&quot;false&quot;/&gt;    &lt;property name=&quot;favorParameter&quot; value=&quot;false&quot;/&gt;    &lt;property name=&quot;ignoreAcceptHeader&quot; value=&quot;true&quot;/&gt;    &lt;property name=&quot;useJaf&quot; value=&quot;false&quot;/&gt;    &lt;property name=&quot;defaultContentType&quot; value=&quot;application/json&quot;/&gt;&lt;/bean&gt;</code></pre><p>3.配置json转换器</p><pre><code>&lt;mvc:annotation-driven         content-negotiation-manager=&quot;contentNegotiationManager&quot;&gt;    &lt;mvc:message-converters register-defaults=&quot;true&quot;&gt;        &lt;bean id=&quot;fastJsonHttpMessageConverter&quot;              class=&quot;com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter&quot;&gt;            &lt;property name=&quot;supportedMediaTypes&quot;&gt;                &lt;list&gt;                    &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt;                &lt;/list&gt;            &lt;/property&gt;            &lt;property name=&quot;features&quot; value=&quot;WriteDateUseDateFormat&quot;/&gt;        &lt;/bean&gt;    &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;</code></pre><p>我们很多童鞋spring mvc用得很不地道,建议看看官方demo <a href="http://s3.springsource.org/MVC/mvc-showcase-screencast.mov" target="_blank" rel="noopener">mvc-showcase-screencast</a></p><h4 id="11-6-使用com-yjf-common-web-CrossScriptingFilter报找不到ESAPI"><a href="#11-6-使用com-yjf-common-web-CrossScriptingFilter报找不到ESAPI" class="headerlink" title="11.6 使用com.yjf.common.web.CrossScriptingFilter报找不到ESAPI"></a>11.6 使用<code>com.yjf.common.web.CrossScriptingFilter</code>报找不到ESAPI</h4><p>添加依赖.</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.owasp.esapi&lt;/groupId&gt;    &lt;artifactId&gt;esapi&lt;/artifactId&gt;    &lt;exclusions&gt;        &lt;exclusion&gt;            &lt;artifactId&gt;log4j&lt;/artifactId&gt;            &lt;groupId&gt;log4j&lt;/groupId&gt;        &lt;/exclusion&gt;        &lt;exclusion&gt;            &lt;groupId&gt;xerces&lt;/groupId&gt;            &lt;artifactId&gt;xercesImpl&lt;/artifactId&gt;        &lt;/exclusion&gt;     &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;xerces&lt;/groupId&gt;    &lt;artifactId&gt;xercesImpl&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 依赖管理 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2013年12月Reading Notes</title>
      <link href="/2013-12-reading-notes/"/>
      <url>/2013-12-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="如何处理web静态文件"><a href="#如何处理web静态文件" class="headerlink" title="如何处理web静态文件"></a>如何处理web静态文件</h2><h4 id="spring-mvc-处理静态资源文件"><a href="#spring-mvc-处理静态资源文件" class="headerlink" title="spring mvc 处理静态资源文件"></a>spring mvc 处理静态资源文件</h4><p>在spring mvc中，通过三种方式来处理静态资源</p><ol><li><p>激活Tomcat的defaultServlet来处理静态文件</p><p> 参考tomcat config目录下的web.xml,这种方式IDE不友好，IDE会报找不到default servlet</p></li><li><p>在spring3.0.4以后版本提供了mvc:resources</p><p> 可以读取WEB-INFO和jar包里面的资源文件，也可以控制浏览器缓存</p></li><li><p>使用<code>&lt;mvc:default-servlet-handler/&gt;</code></p><p> 通过使用DefaultServletHttpRequestHandler来把静态资源文件丢给容器处理，和方式一做的事情一样，这种方式兼容多种web容器，ide友好。使用这个一般是在<code>DispatcherServlet</code>映射为<code>/</code>时，让静态资源继续交给容器处理。其实这种方式的性能不好，因为<code>DispatcherServlet</code>里执行了一大坨代码。</p></li></ol><h4 id="前端页面优化"><a href="#前端页面优化" class="headerlink" title="前端页面优化"></a>前端页面优化</h4><p>前端页面优化，可以用yslow(yahoo强大的web团队推出的精品)、chorme audit、<a href="https://developers.google.com/speed/pagespeed/module" target="_blank" rel="noopener">PageSpeed</a>来评估</p><p>只用apache的童鞋可以考虑使用<a href="https://code.google.com/p/modpagespeed/" target="_blank" rel="noopener">modpagespeed</a>，结合apache的内存缓存，减少服务器IO开销。</p><p>比较理想的方式还是在web服务器加上一个反向代理服务器(varnish、nginx)，它来缓存静态资源文件</p><p>开源的公共js、css库，可以考虑各种开源cdn服务，鉴于国内的网络情况，推荐两个国内的cdn：</p><ul><li><a href="http://developer.baidu.com/wiki/index.php?title=docs/cplat/libs" target="_blank" rel="noopener">百度cdn</a></li><li><a href="http://www.staticfile.org/" target="_blank" rel="noopener">开发静态文件CDN</a></li></ul><h2 id="避免Java应用中NullPointerException的技巧和最佳实践"><a href="#避免Java应用中NullPointerException的技巧和最佳实践" class="headerlink" title="避免Java应用中NullPointerException的技巧和最佳实践"></a>避免Java应用中NullPointerException的技巧和最佳实践</h2><p><a href="http://www.importnew.com/7268.html" target="_blank" rel="noopener">http://www.importnew.com/7268.html</a></p><ol><li>从已知的String对象中调用equals()和equalsIgnoreCase()方法，而非未知对象。</li><li>当valueOf()和toString()返回相同的结果时，宁愿使用前者。</li><li>使用null安全的方法和库(spring和guava都提供了相关工具)</li><li>避免从方法中返回空指针，而是返回空collection或者空数组。</li><li>使用annotation@NotNull 和 @Nullable(目前是想起了才用，得强迫自己加上了)</li><li>避免你的代码中不必要的自动包装和自动解包。</li><li>遵从Contract并定义合理的默认值。</li><li>定义数据库中的字段是否可为空。</li><li>使用空对象模式（Null Object Pattern）</li></ol><h2 id="如何优雅地使用-Windows-系统？"><a href="#如何优雅地使用-Windows-系统？" class="headerlink" title="如何优雅地使用 Windows 系统？"></a>如何优雅地使用 Windows 系统？</h2><p><a href="http://daily.zhihu.com/story/395" target="_blank" rel="noopener">http://daily.zhihu.com/story/395</a></p><p>不离不弃windows很多年了，令人恶心的超级本天天让我纠结，下次一定换MAC。不过还是先将就下。</p><h2 id="tomcat进程关闭时收集dump信息"><a href="#tomcat进程关闭时收集dump信息" class="headerlink" title="tomcat进程关闭时收集dump信息"></a>tomcat进程关闭时收集dump信息</h2><p><a href="https://gist.github.com/bohrqiu/6518715" target="_blank" rel="noopener">https://gist.github.com/bohrqiu/6518715</a></p><p>给gist加个超链接</p><h2 id="PhantomJS"><a href="#PhantomJS" class="headerlink" title="PhantomJS"></a>PhantomJS</h2><p><a href="http://phantomjs.org/" target="_blank" rel="noopener">http://phantomjs.org/</a></p><p>PhantomJS 是一个基于webkit的无界面浏览器，它提供了js api来实现dom操作、css选择器、json、canvas、svg</p><p>PhantomJS适用于下列场景：</p><ul><li><a href="http://phantomjs.org/headless-testing.html" target="_blank" rel="noopener">无界面网站测试</a></li></ul><ul><li><a href="http://phantomjs.org/screen-capture.html" target="_blank" rel="noopener">网站屏幕截图</a></li><li><p><a href="http://phantomjs.org/page-automation.html" target="_blank" rel="noopener">页面操纵</a></p><p>  通过标准dom api或者开源库访问和操作dom</p></li><li><p><a href="http://phantomjs.org/network-monitoring.html" target="_blank" rel="noopener">网络监控</a></p><p>  包括网页加载测试、结合yslow和jenkins实现自动化页面性能测试</p></li></ul><p>貌似速度比Selenium快，用它来抓取页面数据应该很happy。官方有很多<a href="https://github.com/ariya/phantomjs/tree/master/examples" target="_blank" rel="noopener">栗子</a>，可以深入挖掘下。</p><h2 id="Advanced-REST-client"><a href="#Advanced-REST-client" class="headerlink" title="Advanced REST client"></a>Advanced REST client</h2><p><a href="https://chrome.google.com/webstore/detail/advanced-rest-client/hgmloofddffdnphfgcellkdfbfbjeloo" target="_blank" rel="noopener">https://chrome.google.com/webstore/detail/advanced-rest-client/hgmloofddffdnphfgcellkdfbfbjeloo</a></p><p>构造一个rest请求，有时候有点麻烦，借助Advanced REST client，可以很方便的chrome中构造一个REST请求，方便测试</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> spring mvc static resource handle </tag>
            
            <tag> web frontend tuning </tag>
            
            <tag> NullPointerException </tag>
            
            <tag> Windows </tag>
            
            <tag> PhantomJS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JSR303</title>
      <link href="/jsr303/"/>
      <url>/jsr303/</url>
      <content type="html"><![CDATA[<h2 id="how-to-obtain-a-validator"><a href="#how-to-obtain-a-validator" class="headerlink" title="how to obtain a validator"></a>how to obtain a validator</h2><p>To obtain a Validator, you must first create a ValidatorFactory. If there is only one Bean Validation implementation in your classpath, you can use:</p><pre><code>ValidatorFactory vf = Validation.buildDefaultValidatorFactory();</code></pre><p>You should usually not instantiate more than one factory; factory creation is a costly process. Also, the factory also acts as a cache for the available validation constraints.<br><a id="more"></a><br>Below is an example that will create a singleton ValidatorFactory and will let you obtain Validators from it:</p><pre><code>public enum MyValidatorFactory {    SINGLE_INSTANCE {        ValidatorFactory avf =            Validation.byProvider(ApacheValidationProvider.class).configure().buildValidatorFactory();        @Override        public Validator getValidator() {            return avf.getValidator();        }    };        public abstract Validator getValidator(); }</code></pre><p>Using the above class, obtaining a Validator just requires you to call:</p><pre><code>MyValidatorFactory.SINGLE_INSTANCE.getValidator()</code></pre><h2 id="Using-The-Spring-Framework"><a href="#Using-The-Spring-Framework" class="headerlink" title="Using The Spring Framework"></a>Using The Spring Framework</h2><p>If you are using Spring, you can easily inject Validators into your beans. Simply configure the factory in your ApplicationContext by adding:</p><pre><code>&lt;!-- Validator bean --&gt;&lt;bean id=&quot;validator&quot;    class=&quot;org.springframework.validation.beanvalidation.LocalValidatorFactoryBean&quot;&gt;    &lt;property name=&quot;providerClass&quot;        value=&quot;org.apache.bval.jsr303.ApacheValidationProvider&quot; /&gt;&lt;/bean&gt;</code></pre><p>And Spring will be able to inject Validators and the ValidatorFactory into your beans.</p><h2 id="comment"><a href="#comment" class="headerlink" title="comment:"></a>comment:</h2><p>这里使用的是<a href="http://bval.apache.org/obtaining-a-validator.html" target="_blank" rel="noopener">apache bval</a>,<br>一般使用hibernate的实现.</p><p>在javabean中使用validator时，一定要是静态的,别遇上序列化问题</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsr303 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>cxf如何传字段为null</title>
      <link href="/cxf-trans-filed-null/"/>
      <url>/cxf-trans-filed-null/</url>
      <content type="html"><![CDATA[<p>传输对象如下：</p><pre><code>public class EmailSenderOrder {private String clientName=&quot;test&quot;;//clientName默认值为test}</code></pre><p>应用场景需要传输的<code>clientName</code>为null，我们在使用client时，会有如下代码：</p><pre><code>EmailSenderOrder emailSenderOrder = new EmailSenderOrder(); emailSenderOrder.setClientName(null); </code></pre><p>服务端在接受到对象后，clientName结果等于了test。<br><a id="more"></a><br>默认情况下，如果field为null，cxf client生成的报文中没有这个field的报文，这就导致在反序列化时，初始化对象时用了默认值。</p><p>可以如下解决：</p><pre><code>//通过字段序列化@XmlAccessorType(XmlAccessType.FIELD) public class EmailSenderOrder {//如果clientName为null，生成报文&lt;clientName xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:nil=&quot;true&quot;/&gt;@XmlElement(name = &quot;clientName&quot;, nillable = true) private String clientName=&quot;test&quot;;}</code></pre>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cxf </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>zookeeper</title>
      <link href="/zookeeper-dev-ops/"/>
      <url>/zookeeper-dev-ops/</url>
      <content type="html"><![CDATA[<h2 id="原理相关"><a href="#原理相关" class="headerlink" title="原理相关:"></a>原理相关:</h2><ol><li>Three ZooKeeper servers is the minimum recommended size for an ensemble, and we also recommend that they run on separate machines. Because Zookeeper requires a majority, it is best to use an odd number of machines.To create a deployment that can tolerate the failure of F machines, you should count on deploying 2xF+1 machines. <a id="more"></a></li><li>The replicated database is an in-memory database containing the entire data tree. Updates are logged to disk for recoverability, and writes are serialized to disk before they are applied to the in-memory database.</li><li><p>Read requests are serviced from the local replica of each server database. Requests that change the state of the service, write requests, are processed by an agreement protocol.As part of the agreement protocol all write requests from clients are forwarded to a single server, called the leader. The rest of the ZooKeeper servers, called followers, receive message proposals from the leader and agree upon message delivery. The messaging layer takes care of replacing leaders on failures and syncing followers with leaders.(读请求直接读本地节点，写请求写到leader节点，其他follower节点从leader同步)</p></li><li><p>zookeeper对于修改操作会优先顺序写入事务日志，保证可用性，所以不能使用很繁忙的设备写事务日志。</p></li><li><p>dataDir store the in-memory database snapshots </p></li><li><p>使用 daemontools or SMF来保证zookeeper进程down后自动重启</p></li><li><p>If you only have one storage device, put trace files on NFS and increase the snapshotCount; it doesn’t eliminate the problem, but it should mitigate it.</p></li><li><p>可以在zookeeper集群前使用L4 LB,但是要注意LB failure detect机制，保证能快速的发现后端失败的服务器.不然的话，请求有可能被发送到down掉的server上。（<a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/FAQ" target="_blank" rel="noopener">Can I run an ensemble cluster behind a load balancer?</a>）</p></li><li><p>在每个ZK机器上，我们需要在数据目录（数据目录就是dataDir参数指定的那个目录）下创建一个myid文件，myid中就是这个Server ID数字。</p></li><li><p>zookeeper监控</p><pre><code>http://jm.taobao.org/2012/01/12/zookeeper%E7%9B%91%E6%8E%A7/ </code></pre></li><li><p>java client</p><pre><code>https://github.com/Netflix/curator</code></pre><p>应该是最优秀的zookeeper client了，避免原生client的一些问题，并提供一些常用的工具</p></li><li><p>zookeeper eclipse插件</p><pre><code>http://www.massedynamic.org/mediawiki/index.php?title=Eclipse_Plug-in_for_ZooKeeper</code></pre></li><li><p>跨机房使用Observer</p><p>Observer不参与选举,永远是follower.跨机房时,读请求直接在Observer上搞定,写操作转到leader</p></li><li>其他资料：</li></ol><pre><code>http://rdc.taobao.com/team/jm/archives/2318https://cwiki.apache.org/confluence/display/ZOOKEEPER/Indexhttps://cwiki.apache.org/confluence/display/CURATOR/Third+Party+Articleshttp://wiki.apache.org/hadoop/ZooKeeper/FAQ</code></pre><hr><h2 id="开发相关"><a href="#开发相关" class="headerlink" title="开发相关:"></a>开发相关:</h2><h3 id="1-怎么处理CONNECTION-LOSS"><a href="#1-怎么处理CONNECTION-LOSS" class="headerlink" title="1.怎么处理CONNECTION_LOSS?"></a>1.怎么处理CONNECTION_LOSS?</h3><p>CONNECTION_LOSS意味着客户端和服务器端的连接坏了(坏了并不一定就是完全断开了,可能是连接不稳定).此异常并不意味着发送给zookeeper服务端的请求处理失败.当create请求发送到zk服务器并处理后,在响应时,网络坏了.这种情况下,需要用户判断是否处理成功或者重试.</p><p>zookeeper官方提供的Locker通过在EPHEMERAL_SEQUENTIAL中加入sessionId来判断当前session是否已经创建node.</p><h3 id="2-怎么处理SESSION-EXPIRED"><a href="#2-怎么处理SESSION-EXPIRED" class="headerlink" title="2.怎么处理SESSION_EXPIRED?"></a>2.怎么处理SESSION_EXPIRED?</h3><p>SESSION_EXPIRED说明客户端和zk服务端已经出现了网络分区,并且分区间隔时间超过了session timeout,zk服务器认为此client已经挂掉了.</p><p>zk集群来管理会话过期.zk client和服务端建立连接时,会设置一个timeout值,集群通过此值来确定session过期.当session过期后,集群会删除此会话的所有的ephemeral节点,并通知watcher.<strong>在这个时候,会话过期的节点和集群的连接仍然是断开的,当连接被重新建立后,会被通知session expiration.(客户端收到session expiration是当客户端又和zookeeper服务端重连后,client在网络异常的情况下,不知道何时session expiration)</strong></p><pre><code>状态流转的例子如下:    1. &apos;connected&apos; : session is established and client is communicating with cluster (client/server communication is operating properly)    2. .... client is partitioned from the cluster    3.&apos;disconnected&apos; : client has lost connectivity with the cluster    4. .... time elapses, after &apos;timeout&apos; period the cluster expires the session, nothing is seen by client as it is disconnected from cluster    5. .... time elapses, the client regains network level connectivity with the cluster    6. &apos;expired&apos; : eventually the client reconnects to the cluster, it is then notified of the expiration</code></pre><h3 id="3-InterruptedException"><a href="#3-InterruptedException" class="headerlink" title="3.InterruptedException"></a>3.InterruptedException</h3><p>ZooKeeper遵循java的线程中断机制,也通过此方式来取消用户操作.可以参照下面的代码,让InterruptedException中断操作,或者把此异常抛出去,让使用方来处理.</p><pre><code>@Overridepublic void process(WatchedEvent event) {    if (event.getType() == EventType.NodeDataChanged) {         try {            displayConfig();        } catch (InterruptedException e) {            System.err.println(&quot;Interrupted. Exiting.&quot;);             Thread.currentThread().interrupt();        } catch (KeeperException e) {             System.err.printf(&quot;KeeperException: %s. Exiting.\n&quot;, e);        }     }}</code></pre><h3 id="4-time"><a href="#4-time" class="headerlink" title="4.time"></a>4.time</h3><p>A low session timeout leads to faster detection of machine failure. </p><p>Applications that create more complex ephemeral state should favor longer session timeouts, as the cost of reconstruction is higher. In some cases, it is possible to design the application so it can restart within the session timeout period and avoid session expiry. (This might be desirable to perform maintenance or upgrades). <strong>Every session is given a unique identity and password by the server, and if these are passed to ZooKeeper while a connection is being made, it is possible to recover a session (as long as it hasn’t expired)</strong>. An application can therefore arrange a graceful shutdown, whereby it stores the session identity and password to stable storage before restarting the pro- cess, retrieving the stored session identity and password and recovering the session.</p><h3 id="5-The-single-event-thread"><a href="#5-The-single-event-thread" class="headerlink" title="5.The single event thread"></a>5.The single event thread</h3><p>每个zookeeper对象有一个线程来分发事件给watchers.如果你在watcher里面处理很耗时的操作,那么其他watchers会等这个watcher内处理完.</p><h3 id="6-官方demo分析"><a href="#6-官方demo分析" class="headerlink" title="6.官方demo分析"></a>6.官方demo分析</h3><p>基本原理:</p><p>在<code>dir</code>(简单理解为lock string)下面创建sequential ephemeral node(后面简称Node),如果创建的node序列号最小,则表明当前连接就是锁的持有者.</p><p>这里需要注意几个地方:</p><ol><li><p>在创建Node过程中网络分区,导致ConnectionLossException</p><p>比如在zookeeper服务端节点已经创建成功了,但是在返回结果时,网络出问题了.这个时候我们唯一能做的只是重试.但是重试创建节点操作又会导致新的Node被创建,最后出现没人管的孤儿节点,死锁奇迹般的发生了.</p><p>出现ConnectionLossException异常后,节点通过重试,SeesionId不会改变.官方的例子通过<code>&quot;x-&quot; + sessionId + &quot;-&quot;</code>作为<code>prefix</code>来检查这种情况.</p><p>在排序Node时,先比较<code>prefix</code>,再比较<code>sequence</code>.</p></li><li><p>羊群效应</p><p>如果在getChildren时加上watcher会导致每次child被删除时,所有child都会收到通知.如果在集群规模很大时,就很悲剧了.这里可以只监听比当前序号小的Node,来减少网络压力.比如Node-27监听Node-26,Node-26监听Node25</p></li><li><p>其他异常处理</p><p>对于不可恢复的异常,比如<code>SessionExpiredException</code>(The session timeout may not be less than 2 ticks or more than 20),这个异常需要抛给用户来处理,可以通过回调的方式让用户加入异常处理逻辑.</p><p><code>InterruptedException</code>异常要么抛出去,要么调用<code>Thread.currentThread().interrupt()</code>,别抓住了自己吃掉.</p></li></ol><p>官方的lock实现还算不错,只是太低层次了点(重试带着简单粗暴的美感,但是对于非幂等性操作谨慎).我们还需要通过<code>LockListener</code>结合<code>CountDownLatch</code>(当lockAcquired时countDown),来提供可阻塞的API.当然最好是我们弄个<code>java.util.concurrent.locks.Lock</code>的分布式锁实现.</p><p>参考:</p><pre><code>http://wiki.apache.org/hadoop/ZooKeeper/Troubleshootinghttps://www.inkling.com/read/hadoop-definitive-guide-tom-white-3rd/chapter-14/building-applications-withhttp://wiki.apache.org/hadoop/ZooKeeper/ErrorHandling</code></pre>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ZOOKEEPER </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hessian反序列化field值丢失bug</title>
      <link href="/hessian-java-serialization/"/>
      <url>/hessian-java-serialization/</url>
      <content type="html"><![CDATA[<h3 id="bug说明"><a href="#bug说明" class="headerlink" title="bug说明"></a>bug说明</h3><hr><p>子类和父类中有同名的字段时，hessian反序列化会丢失字段值。<br><a id="more"></a><br>父类<code>Person</code>：</p><pre><code>public class Person implements Serializable {    private static final long serialVersionUID = 1L;    private String name;    private int age;    public String getName() {        return name;    }    public void setName(String name) {        this.name = name;    }    public int getAge() {        return age;    }    public void setAge(int age) {        this.age = age;    }    @Override    public String toString() {        final StringBuilder sb = new StringBuilder(&quot;Person{&quot;);        sb.append(&quot;name=&apos;&quot;).append(name).append(&apos;\&apos;&apos;);        sb.append(&quot;, age=&quot;).append(age);        sb.append(&apos;}&apos;);        return sb.toString();    }}</code></pre><p>子类<code>PersonEx</code>：</p><pre><code>public class PersonEx  extends  Person{    private static final long    serialVersionUID    = 1L;    private String    name;    public String getName() {        return name;    }    public void setName(String name) {        this.name = name;    }    @Override    public String toString() {        final StringBuilder sb = new StringBuilder(&quot;PersonEx{&quot;);        sb.append(&quot;name=&apos;&quot;).append(name).append(&apos;\&apos;&apos;);        sb.append(&apos;}&apos;);        sb.append(super.toString());        return sb.toString();    }}</code></pre><p>当我们序列化如下对象后</p><pre><code>PersonEx p = new PersonEx();p.setName(&quot;XXX&quot;);p.setAge(28);</code></pre><p>后，反序列化回来的<code>PersonEx</code>对象<code>getName()==null</code>.</p><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><hr><p>造成这个问题的原因如下：<br>hessian序列化机制，他通过反射把所有字段名和值(整个传输对象图)读取出来,见<code>JavaSerializer#writeObject</code>:</p><pre><code>   if (ref == -1) {//写入需要反射的字段名  writeDefinition20(out);  out.writeObjectBegin(cl.getName());   }//写入值writeInstance(obj, out);</code></pre><p>按照此规则，现在序列化结构如下(忽略其他映射关系)：</p><pre><code>name|age|name|Person|XXX|28|null</code></pre><p>反序列化时，读取字段名，在set字段值：</p><ol><li>读取到name字段，调用<code>setName(&quot;XXX&quot;)</code></li><li>再次读取name字段，调用<code>setName(null)</code></li></ol><p>结果就囧了。。。。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><hr><h4 id="1-修改hessian代码"><a href="#1-修改hessian代码" class="headerlink" title="1.修改hessian代码"></a>1.修改hessian代码</h4><p>修改了hessian的序列化机制，当类的父对象出现相同的字段名时，跳过对此字段的处理。</p><pre><code>//添加成员变量propertiesNameSet        private HashSet&lt;String&gt; propertiesNameSet = Sets.newHashSet();//在JavaSerializer构造器里，遍历字段时，添加检查if (propertiesNameSet.contains(field.getName())) {      continue;} else {     propertiesNameSet.add(field.getName());}</code></pre><p>hessian在反序列化时有同名字段的判断<code>com.caucho.hessian.io.JavaDeserializer#getFieldMap</code>保证<code>fieldMap</code>中不出现同名的字段。</p><h4 id="2-修改同名字段问题"><a href="#2-修改同名字段问题" class="headerlink" title="2.修改同名字段问题"></a>2.修改同名字段问题</h4><p>出现了同名字段，也可以认为是我们代码设计出问题了，没有理解清楚继承结构。在子类中删除同名的字段，就避免这个bug。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>现在的序列化框架基本上都会遇到此问题,<code>Kryo</code>中的<code>com.esotericsoftware.kryo.serializers.CompatibleFieldSerializer</code>也没有对此问题进行处理.作为框架开发者,要尽量减少框架使用者犯错误的机会,也就是所谓的防御性编程吧.</p><p>给<code>Kryo</code> <a href="https://github.com/EsotericSoftware/kryo/pull/187" target="_blank" rel="noopener">pull request</a> ,防止因为子类和父类中有同名field name而导致的问题.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hessian </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2013年11月读书笔记</title>
      <link href="/2013-11-reading-notes/"/>
      <url>/2013-11-reading-notes/</url>
      <content type="html"><![CDATA[<h2 id="Netty-4-at-Twitter-Reduced-GC-Overhead"><a href="#Netty-4-at-Twitter-Reduced-GC-Overhead" class="headerlink" title="Netty 4 at Twitter: Reduced GC Overhead"></a>Netty 4 at Twitter: Reduced GC Overhead</h2><p><a href="https://blog.twitter.com/2013/netty-4-at-twitter-reduced-gc-overhead" target="_blank" rel="noopener">https://blog.twitter.com/2013/netty-4-at-twitter-reduced-gc-overhead</a></p><p>主要讲了netty4在减少gc压力和内存带宽消耗上的改进：<br>新消息收到或者发送消息时netty3会创建一个buffer，创建字节数组<code>new byte[capacity]</code>，并用0来填充数组，这样会造成gc压力和内存带宽消耗，nettry4中为不同的事件定义不同的处理方法，减少事件对象创建。<br>netty4中引入新接口ByteBufAllocator，它提供一个buffer池(类似于<a href="https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919" target="_blank" rel="noopener">jemalloc</a> )，实现buddy memory allocation and slab allocation.</p><a id="more"></a><h2 id="Buddy-memory-allocation"><a href="#Buddy-memory-allocation" class="headerlink" title="Buddy memory allocation"></a>Buddy memory allocation</h2><p><a href="https://en.wikipedia.org/wiki/Buddy_memory_allocation" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Buddy_memory_allocation</a></p><p>buddy memory allocation是一种内存分配算法，它把内存划分为不同的分区，尽量满足不同的内存请求。最常见的是binary buddies，每一个内存block有一个order，order从0到某个值，在不同的order的block按照2order 的大小比例 ，所以满足 orderA=orderB-1 ，block  B的大小为blockA的两倍。<br>首先需要确定最小block的大小(最小的可被分配的内存块)。最小快太小，操作系统会消耗过多内存和计算资源去跟踪内存块分配和回收。最小快比较大，又造成内存浪费。最小block的大小作为order0 block大小。</p><h2 id="Slab-allocation"><a href="#Slab-allocation" class="headerlink" title="Slab allocation"></a>Slab allocation</h2><p><a href="https://en.wikipedia.org/wiki/Slab_allocation" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Slab_allocation</a></p><p>slab allocation是一种内存管理机制，用于有效的内存分配，并尽量消除分配和回收内存过程中造成的碎片。它按照预先规定的大小，将分配的内存分割成特定长度的内存块，再把尺寸相同的内存块分成组，这些内存块不会释放，可以重复利用。</p><h2 id="Scalable-memory-allocation-using-jemalloc"><a href="#Scalable-memory-allocation-using-jemalloc" class="headerlink" title="Scalable memory allocation using jemalloc"></a>Scalable memory allocation using jemalloc</h2><p><a href="https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919" target="_blank" rel="noopener">https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919</a></p><p><a href="http://blog.linuxeye.com/355.html" target="_blank" rel="noopener">TCMalloc优化MySQL、Nginx、Redis内存管理</a></p><p><a href="http://wangkaisino.blog.163.com/blog/static/1870444202011431112323846/" target="_blank" rel="noopener">更好的内存管理-jemalloc</a></p><h2 id="Heartbeat-In-Persistent-Connection"><a href="#Heartbeat-In-Persistent-Connection" class="headerlink" title="Heartbeat In Persistent Connection"></a>Heartbeat In Persistent Connection</h2><p><a href="http://cheney-mydream.iteye.com/blog/1497152" target="_blank" rel="noopener">http://cheney-mydream.iteye.com/blog/1497152</a></p><p><a href="http://bbs.csdn.net/topics/360072641" target="_blank" rel="noopener">http://bbs.csdn.net/topics/360072641</a></p><p>TCP连接建立过后,如果没有心跳，时间长了就会产生“僵尸连接”，就是通信的双方其实连接已经断了，但由于TCP并不定时检测连接是否中断，而通信的双方又相互没有send操作，导致该连接在通信的双方的tcp上一直有效，占用操作系统资源。这时TCP连接是不可使用的，但是对于应用层并不知道，心跳包主要也就是用于长连接的保活和断线处理。</p><p>在rabbitmq client中，为了保证连接可用使用HeartbeatSender来定时发送心跳包。同样的，在druid中，可以配置在连接空闲达到阀值时，执行简单的sql来检测连接是否有效。</p><h2 id="Nashorn-Naz-horn"><a href="#Nashorn-Naz-horn" class="headerlink" title="Nashorn(Naz-horn)"></a>Nashorn(Naz-horn)</h2><p><a href="https://oracleus.activeevents.com/2013/connect/sessionDetail.ww?SESSION_ID=7835" target="_blank" rel="noopener">https://oracleus.activeevents.com/2013/connect/sessiondetail.ww?session_id=7835</a></p><p>介绍了noshorn一些用法<br>Shell Scripting部分介绍了使用Noshorn来编写shell 脚本，以后可以摆脱bash了。其他包括Noshorn中java互操性、线程、调试等。</p><p><a href="https://oracleus.activeevents.com/2013/connect/sessionDetail.ww?SESSION_ID=5793" target="_blank" rel="noopener">https://oracleus.activeevents.com/2013/connect/sessionDetail.ww?SESSION_ID=5793</a></p><p>介绍了Noshorn是什么:</p><ol><li>JVM上的javascript引擎</li><li>100% java实现</li><li>终极invokedynamic用户</li><li>100%编译成字节码执行</li><li>100% 兼容ECMASCRIPT5.1</li></ol><p>没有浏览器API(HTML5 canvas、HTML5 canvas、WebWorkers WebSockets、WebGL)</p><p><a href="https://oracleus.activeevents.com/2013/connect/sessionDetail.ww?SESSION_ID=2585" target="_blank" rel="noopener">https://oracleus.activeevents.com/2013/connect/sessionDetail.ww?SESSION_ID=2585</a></p><p>介绍了JVM上的内嵌脚本语言，JSR-223 (javax.script规范)，其中提到了使用script语言结合动态代理，并实时检测脚本文件变动实现live reloading。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> READING NOTES </tag>
            
            <tag> netty </tag>
            
            <tag> Persistent Connection </tag>
            
            <tag> memory allocation </tag>
            
            <tag> Noshorn </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kryo反序列化时版本不一致导致OOM</title>
      <link href="/kryo-oom/"/>
      <url>/kryo-oom/</url>
      <content type="html"><![CDATA[<p>生产环境某系统上线大概4-5个小时后，出现OOM(java.lang.OutOfMemoryError: Java heap space )异常。按照目前的压力来说出现OOM不应该，本次上线也没有对代码进行过多的修改。和相关开发人员沟通后，发现上线之前memcached缓存没有清空，memcached存储着kryo序列化后的二进制数据，涉及到的对象增加了属性，初步怀疑是kryo反序列话时出了问题。</p><a id="more"></a><p>拿到hprof日志后，分析如下：</p><p>初步用jvisualvm看下</p><p><img src="/kryo-oom/1.jpg" alt=""></p><p>占用内存很小，tomcat的heap设置为4096M，不可能是内存泄漏造成的。</p><p>分析线程dump发现</p><p><img src="/kryo-oom/2.jpg" alt=""></p><p>在kryo反序列化报了oom</p><p>用MAT执行OQL:</p><p><img src="/kryo-oom/3.jpg" alt=""></p><p>dump buffer(见附件)到本地反序列化</p><p><img src="/kryo-oom/4.jpg" alt=""></p><p>然后就悲剧了…</p><p><img src="/kryo-oom/5.jpg" alt=""></p><p>要分配的这个char数组太大了，内存根本就不足。kryo序列化不会存储java 字段信息，他会把属性值按照一定的顺序写到byte数组里面的(没有字段信息)。如果反序列化时，java对象结构变化，就有可能出现今天的悲剧事件。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KRYO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>web服务器集群技术</title>
      <link href="/web-layer-cluster/"/>
      <url>/web-layer-cluster/</url>
      <content type="html"><![CDATA[<p>web服务器集群技术包括web负载均衡和http session 失效转移<br><a id="more"></a></p><h2 id="1-负载均衡"><a href="#1-负载均衡" class="headerlink" title="1.负载均衡"></a>1.负载均衡</h2><p>负载均衡我们主要关注以下四点：</p><h3 id="1-1-实现负载均衡的算法"><a href="#1-1-实现负载均衡的算法" class="headerlink" title="1.1 实现负载均衡的算法"></a>1.1 实现负载均衡的算法</h3><p>实现的算法很多，可以参考<a href="http://www.cnblogs.com/shanyou/archive/2012/11/09/2763272.html" target="_blank" rel="noopener">此文章</a>。最好是选用通过检测后端服务器状态来实现最优的负载均衡。</p><h3 id="1-2-健康检查"><a href="#1-2-健康检查" class="headerlink" title="1.2 健康检查"></a>1.2 健康检查</h3><p>当一台服务器失效了，负载均衡器应当检测出失效并不再将请求分发到这台服务器上。同样，它也要检测服务器是否恢复正常，并恢复分发请求。</p><p>健康检测要关注检测状态所消耗的时间，比如haproxy如下的配置：</p><pre><code>check inter 2000 rise 2 fall 3</code></pre><p>检测周期为2s，连续成功2次认为节点恢复，连续失败3次认为节点不能提供服务。这里就存在负载均衡和后端服务状态不一致的时间窗口6s，我们需要通过一些机制或者手段去掉这6s对用户的影响或者尽量减少对用户的影响。</p><p>通过haproxy的redispatch机制，我们可以减少对用户的影响。通过在负载均衡上主动关闭流量，我们几乎可以做到完全屏蔽用户的影响(关闭流量会引导新请求到其他节点，对于正在处理的请求，我们最好是等一段时间，让他处理完，等待时间和影响用户感知，这个由业务来权衡)。</p><h3 id="1-3-会话粘滞"><a href="#1-3-会话粘滞" class="headerlink" title="1.3 会话粘滞"></a>1.3 会话粘滞</h3><p>机制很多，我觉得比较好的方式是在第一次http请求时向cookie写入节点信息(减少代理上网造成的不均衡)，后续的请求都转发到此节点。</p><p>我们需要根据不同的应用选择是否启用会话粘滞。如果是接口调用，我们没有必要支持会话粘滞；如果是web页面，我们需要启用此特性。还需要注意的一点是，负载均衡上的会话超时时间设置应该大于或者等于web容器的会话超时时间设置。</p><h3 id="1-4-其他"><a href="#1-4-其他" class="headerlink" title="1.4 其他"></a>1.4 其他</h3><p>其他功能和负载均衡关系不是很大，但是可以放在负载均衡设备上来做。比如ssl卸载、gzip压缩、内容缓存。在我们访问量比较少的情况下，这些操作还是放在web容器来做吧，省钱。</p><h2 id="2-Session失效转移"><a href="#2-Session失效转移" class="headerlink" title="2. Session失效转移"></a>2. Session失效转移</h2><p>session失效转移是说在用户访问的某节点挂掉后，用户还能够正常的获取session做操作，这里面通常会涉及到三个问题：</p><h3 id="2-1-全局http-session-id"><a href="#2-1-全局http-session-id" class="headerlink" title="2.1 全局http session id"></a>2.1 全局http session id</h3><p>如果session不能唯一，这肯定要天下大乱，后面我会谈到在memcached-session-manager中怎么保证session id不重复</p><h3 id="2-2-如何备份会话状态"><a href="#2-2-如何备份会话状态" class="headerlink" title="2.2 如何备份会话状态"></a>2.2 如何备份会话状态</h3><p>常见的机制有：数据库备份、广播复制(所有集群内的web容器都保存所有的会话)、对等复制(每台服务器任意选择一台服务器备份)、中心状态服务器复制(session保存到中心服务器)、分布式缓存(现在大多数互联网企业选择的方案)</p><h3 id="2-3-备份的频率和粒度"><a href="#2-3-备份的频率和粒度" class="headerlink" title="2.3 备份的频率和粒度"></a>2.3 备份的频率和粒度</h3><p>备份频率和粒度很影响性能和可靠性</p><h4 id="2-3-1-备份频率："><a href="#2-3-1-备份频率：" class="headerlink" title="2.3.1 备份频率："></a>2.3.1 备份频率：</h4><ul><li>在web请求处理结束后备份 </li><li>固定时间间隔备份</li></ul><p>memcached-session-manager灵活的使用了web请求结束后备份和固定时间间隔机制检查，来提高性能。</p><h4 id="2-3-2-备份粒度："><a href="#2-3-2-备份粒度：" class="headerlink" title="2.3.2 备份粒度："></a>2.3.2 备份粒度：</h4><ul><li><p>整个会话</p><p>  每次都备份整个会话，这样可以带来易用性，但是性能不佳</p></li><li><p>修改过的会话</p><p>  仅当会话修改后才备份会话。当“session.setAttribute()”或 “session.removeAttribute()”被调用后，则认为会话被修改过。所以这种方式，我们在修改会话内的对象时，必须主动调一次set/removeAttribute,让它知道这个会话已经被修改。我们可以在序列化对象时做压缩尽量减少网络的开销。</p></li><li><p>修改过的属性</p><p>  这种方式带来最小的网络开销，可能会遇到一些问题。比如后端缓存服务器是否支持，属性之间的交叉引用如何识别等。属性交叉引用可以通过计算所有属性的hash值来判断某属性的修改是否会影响到其他属性，我们需要权衡网络开销和cpu消耗</p></li></ul><h2 id="3-我们的选择"><a href="#3-我们的选择" class="headerlink" title="3. 我们的选择"></a>3. 我们的选择</h2><h3 id="3-1-负载均衡"><a href="#3-1-负载均衡" class="headerlink" title="3.1 负载均衡"></a>3.1 负载均衡</h3><p>负载均衡可以用硬件或者软件来实现。如果从成本的角度考虑，现阶段用软负载可能更好。我们需要从性能、稳定性、负载的产品重要性几个方面来考虑</p><h3 id="3-2-session失效转移"><a href="#3-2-session失效转移" class="headerlink" title="3.2 session失效转移"></a>3.2 session失效转移</h3><p>我们采用缓存集群来保存session，数据的可用性、一致性交给缓存集群。备份粒度和频率我们通过组件来实现。</p><h4 id="3-2-1-分布式缓存产品的选择"><a href="#3-2-1-分布式缓存产品的选择" class="headerlink" title="3.2.1 分布式缓存产品的选择"></a>3.2.1 分布式缓存产品的选择</h4><p>备份的粒度是决定我们选择分布式缓存产品的一个重要因素。备份整个会话或者修改过的会话，我们可以选择key-value类型的nosql缓存组件。如果我们要支持<code>备份修改过的属性</code>,我们需要选择支持更多数据(比如支持内置的命名空间，MAP)结构的nosql缓存组件。</p><p>memcached、mongodb、redis、tair、mongodb、voldemort…有很多很多nosql产品我们可以选择。选择机会多了，选择也就越难了。</p><p>根据CAP理论，我们只能在一致性、可用性、分区容错性上取舍，根据不同的应用场景来选择不同的处理方式。没有绝对的最优，只有不断的根据我们不同阶段的特点选择不同的产品。</p><p>对于缓存来说最好的选择方案是选择支持灵活的路由机制(服务端路由或者client路由保证AP)，支持丰富的数据结构(从易用性和性能考虑)，支持数据持久化(保证A，最好是有这个特性，当然缓存嘛，只是来加快应用的，不应该把数据只存在缓存中，不能保证高可用)，支持多版本控制(尽量保证C)。</p><p>下图是voldemort(有幸参与过此产品的应用开发)的物理架构图。大多数的nosql产品都面临这下面三种物理架构的抉择。</p><p><img src="http://www.project-voldemort.com/voldemort/images/physical_arch.png" alt=""></p><p>memcached、redis只支持客户端路由，严格意义上讲，它算不上分布式缓存组件。如果要达到高可用性和分区容错性，我们需要自己来存多份(<a href="http://www.project-voldemort.com/voldemort/design.html" target="_blank" rel="noopener">NRW</a>Routing Parameters部分)</p><p>选择mongodb、mongodb、tair、voldemort算是比较好的方案，鉴于我们的运维能力，可能hold不住，暂时只能呵呵了。tair相对来说，很适合我们的应用场景，支持比纯KV更丰富的数据结构，支持服务端路由，支持服务端NRW。</p><p>目前我们选择memcached作为缓存组件。</p><h4 id="3-2-2-session备份组件的选择"><a href="#3-2-2-session备份组件的选择" class="headerlink" title="3.2.2 session备份组件的选择"></a>3.2.2 session备份组件的选择</h4><p>我们可以通过filter来备份session。但是对于后端缓存组件选用memcached来说，这样会存在一个问题。存储的key为sessionid，通过hash或者<a href="http://blog.csdn.net/sparkliang/article/details/5279393" target="_blank" rel="noopener">一致性hash</a>来实现路由，这样在memcached集群拓扑变动时，会造成路由的迁移(拓扑变动造成路由到不同的memcached服务器)。对于应用来说，缓存丢失了。</p><p>如果我们能把第一次选择memcached节点写入到sessionid里面，后续的请求都根据sessionid中的node信息选择memcached，这样在节点动态调整时，不会造成缓存丢失。但是我们在filter中不能改变sessionid的值，所以我们选择了<a href="https://code.google.com/p/memcached-session-manager/" target="_blank" rel="noopener">memcached-session-manager</a>。</p><h2 id="4-memcached-session-manager"><a href="#4-memcached-session-manager" class="headerlink" title="4.memcached-session-manager"></a>4.memcached-session-manager</h2><h3 id="4-1-主要特性如下："><a href="#4-1-主要特性如下：" class="headerlink" title="4.1 主要特性如下："></a>4.1 主要特性如下：</h3><ul><li><p>Supports Tomcat 6 and Tomcat 7</p></li><li><p>Handles sticky or non-sticky sessions</p><p>  启用session sticky时，memcached作为二级缓存，tomcat不挂掉时，不会从memcached取数据</p></li><li><p>No Single Point of Failure</p></li><li><p>Handles tomcat failover</p><p>  tomcat挂掉时从memcached读取session</p></li><li><p>Handles memcached failover</p><p>  non-sticky模式下，由于jvm没有缓存session，它会把session存到两台memcached，保证可用性。<br>  在sticky模式下，jvm缓存着session，一台memcached也会存session，也保证了可用性。</p><p>  当然，这个只是相对的保证了可用性，不能完全保证可用性。</p></li><li><p>Comes with pluggable session serialization</p><p>  我们可以选择kryo作为序列化组件</p></li><li><p>Allows asynchronous session storage for faster response times</p><p>  在请求响应之前，异步写入session到memcached</p></li><li><p>Sessions are only sent to memcached if they’re actually modified</p><p>  仅当session被修改时，才存储session</p></li><li><p>JMX management &amp; monitoring</p><p>  提供JMX管理监控功能</p></li></ul><h3 id="4-2-代码分析"><a href="#4-2-代码分析" class="headerlink" title="4.2 代码分析"></a>4.2 代码分析</h3><p>考虑到性能，我们只采用sticky模式(jvm和一个memcached中存session)，主要的功能实现如下：</p><ul><li><p>session创建</p><p>  a.<code>request.getSession()</code>调用<code>MemcachedSessionService#createSession</code>,创建session</p><p>  b.用<code>org.apache.catalina.util.SessionIdGenerator</code>生成sessionid，</p><p>  c.在sessionid中加入memcached节点信息(<code>MemcachedSessionService.newSessionId</code>，通过<code>NodeIdService.getMemcachedNodeId</code>随机选择节点)</p><p>  注意：SessionIdGenerator只能保证jvm内的不重复，多个jvm下需要另外的id生成机制，如果加上jvmRoute可以避规这个问题。</p></li></ul><ul><li><p>session恢复</p><p>  a.首先在本地session缓存中找session，如果有此session。就用此session</p><p>  b.如果本地缓存没有session，则MemcachedSessionService.findSession通过用户请求传来的sessionid从memcached服务器找session</p></li></ul><ul><li><p>session存储</p><p>  在请求结束后(de.javakaffee.web.msm.RequestTrackingHostValve:173)，会检测session是否有修改(调用session.setAttribute标记此session被修改)。如果修改，(de.javakaffee.web.msm.BackupSessionService:205)创建一个BackupSessionTask，在检查到session内容改变后异步(通过序列化后的的byte数组做hash比较)写入memcached。</p></li></ul><ul><li><p>session过期策略</p><p>  如果仅仅使用session.maxInactiveInterval，在session初始化时设置此key的过期时间。这需要在每次session被访问时都修改memcached中的getLastAccessedTime，这样做效率不是太好。所以在memcached-session-manager通过容器来提供周期性的回调，检查需要过期的时间。</p><p>  通过ContainerBackgroundProcessor线程来周期性的回调MemcachedBackupSessionManager.backgroundProcess()方法。过期时间为：session.maxInactiveInterval - timeIdle</p><p>  注意：需要保证memcached和应用服务器时间一致</p></li><li><p>session销毁</p><p>  MemcachedBackupSessionManager.removeInternal，会把memcached和jvm中的session清理掉</p><p>  注意：在销毁session时如果memcached挂掉，会出现不一致的情况。</p></li><li><p>可靠性</p><p>  选择采用sticky模式时，没有多份复制数据。如果很不幸，tomcat和memcached都挂了，session就丢失了。见官方<a href="https://groups.google.com/forum/#!topic/memcached-session-manager/W6z6eSuhAJ0" target="_blank" rel="noopener">maillist</a>。</p><p>  在非sticky模式下，session会保存到两个memcached(MemcachedSessionService:1079)。但是tomcat本地没有存储session，会影响所有的请求性能。</p></li></ul><ul><li><p>memcached状态检测</p><p>  在创建、查找session、恢复session时，都会通过NodeAvailabilityCache检测memcached状态，检测后端memcached状态间隔50ms(MemcachedNodesManager.NODE_AVAILABILITY_CACHE_TTL)</p></li></ul><h3 id="4-3-最佳实践"><a href="#4-3-最佳实践" class="headerlink" title="4.3 最佳实践"></a>4.3 最佳实践</h3><p>根据上面的代码分析，以下的最佳实践适合我们。</p><p>对于我们的开发同学，session里面的对象修改后，需要setAttribute下。</p><p>对于运维同学：</p><ul><li><p>设置tomcat jvmRoute，避免sessionid重复</p></li><li><p>MemcachedSessionService.setMemcachedProtocol设置二进制协议</p></li><li><p>MemcachedSessionService.setSessionBackupTimeout 默认异步操作100ms超时，在网络不好的情况下会出现大量的异常，设置长点。</p></li><li><p>MemcachedSessionService.setOperationTimeout是memcached客户端和服务端通信时的超时时间,不能设置太短</p></li></ul>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web cluster </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>日志优化</title>
      <link href="/log-tuning/"/>
      <url>/log-tuning/</url>
      <content type="html"><![CDATA[<p>一些日志优化相关的东东.</p><h2 id="1-关掉没用的appender"><a href="#1-关掉没用的appender" class="headerlink" title="1. 关掉没用的appender"></a>1. 关掉没用的appender</h2><p>现在我们所有的系统都会把日志输出到指定的文件，为了本地开发测试方便，我们也会把日志输出到控制台。在生产环境输出到控制台是完全没有必要的，既浪费了存储空间，又浪费了性能，请在生产环境去掉ConsoleAppender</p><ul><li>logback去掉<code>ch.qos.logback.core.ConsoleAppender</code></li><li>log4j去掉<code>org.apache.log4j.ConsoleAppender</code></li></ul><p>使用logback的同学也可以如下操作：</p><p>1.添加依赖</p><pre><code>&lt;dependency&gt;        &lt;groupId&gt;org.codehaus.janino&lt;/groupId&gt;        &lt;artifactId&gt;janino&lt;/artifactId&gt;        &lt;version&gt;2.5.16&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>2.修改logback.xml中原ConsoleAppender配置如下：</p><pre><code>&lt;if condition=&apos;property(&quot;os.name&quot;).toUpperCase().contains(&quot;WINDOWS&quot;)&apos;&gt;    &lt;then&gt;        &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;            &lt;encoder&gt;                &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}:%L-%msg%n%n&lt;/pattern&gt;            &lt;/encoder&gt;        &lt;/appender&gt;        &lt;root&gt;            &lt;appender-ref ref=&quot;STDOUT&quot; /&gt;        &lt;/root&gt;    &lt;/then&gt;&lt;/if&gt;</code></pre><p>上面的配置表示在windows中运行时日志输出到控制台，在其他系统中日志不输出到控制台</p><h2 id="2-禁用日志收集栈信息"><a href="#2-禁用日志收集栈信息" class="headerlink" title="2. 禁用日志收集栈信息"></a>2. 禁用日志收集栈信息</h2><p>在写日志时，打印行号能方便我们快速定位出问题的代码。此功能通过生成栈信息，然后定位到合适的栈帧来实现。禁用此功能会提高日志性能。</p><p>异步日志实现默认关闭了收集栈信息，见<code>ch.qos.logback.classic.AsyncAppender#includeCallerData</code></p><p>对于同步日志，只需要把<code>pattern</code>中的<code>%L</code>去掉就可以禁用栈信息。</p><h2 id="3-使用异步日志"><a href="#3-使用异步日志" class="headerlink" title="3. 使用异步日志"></a>3. 使用异步日志</h2><h3 id="3-1-logback"><a href="#3-1-logback" class="headerlink" title="3.1 logback"></a>3.1 logback</h3><p>logback只需要用异步appender包裹原来的appender就可以了</p><pre><code>&lt;appender name=&quot;ASYNC_ROLLING-cs&quot; class=&quot;com.yjf.common.log.LogbackAsyncAppender&quot;&gt;    &lt;appender-ref ref=&quot;ROLLING-cs&quot; /&gt;&lt;/appender&gt;</code></pre><p>目前我们使用了用于输出日志到文件的<code>ch.qos.logback.core.rolling.RollingFileAppender</code>和输出日志到rabbitmq的<code>com.yjf.monitor.client.integration.log.appender.jms.LogbackMsgRollingAppenderAdapter</code>，请都用上面的<code>LogbackAsyncAppender</code>包裹住。</p><p>此配置下，对象先放入一个队列，然后由另外一个线程来处理具体的日志输出，实现异步化，实现流程如下：</p><ul><li>queue大小为1024，如果queue剩余空间小于100时,会做丢弃判断</li><li>如果queue剩余空间小于100时，会丢弃TRACE、DEBUG日志，也会丢弃LoggerName不以com.yjf开始的INFO日志</li><li>如果queue没有剩余空间为0时，会阻塞业务线程，直到queue有剩余空间</li><li>输出日志到文件的appender，由于会用锁来控制多线程的写入，这种用单线程来写文件的方式很完美。</li><li>输出日志到rabbitmq的appender，<code>LogbackMsgRollingAppenderAdapter</code>在并发下会有性能问题，因为<code>LogbackMsgRollingAppenderAdapter</code>内部只用到一个channel，如果遇到高并发场景，请给<code>CachingConnectionFactory</code>设置合理的channelCacheSize值</li></ul><h3 id="3-2-log4j"><a href="#3-2-log4j" class="headerlink" title="3.2 log4j"></a>3.2 log4j</h3><ul><li>写日志到文件的appender，用<code>org.apache.log4j.AsyncAppender</code>代替<code>org.apache.log4j.DailyRollingFileAppender</code></li><li>写日志到rabbitmq的appender，建议用<code>com.yjf.common.log.Log4jAsynAmqpAppender</code>，内部也用queue来实现异步化</li></ul><h2 id="4-logger-api增强"><a href="#4-logger-api增强" class="headerlink" title="4. logger api增强"></a>4. logger api增强</h2><p>下面是常用的使用方式：</p><pre><code>logger.info(&quot;金额无效,手续费大于或者等于提现总金额.charge:{},amount:{}&quot;, new Object[] { 1, 2, 3 });logger.info(&quot;金额无效,手续费大于或者等于提现总金额.charge:{},amount:{},test:{}&quot;, 1, 2, 3); LoggerFormat.info(String.format(&quot;金额无效,手续费大于或者等于提现总金额.charge:%s,amount:%s,test:%s&quot;, 1, 2,3), logger);</code></pre><p>第一种是slf4j提供的原生api，第二种是yjf-common-utils提供的支持可变的参数的logger，第三种是yjf-common-util提供的日志工具类。这三种使用方式在日志级别为error的情况下，跑一百万次测试出的性能数据如下：</p><pre><code>LoggerFactoryTest.testLogOri: [measured 1000000 out of 1020000 rounds, threads: 4 (all cores)] round: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 2, GC.time: 0.62, time.total: 2.67, time.warmup: 0.04, time.bench: 2.63LoggerFactoryTest.testYjfLogger: [measured 1000000 out of 1020000 rounds, threads: 4 (all cores)] round: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 1, GC.time: 0.72, time.total: 3.43, time.warmup: 0.06, time.bench: 3.37LoggerFactoryTest.testLogUtils: [measured 1000000 out of 1020000 rounds, threads: 4 (all cores)] round: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 14, GC.time: 1.78, time.total: 11.62, time.warmup: 0.22, time.bench: 11.40</code></pre><p>从这些数据可以看出，第三种使用方式由于在方法调用时就有字符串拼接的开销，在error级别下，性能肯定不是很好。</p><p>在日志级别为info情况下，这种差距不是很大，但是如果我们使用异步日志，字符串的拼接在独立的线程中完成，不会在调用线程中完成，业务整体执行时间会减少。</p><p>第三种方式还有一个问题，行号永远显示的是LoggerFormat.info方法的行号，不便于我们定位问题。“懒”的同学就用第二种方式吧，支持变长参数，例子如下：</p><pre><code>import com.yjf.common.log.Logger;import com.yjf.common.log.LoggerFactory;...        Logger logger = LoggerFactory.getLogger(LoggerFactoryTest.class    .getName());...logger.info(&quot;xx:{} xx:{} xx:{}&quot;,&quot;a&quot;,&quot;b&quot;,&quot;c&quot;);logger.info(&quot;xx:{} xx:{} xx:[]&quot;, &quot;a&quot;,&quot;b&quot;,&quot;c&quot;, new RuntimeException(&quot;挂了&quot;));</code></pre><p>请不要再使用<code>com.yjf.common.log.LoggerFormat</code>和<code>com.yjf.common.lang.util.PrintLogTool</code></p><h2 id="5-tomcat日志优化"><a href="#5-tomcat日志优化" class="headerlink" title="5. tomcat日志优化"></a>5. tomcat日志优化</h2><p>tomcat embed默认日志使用的是<code>org.apache.juli.logging.DirectJDKLog</code>，此日志使用了<code>java.util.logging.Logger</code>，此logger使用了jre下面的配置文件<code>$JAVA_HOME\jre\lib\logging.properties</code>，此配置文件配置了一个处理器<code>java.util.logging.ConsoleHandler</code>，它只做了一个事情，使用<code>System.err</code>来作为默认的日志输出，也就是说tomcat embed遇到不能处理的异常后，用System.err来打印日志。(见：<code>org.apache.catalina.core.StandardWrapperValve#invoke</code>方法)</p><p>我们使用的的tomcat和tomcat embed有点差别，tomcat 中使用了<code>org.apache.juli.FileHandler</code>，此输出位置为<code>$CATALINA_HOME/logs/localhost.yyyy-MM-dd.log</code>，也就是说tomcat在遇到他搞不定的异常时，把日志输出到了此位置。<br>tomcat把输出和错误输出都打印到catalina.out文件了，见catalina.sh</p><pre><code>org.apache.catalina.startup.Bootstrap &quot;$@&quot; start \  &gt;&gt; &quot;$CATALINA_OUT&quot; 2&gt;&amp;1 &quot;&amp;&quot;</code></pre><p>这也解释了上次易交易产品遇到的那个问题，spring mvc action递归调用自己，catalina.out文件中没有异常日志。但是我在本地使用tomcat embed测试，会在控制台输出<code>StackOverflowError</code>。</p><p>tomcat日志优化点：</p><ul><li>用<code>org.apache.juli.AsyncFileHandler</code>代替<code>org.apache.juli.FileHandler</code></li><li>现在我们应用的日志目录都改为<code>/var/log/webapps/{project_name}/</code>。为了便于管理，tomcat 所有日志文件也会输出到<code>/var/log/webapps/{project_name}/</code>路径</li></ul><p>以上优化已提交到定制化tomcat模板。</p><h2 id="6-优化J-U-C"><a href="#6-优化J-U-C" class="headerlink" title="6.优化J.U.C"></a>6.优化J.U.C</h2><p>J.U.L代表java内置的日志机制，上面部分提到tomcat在遇到他搞不定的异常时，会把日志输出到<code>localhost.yyyy-MM-dd.log</code>。这样很不爽，很多同学在检查应用异常时，下意识的不会去看此日志文件，为了避免此问题，请使用下面的解决方案：</p><ol><li><p>使用<code>com.yjf.common.log.LogbackConfigListener</code>,使用方法见doc</p><p> 请使用yjf-common-util版本大于等于1.6.9.20130708的包</p></li><li><p>logback增加配置</p><pre><code>&lt;contextListener class=&quot;ch.qos.logback.classic.jul.LevelChangePropagator&quot;&gt;    &lt;resetJUL&gt;true&lt;/resetJUL&gt;  &lt;/contextListener&gt;</code></pre></li></ol><p>从此以后，所有的异常日志都会在应用日志文件中找到。</p><h2 id="7-性能测试"><a href="#7-性能测试" class="headerlink" title="7. 性能测试"></a>7. 性能测试</h2><p>测试四种情况，普通日志输出，普通日志禁用线程栈信息，异步日志，异步日志禁用线程栈信息，测试结果如下：</p><pre><code>LoggerPerfTest.testCommonLogger: [measured 100000 out of 101000 rounds, threads: 16 (physical processors: 4)] round: 0.00 [+- 0.00], round.block: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 2, GC.time: 0.12, time.total: 10.73, time.warmup: 0.11, time.bench: 10.62LoggerPerfTest.testCommonLoggerWithoutStackInfo: [measured 100000 out of 101000 rounds, threads: 16 (physical processors: 4)] round: 0.00 [+- 0.00], round.block: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 2, GC.time: 0.04, time.total: 3.93, time.warmup: 0.14, time.bench: 3.79LoggerPerfTest.testAsyncLogger: [measured 100000 out of 101000 rounds, threads: 16 (physical processors: 4)] round: 0.00 [+- 0.00], round.block: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 3, GC.time: 0.15, time.total: 2.77, time.warmup: 0.06, time.bench: 2.71LoggerPerfTest.testAsyncLoggerWithoutStackInfo: [measured 100000 out of 101000 rounds, threads: 16 (physical processors: 4)] round: 0.00 [+- 0.00], round.block: 0.00 [+- 0.00], round.gc: 0.00 [+- 0.00], GC.calls: 0, GC.time: 0.00, time.total: 1.86, time.warmup: 0.00, time.bench: 1.85</code></pre><p>可见异步日志性能会提升不少，不收集栈信息性能也会提升不少。</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日志优化 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用ssh tunneling和JMX远程监控java程序</title>
      <link href="/ssh-tunneling-and-JMX-for-remote-monitor/"/>
      <url>/ssh-tunneling-and-JMX-for-remote-monitor/</url>
      <content type="html"><![CDATA[<p>很多时候，我们需要连到远程应用服务器上去观察java进程的运行情况。由于邪恶的防火墙限制我们很难直接连到应用服务器。所以，也有了本文…<br><a id="more"></a><br>常见的网络拓扑结构如下：</p><p><img src="/ssh-tunneling-and-JMX-for-remote-monitor/network_topology.jpg" alt=""></p><p>如上图所示，办公电脑通过互联网连接跳板机,在跳板机上，我们可以访问应用服务器，查看应用服务器日志或做其他操作。现在我们需要在办公电脑上监控应用服务器1上的java进程。</p><h2 id="ssh-tunneling"><a href="#ssh-tunneling" class="headerlink" title="ssh tunneling"></a>ssh tunneling</h2><p>由于防火墙的限制，我们不能直接访问应用服务器。我们可以通过ssh tunneling来实现从办公电脑访问到应用服务器服务端口。</p><ul><li><p>跳板机：内网ip：192.168.0.1 外网ip：14.17.32.211 ssh端口：22</p></li><li><p>应用服务器1：内网ip：192.168.0.2 应用端口：11113</p></li></ul><p>通过ssh tunneling，我们利用ssh client建立ssh tunneling映射如下：</p><pre><code>127.0.0.1:11113-&gt;14.17.32.211:22-&gt;192.168.0.2:11113</code></pre><p>本地应用客户端通过访问本地11113端口，ssh client会把请求转发到应用服务器192.168.0.2:11113</p><h2 id="JMX"><a href="#JMX" class="headerlink" title="JMX"></a>JMX</h2><p>一个典型的jmx url：</p><p>service:jmx:rmi://localhost:5000/jndi/rmi://localhost:6000/jmxrmi</p><p>这个JMX URL可以分为如下几个部分：</p><ul><li><p>service:jmx: 这个是JMX URL的标准前缀，所有的JMX URL都必须以该字符串开头。</p></li><li><p>rmi: 这个是connector server的传输协议，在这个url中是使用rmi来进行传输的。JSR 160规定了所有connector server都必须至少实现rmi传输，是否还支持其他的传输协议依赖于具体的实现。比如MX4J就支持soap、soap+ssl、hessian、burlap等等传输协议。</p></li><li><p>localhost:5000: 这个是connector server的IP和端口，该部分是一个可选项，可以被省略掉。因为我们可以通过后面的服务注册端口，拿到jmx服务运行的端口信息。</p></li><li><p>/jndi/rmi://localhost:6000/jmxrmi: 这个是connector server的路径，具体含义取决于前面的传输协议。比如该URL中这串字符串就代表着该connector server的stub是使用jndi api绑定在rmi://localhost:6000/jmxrmi这个地址。可以理解为，localhost:6000提供了服务的注册查询端口，具体的jmx服务实现在localhost:5000</p></li></ul><p>java进程一般通过如下的配置启动jmx：</p><pre><code>-Dcom.sun.management.jmxremote -Djava.rmi.server.hostname=192.168.0.2  -Dcom.sun.management.jmxremote.port=11113 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false</code></pre><p>通过上面的配置可以看出，只配置了服务注册查询端口11113，而实际的jmx服务运行端口是在运行时通过11113获取到的。</p><h2 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h2><p>上面提到了用ssh tunneling来实现端口转发，跳过防火墙的限制，也讲到了jmx的服务暴露方式。同时引出了我们遇到的问题，我们为了监控远程服务器上的java进程，我们能通过本地的11113端口访问到远程服务器上的JMX服务注册查询端口11113，但是JMX服务运行端口，我们不知道(因为是在运行时随机指定的)，这样貌似走进了死胡同。</p><p>幸运的是我们自己来初始化JMXConnectorServer时，我们可以指定具体的jmx服务端口，并且还可以指定JMX服务端口和JMX注册查询端口为同一个端口。比如我们可以设置JMX url为：</p><pre><code>service:jmx:rmi://localhost:11113/jndi/rmi://localhost:11113/jmxrmi</code></pre><h3 id="解决方案如下："><a href="#解决方案如下：" class="headerlink" title="解决方案如下："></a>解决方案如下：</h3><ol><li><p>通过Java Agent实现在java业务代码运行之前，启动jmx server，并且设置jxm服务注册查询端口和服务端口为同一端口，JMX URL为：</p><pre><code>service:jmx:rmi://127.0.0.1:11113/jndi/rmi://127.0.0.1:11113/jmxrmi</code></pre></li></ol><ol><li>通过ssh tunneling实现端口转发，我们的JMX client只需要访问本地的端口就能跳过防火墙的限制</li></ol><p>注意：这里ip地址写为127.0.0.1是有原因的，看看我们的请求流程:</p><ul><li>JMX client访问本地的127.0.0.1:11113</li><li>注册查询请求被ssh tunneling转发到应用服务192.168.0.2:11113</li><li>应用服务器上的java进程JMX注册查询服务会告诉JMX client,JMX服务在127.0.0.1:11113</li><li>然后JMX client再访问127.0.0.1:11113</li><li>服务请求又被ssh tunneling转发到应用服务192.168.0.2:11113，这次建立了JMX服务请求连接</li></ul><h3 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h3><ol><li>下载<a href="https://github.com/bohrqiu/jmx_agent.git" target="_blank" rel="noopener">jmx agent</a>后执行<code>mvn package</code>，在target目录会生成jmxagent-0.0.1.jar，上传此jar包到服务器</li><li><p>配置java服务进程启动参数</p><pre><code>-javaagent:/root/jmxagent-0.0.1.jar -Djmx.rmi.agent.hostname=127.0.0.1 -Djmx.rmi.agent.port=11113</code></pre><p> 上面设置jmx服务ip为127.0.0.1，服务端口为11113，使用javaagent jar包路径为/root/jmxagent-0.0.1.jar</p></li><li><p>启动java服务</p><p> 在控制台中，可以看到<code>Start the RMI connector server</code>的字样，说明服务正常启动了。</p></li><li><p>建立ssh tunneling</p><p> 在xshell中配置ssh tunneling很简单，只需要两个步骤：</p><p> 配置连接，我们这里需要连接到跳板机的ssh服务，如下图：    </p><p> <img src="/ssh-tunneling-and-JMX-for-remote-monitor/xshell_ssh_tunneling1.jpg" alt=""></p><p> 配置tunneling，配置稳定端口11113，应用服务器192.168.0.2:11113</p><p> <img src="/ssh-tunneling-and-JMX-for-remote-monitor/xshell_ssh_tunneling2.jpg" alt=""></p></li><li><p>使用jmx client监控远程服务</p><p> 在jvisualvm中添加JMX连接，如下图：</p><p> <img src="/ssh-tunneling-and-JMX-for-remote-monitor/xshell_ssh_tunneling3.jpg" alt=""></p></li><li><p>enjoy!    </p></li></ol><p>PS:附带一个maven启用此解决方案的脚本</p><pre><code>export MAVEN_OPTS=&quot;-server -Xms8192m -Xmx8192m -XX:PermSize=128m -XX:MaxPermSize=256m -XX:+PrintGCTimeStamps -XX:+PrintGCDetails  -XX:SurvivorRatio=4 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:MaxTenuringThreshold=5 -XX:+CMSClassUnloadingEnabled -verbosegc  -Xloggc:/var/log/xxx/gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/log/xxx/oom.hprof  -Djava.awt.headless=true  -javaagent:/root/jmxagent-0.0.1.jar -Djmx.rmi.agent.hostname=127.0.0.1 -Djmx.rmi.agent.port=11113&quot;mvn exec:java -Dexec.mainClass=&quot;com.xxx.Bootstrap&quot; &amp;</code></pre>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SSH TUNNELING </tag>
            
            <tag> JMX </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用jdk7新增异常构造器提高异常性能</title>
      <link href="/jdk7-exception/"/>
      <url>/jdk7-exception/</url>
      <content type="html"><![CDATA[<p>JDK7在Throwable对象中增加了一个新的构造器</p><pre><code>protected Throwable(String message, Throwable cause,                    boolean enableSuppression,                    boolean writableStackTrace)</code></pre><p>第三个参数表示是否启用suppressedExceptions(try代码快中抛出异常，在finally中又抛出异常，导致try中的异常丢失)<br>。第四个参数表示是否填充异常栈，如果为false，异常在初始化的时候不会调用本地方法fillInStackTrace。<br><a id="more"></a><br>在业务开发中，我们会使用很多异常来表示不同的业务限制，比如用户余额不足、用户权限不够、参数不合法，这样的异常是不需要填充栈信息的，所以我们可以使用如下的代码来提高异常生成性能：</p><pre><code>package com.yjf.common.exception;    public class AppExcetpion extends RuntimeException {    private static final long serialVersionUID = 1L;            public AppExcetpion() {        this(null, null);    }    public AppExcetpion(String message, Throwable cause) {        super(message, cause, true, false);    }    public AppExcetpion(String message) {        this(message, null);    }    public AppExcetpion(Throwable cause) {        this(null, cause);    }}</code></pre><p>使用此异常会比以前我们使用的异常性能提高10多倍。</p><pre><code>2013-05-09 14:58:39 [main] ERROR com.yjf.common.exception.JAVA7ExceptionTest.testJava7:23 - 运行:2000000/2010000 耗时:457ms2013-05-09 14:58:45 [main] ERROR com.yjf.common.exception.JAVA7ExceptionTest.testOri:40 - 运行:2000000/2010000 耗时:6442ms</code></pre><p>ps:没用使用jdk7或者某些场景下不能使用新特性的,可以考虑重写<code>fillInStackTrace</code>方法:</p><pre><code>public class OrderCheckException extends IllegalArgumentException {    private static final long serialVersionUID = 1L;    private Map&lt;String, String&gt; errorMap = new HashMap&lt;&gt;();    private String msg;    public OrderCheckException() {        super();    }    public OrderCheckException(Throwable cause) {        super(cause);    }    public Map&lt;String, String&gt; getErrorMap() {        return errorMap;    }    /**     * 增加参数错误信息     *      * @param parameter 校验失败参数     * @param msg 参数信息     */    public void addError(String parameter, String msg) {        this.errorMap.put(parameter, msg);        this.msg = null;    }    @Override    public String getMessage() {        if (msg == null) {            if (errorMap.isEmpty()) {                msg = &quot;&quot;;            } else {                StringBuilder sb = new StringBuilder();                for (Map.Entry entry : errorMap.entrySet()) {                    sb.append(entry.getKey()).append(SplitConstants.SEPARATOR_CHAR_COLON)                    .append(entry.getValue()).append(SplitConstants.SEPARATOR_CHAR_COMMA);                }                msg = sb.toString();            }        }        return msg;    }    @Override    public synchronized Throwable fillInStackTrace() {        return this;    }  }</code></pre><p> 上面这个<code>OrderCheckException</code>,它继承了<code>IllegalArgumentException</code>,但是此异常没有重写<code>java.lang.RuntimeException#RuntimeException(java.lang.String, java.lang.Throwable, boolean, boolean)</code>,只有通过重写<code>fillInStackTrace</code>来达到效果.</p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EXCEPTION </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Thinking Clearly about Performance笔记</title>
      <link href="/thinking-clearly-about-performance/"/>
      <url>/thinking-clearly-about-performance/</url>
      <content type="html"><![CDATA[<h2 id="Thinking-Clearly-about-Performance笔记"><a href="#Thinking-Clearly-about-Performance笔记" class="headerlink" title="Thinking Clearly about Performance笔记"></a>Thinking Clearly about Performance笔记</h2><p>原文链接:<a href="http://queue.acm.org/detail.cfm?id=1854041" target="_blank" rel="noopener">Thinking Clearly about Performance</a></p><h3 id="RESPONSE-TIME-VERSUS-THROUGHPUT"><a href="#RESPONSE-TIME-VERSUS-THROUGHPUT" class="headerlink" title="RESPONSE TIME VERSUS THROUGHPUT"></a>RESPONSE TIME VERSUS THROUGHPUT</h3><p>响应时间和吞吐量没有太多关系.你要了解两个值需要测试两个值.下面两个例子说明为什么两者之间没有太多关系.</p><ol><li><p>应用吞吐量为1000笔/s,用户的平均响应时间是多少?</p><p> 如果应用下面是1000个服务提供者在提供服务,每一笔的响应时间最大可以为1s.所以,只能得出的结论是平均响应时间为0-1s</p></li><li><p>客户对某应用的需求为在单cpu的服务器上吞吐量为100笔/s.现在你写的应用每次执行耗时1ms,你的程序满足客户需求吗?</p><p> 如果请求串行发过来,每次执行一个,一个执行完在执行下一个,这种情况应该还是可以满足需求的.但是如果这100个请求在1s内随机的发送过来,CPU调度器(比如线程上下文切换)和串行资源(比如CAS导致的重试)可能让你不能满足客户需求.</p></li></ol><h3 id="PERCENTILE-SPECIFICATIONS"><a href="#PERCENTILE-SPECIFICATIONS" class="headerlink" title="PERCENTILE SPECIFICATIONS"></a>PERCENTILE SPECIFICATIONS</h3><p>平均并不能精确的定义响应时间.假如你能容忍的响应时间是1s,对于不同的应用,他们的平均响应时间都是1s.但是应用A90%的请求响应时间都小于1s和应用B60%的请求响应时间都小于1s,这两个应用提供的服务性能是不一样的.我们一般可以如下的形式来定义响应时间:<code>the “Track Shipment” task must complete in less than .5 second in at least 99.9 percent of executions.</code></p><h3 id="PROBLEM-DIAGNOSIS"><a href="#PROBLEM-DIAGNOSIS" class="headerlink" title="PROBLEM DIAGNOSIS"></a>PROBLEM DIAGNOSIS</h3><p>明确用户的需求,用户不会精确的定义他对性能的需求.大多数时候,他只是说”系统太慢了,我们没办法使用”,可以引导用户提出他的需求<code>Response time of X is more than 20 secondsin many cases. We’ll be happy when response time is one second or less in at least 95 percent of executions.</code></p><h3 id="THE-SEQUENCE-DIAGRAM"><a href="#THE-SEQUENCE-DIAGRAM" class="headerlink" title="THE SEQUENCE DIAGRAM"></a>THE SEQUENCE DIAGRAM</h3><p>The sequence diagram is a good tool for conceptualizing flow of control and the corresponding flow of time. To think clearly about response time, however, you need something else.</p><h3 id="THE-PROFILE"><a href="#THE-PROFILE" class="headerlink" title="THE PROFILE"></a>THE PROFILE</h3><p>A profile shows where your code has spent your time and—sometimes even more importantly—where it has not. There is tremendous value in not having to guess about these things.</p><p>With a profile, you can begin to formulate the answer to the question, “How long should this task run?” which, by now, you know is an important question in the first step of any good problem diagnosis.</p><p><img src="http://deliveryimages.acm.org/10.1145/1860000/1854041/millsap-table2.png" alt=""></p><h3 id="AMDAHL’S-LAW"><a href="#AMDAHL’S-LAW" class="headerlink" title="AMDAHL’S LAW"></a>AMDAHL’S LAW</h3><p>Performance improvement is proportional to how much a program uses the thing you improved. If the thing you’re trying to improve contributes only 5 percent to your task’s total response time, then the maximum impact you’ll be able to make is 5 percent of your total response time. This means that the closer to the top of a profile that you work (assuming that the profile is sorted in descending response-time order), the bigger the benefit potential for your overall response time.</p><h3 id="MINIMIZING-RISK"><a href="#MINIMIZING-RISK" class="headerlink" title="MINIMIZING RISK"></a>MINIMIZING RISK</h3><p>when everyone is happy except for you, make sure your local stuff is in order before you go messing around with the global stuff that affects everyone else, too.</p><h3 id="LOAD"><a href="#LOAD" class="headerlink" title="LOAD"></a>LOAD</h3><p>One measure of load is utilization, which is resource usage divided by resource capacity for a specified time interval.</p><p>There are two reasons that systems get slower as load increases: <strong>queuing delay</strong> and <strong>coherency delay</strong>.</p><ul><li><p>QUEUING DELAY</p><p>  Response time (R), in the perfect scalability M/M/m model, consists of two components: service time (S) and queuing delay (Q), or R = S + Q. </p></li></ul><p>当谈到性能时,你期望一个系统满足下面两个目标:</p><ul><li>最佳的响应时间(不用等太久就能获得结果)</li><li>最佳吞吐量(能服务更多的人)</li></ul><p>但是这两个目标是互相矛盾的,优化第一个目标,需要你较少系统的负载.优化第二个目标,又需要你提高系统使用率,增加负载.你不能同时满足这两个目标,只能权衡取舍.</p><h3 id="COHERENCY-DELAY"><a href="#COHERENCY-DELAY" class="headerlink" title="COHERENCY DELAY"></a>COHERENCY DELAY</h3><p>Your system doesn’t have theoretically perfect scalability. Coherency delay is the factor that you can use to model the imperfection. It is the duration that a task spends communicating and coordinating access to a shared resource. </p><p>The utilization value at which this optimal balance occurs is called the <strong>knee</strong>. This is the point at which throughput is maximized with minimal negative impact to response times. </p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Performance </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>java序列化</title>
      <link href="/java-serialization/"/>
      <url>/java-serialization/</url>
      <content type="html"><![CDATA[<h2 id="什么是序列化"><a href="#什么是序列化" class="headerlink" title="什么是序列化"></a>什么是序列化</h2><p>serialization is the process of converting a data structure or object state into a format that can be stored (for example, in a file or memory buffer, or transmitted across a network connection link) and “resurrected” later in the same or another computer environment.<br><a id="more"></a></p><h2 id="JAVA内置序列化介绍"><a href="#JAVA内置序列化介绍" class="headerlink" title="JAVA内置序列化介绍"></a>JAVA内置序列化介绍</h2><h3 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h3><p>由于Java提供了良好的默认支持，实现基本的对象序列化是件比较简单的事。待序列化的Java类只需要实现Serializable接口即可。Serializable仅是一个标记接口，并不包含任何需要实现的具体方法。实现该接口只是为了声明该Java类的对象是可以被序列化的。实际的序列化和反序列化工作是通过ObjectOuputStream和ObjectInputStream来完成的。ObjectOutputStream的writeObject方法可以把一个Java对象写入到流中，ObjectInputStream的readObject方法可以从流中读取一个Java对象。</p><p>在写入和读取的时候，虽然用的参数或返回值是单个对象，但实际上操纵的是一个对象图，包括该对象所引用的其它对象，以及这些对象所引用的另外的对象。Java会自动帮你遍历对象图并逐个序列化。除了对象之外，Java中的基本类型和数组也是可以通过 ObjectOutputStream和ObjectInputStream来序列化的。</p><p>序列化:</p><pre><code>try {    User user = new User(&quot;Bohr&quot;, &quot;QIU&quot;);    ObjectOutputStream output = new ObjectOutputStream(new FileOutputStream(&quot;user.bin&quot;));    output.writeObject(user);    output.close();} catch (IOException e) {    e.printStackTrace();}</code></pre><p>反序列化:</p><pre><code>try {    ObjectInputStream input = new ObjectInputStream(new FileInputStream(&quot;user.bin&quot;));    User user = (User) input.readObject();    System.out.println(user);    } catch (Exception e) {        e.printStackTrace();    }</code></pre><p> User类实现了Serializable接口。</p><h3 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h3><h4 id="哪些东东会被序列化"><a href="#哪些东东会被序列化" class="headerlink" title="哪些东东会被序列化"></a>哪些东东会被序列化</h4><p>序列化只保存状态，不保存行为。在默认的序列化实现中，Java对象中的非静态和非瞬时域都会被序列化。</p><h4 id="如何控制序列化字段"><a href="#如何控制序列化字段" class="headerlink" title="如何控制序列化字段"></a>如何控制序列化字段</h4><p>1、把域声明为瞬时的，即使用transient关键词。</p><p>2、添加一个serialPersistentFields域来声明序列化时要包含的域。</p><pre><code>private static final ObjectStreamField[] serialPersistentFields = {     new ObjectStreamField(&quot;firstName&quot;, String.class) };  </code></pre><p>上面的代码给出了 serialPersistentFields的声明示例，即只有firstName这个域是要被序列化的。</p><h4 id="为什么反序列化时不成功"><a href="#为什么反序列化时不成功" class="headerlink" title="为什么反序列化时不成功"></a>为什么反序列化时不成功</h4><p>虚拟机是否允许反序列化，不仅取决于类路径和功能代码是否一致，一个非常重要的一点是两个类的序列化 ID 是否一致（就是 private static final long serialVersionUID = 1L）。</p><p>如果类没有serialVersionUID静态字段，jvm在反序列化时会根据field情况生成serialVersionUID，类字段增减时，就会出现版本不一致的问题，最好添加一个默认的版本，当然也可以通过这种方式来控制类的不同版本。</p><h4 id="实现了Serializable接口为什么还是序列化不成功？"><a href="#实现了Serializable接口为什么还是序列化不成功？" class="headerlink" title="实现了Serializable接口为什么还是序列化不成功？"></a>实现了Serializable接口为什么还是序列化不成功？</h4><p>如果类中的域包含不可序列化的对象，序列化就会失败，抛出NotSerializableException。</p><h4 id="父类实现了Serializable接口，子类不想序列化怎么办？"><a href="#父类实现了Serializable接口，子类不想序列化怎么办？" class="headerlink" title="父类实现了Serializable接口，子类不想序列化怎么办？"></a>父类实现了Serializable接口，子类不想序列化怎么办？</h4><p>子类可以重载writeObject () 或者 readObject ()方法，在方法体中throw NotSerializableException </p><h4 id="什么是compatible-changes-and-incompatible-changes"><a href="#什么是compatible-changes-and-incompatible-changes" class="headerlink" title="什么是compatible changes and incompatible changes"></a>什么是compatible changes and incompatible changes</h4><p>增减字段或者方法属于compatible changes，只要serialVersionUID相同，还可以成功的反序列化。但是如果修改类层次，或者不实现Serializable接口，就属于incompatible changes。参考java 序列化规范</p><h4 id="反序列化后的对象和new-的对象有什么区别"><a href="#反序列化后的对象和new-的对象有什么区别" class="headerlink" title="反序列化后的对象和new 的对象有什么区别"></a>反序列化后的对象和new 的对象有什么区别</h4><p>在通过ObjectInputStream的readObject方法读取到一个对象之后，这个对象是一个新的实例，但是其构造方法是没有被调用的，其中的域的初始化代码也没有被执行。对于那些没有被序列化的域，在新创建出来的对象中的值都是默认的。也就是说，这个对象从某种角度上来说是不完备的。这有可能会造成一些隐含的错误。调用者并不知道对象是通过一般的new操作符来创建的，还是通过反序列化所得到的。解决的办法就是在类的readObject方法里面，再执行所需的对象初始化逻辑。对于一般的Java类来说，构造方法中包含了初始化的逻辑。可以把这些逻辑提取到一个方法中，在readObject方法中调用此方法。</p><h4 id="序列化安全性"><a href="#序列化安全性" class="headerlink" title="序列化安全性"></a>序列化安全性</h4><p>Java对象序列化之后的内容格式是公开的。所以可以很容易的从中提取出各种信息。从实现的角度来说，可以从不同的层次来加强序列化的安全性。</p><p>对序列化之后的流进行加密。这可以通过CipherOutputStream来实现。<br>实现自己的writeObject和readObject方法，在调用defaultWriteObject之前，先对要序列化的域的值进行加密处理。<br>使用一个SignedObject或SealedObject来封装当前对象，用SignedObject或SealedObject进行序列化。<br>在从流中进行反序列化的时候，可以通过ObjectInputStream的registerValidation方法添加ObjectInputValidation接口的实现，用来验证反序列化之后得到的对象是否合法。</p><h4 id="自定义对象序列化"><a href="#自定义对象序列化" class="headerlink" title="自定义对象序列化"></a>自定义对象序列化</h4><h5 id="Serializable接口"><a href="#Serializable接口" class="headerlink" title="Serializable接口"></a>Serializable接口</h5><p><code>Serializable</code>接口是一个标记接口，接口内没有任何方法，但是在实际的序列化和反序列化过程中，jvm通过一些契约规则来满足用户自定义需求。</p><p>基本的对象序列化机制让开发人员可以在包含哪些域上进行定制。如果想对序列化的过程进行更加细粒度的控制，就需要在类中添加writeObject和对应的 readObject方法。这两个方法属于前面提到的序列化机制的隐含契约的一部分。在通过ObjectOutputStream的 writeObject方法写入对象的时候，如果这个对象的类中定义了writeObject方法，就会调用该方法，并把当前 ObjectOutputStream对象作为参数传递进去。writeObject方法中一般会包含自定义的序列化逻辑，比如在写入之前修改域的值，或是写入额外的数据等。对于writeObject中添加的逻辑，在对应的readObject中都需要反转过来，与之对应。</p><p>在添加自己的逻辑之前，推荐的做法是先调用Java的默认实现。在writeObject方法中通过ObjectOutputStream的defaultWriteObject来完成，在readObject方法则通过ObjectInputStream的defaultReadObject来实现。下面的代码在对象的序列化流中写入了一个额外的字符串。</p><pre><code>private void writeObject(ObjectOutputStream output) throws IOException {    output.defaultWriteObject();    output.writeUTF(&quot;Hello World&quot;);}private void readObject(ObjectInputStream input) throws IOException, ClassNotFoundException {    input.defaultReadObject();    String value = input.readUTF();        System.out.println(value);} </code></pre><h5 id="Externalizable接口"><a href="#Externalizable接口" class="headerlink" title="Externalizable接口"></a>Externalizable接口</h5><p><code>Externalizable</code> 是一个包含方法签名的接口,包括writeExternal和readExternal: </p><pre><code>public void readExternal(ObjectInput arg0) throws IOException,             ClassNotFoundException {         Object obj = arg0.readObject();       }  public void writeExternal(ObjectOutput arg0) throws IOException {          arg0.writeObject(&quot;Hello world&quot;);  }  </code></pre><p>参考:<br><a href="http://www.infoq.com/cn/articles/cf-java-object-serialization-rmi" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/cf-java-object-serialization-rmi</a></p>]]></content>
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java序列化 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
